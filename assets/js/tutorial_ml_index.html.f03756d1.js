"use strict";(self.webpackChunkmy_vuepress_site=self.webpackChunkmy_vuepress_site||[]).push([[2831],{8357:(l,i,t)=>{t.r(i),t.d(i,{comp:()=>r,data:()=>e});var n=t(641);const s={},r=(0,t(6262).A)(s,[["render",function(l,i){return(0,n.uX)(),(0,n.CE)("div",null,[...i[0]||(i[0]=[(0,n.Fv)('<h1 id="机器学习学习教程" tabindex="-1"><a class="header-anchor" href="#机器学习学习教程"><span>机器学习学习教程</span></a></h1><h2 id="_1-机器学习基础概念" tabindex="-1"><a class="header-anchor" href="#_1-机器学习基础概念"><span>1. 机器学习基础概念</span></a></h2><h3 id="q1-什么是机器学习" tabindex="-1"><a class="header-anchor" href="#q1-什么是机器学习"><span>Q1: 什么是机器学习？</span></a></h3><p><strong>答：</strong> 机器学习是人工智能的一个分支，致力于研究如何让计算机系统通过学习数据中的模式和规律，从而对新的、未见过的数据进行预测或决策，而无需被明确编程。</p><p>核心思想：</p><ul><li>从数据中自动学习模式</li><li>泛化能力：对新数据做出准确预测</li><li>不需要显式编程每个决策规则</li></ul><h3 id="q2-机器学习的三大类型是什么" tabindex="-1"><a class="header-anchor" href="#q2-机器学习的三大类型是什么"><span>Q2: 机器学习的三大类型是什么？</span></a></h3><p><strong>答：</strong> 机器学习主要分为三大类型：</p><ol><li><p><strong>监督学习（Supervised Learning）</strong>：</p><ul><li>使用带有标签的训练数据</li><li>目标是学习输入到输出的映射关系</li><li>包括分类和回归任务</li></ul></li><li><p><strong>无监督学习（Unsupervised Learning）</strong>：</p><ul><li>使用无标签的数据</li><li>目标是发现数据中的结构或模式</li><li>包括聚类、降维等任务</li></ul></li><li><p><strong>强化学习（Reinforcement Learning）</strong>：</p><ul><li>通过与环境交互学习</li><li>根据奖励信号优化行为策略</li><li>目标是最大化累积奖励</li></ul></li></ol><h3 id="q3-机器学习的基本流程是什么" tabindex="-1"><a class="header-anchor" href="#q3-机器学习的基本流程是什么"><span>Q3: 机器学习的基本流程是什么？</span></a></h3><p><strong>答：</strong> 机器学习的基本流程包括：</p><ol><li><strong>问题定义</strong>：明确要解决的问题类型</li><li><strong>数据收集</strong>：获取相关的训练数据</li><li><strong>数据预处理</strong>：清洗、转换、标准化数据</li><li><strong>特征工程</strong>：提取和选择有用的特征</li><li><strong>模型选择</strong>：选择合适的算法</li><li><strong>模型训练</strong>：使用训练数据训练模型</li><li><strong>模型评估</strong>：使用验证数据评估性能</li><li><strong>模型调优</strong>：调整超参数优化性能</li><li><strong>模型部署</strong>：将模型应用到实际场景</li><li><strong>模型监控</strong>：持续监控模型性能</li></ol><h2 id="_2-监督学习算法" tabindex="-1"><a class="header-anchor" href="#_2-监督学习算法"><span>2. 监督学习算法</span></a></h2><h3 id="q4-线性回归的原理是什么" tabindex="-1"><a class="header-anchor" href="#q4-线性回归的原理是什么"><span>Q4: 线性回归的原理是什么？</span></a></h3><p><strong>答：</strong> 线性回归是一种用于预测连续数值的监督学习算法。</p><p>原理：</p><ul><li>假设目标变量与特征之间存在线性关系</li><li>通过最小化预测值与真实值之间的平方误差来学习参数</li><li>模型形式：y = w₀ + w₁x₁ + w₂x₂ + ... + wₙxₙ</li></ul><p>损失函数（均方误差）： MSE = (1/m) Σ(yᵢ - ŷᵢ)²</p><p>优化方法：</p><ul><li>梯度下降法</li><li>正规方程法</li></ul><h3 id="q5-逻辑回归与线性回归的区别" tabindex="-1"><a class="header-anchor" href="#q5-逻辑回归与线性回归的区别"><span>Q5: 逻辑回归与线性回归的区别？</span></a></h3><p><strong>答：</strong></p><table><thead><tr><th>特性</th><th>线性回归</th><th>逻辑回归</th></tr></thead><tbody><tr><td>任务类型</td><td>回归</td><td>分类</td></tr><tr><td>输出范围</td><td>(-∞, +∞)</td><td>(0, 1)</td></tr><tr><td>激活函数</td><td>无</td><td>Sigmoid函数</td></tr><tr><td>损失函数</td><td>均方误差</td><td>交叉熵</td></tr><tr><td>决策边界</td><td>无</td><td>0.5阈值</td></tr></tbody></table><p>逻辑回归通过Sigmoid函数将线性回归的输出映射到(0,1)区间，表示属于正类的概率。</p><h3 id="q6-决策树算法的原理" tabindex="-1"><a class="header-anchor" href="#q6-决策树算法的原理"><span>Q6: 决策树算法的原理？</span></a></h3><p><strong>答：</strong> 决策树是一种基于树结构的分类和回归算法。</p><p>构建过程：</p><ol><li><strong>特征选择</strong>：选择最优分割特征（信息增益、基尼系数等）</li><li><strong>节点分割</strong>：根据特征值分割数据集</li><li><strong>递归构建</strong>：对子节点递归执行上述过程</li><li><strong>停止条件</strong>：达到最大深度、样本数不足等</li></ol><p>优点：</p><ul><li>易于理解和解释</li><li>不需要数据预处理</li><li>能处理数值型和类别型特征</li></ul><p>缺点：</p><ul><li>容易过拟合</li><li>对噪声敏感</li><li>不稳定（数据小变动可能导致树结构大变化）</li></ul><h2 id="_3-无监督学习算法" tabindex="-1"><a class="header-anchor" href="#_3-无监督学习算法"><span>3. 无监督学习算法</span></a></h2><h3 id="q7-k-means聚类算法的原理" tabindex="-1"><a class="header-anchor" href="#q7-k-means聚类算法的原理"><span>Q7: K-means聚类算法的原理？</span></a></h3><p><strong>答：</strong> K-means是一种基于距离的聚类算法。</p><p>算法步骤：</p><ol><li>初始化K个聚类中心</li><li>将每个样本分配给最近的聚类中心</li><li>更新聚类中心为所属样本的均值</li><li>重复步骤2-3直到收敛</li></ol><p>目标函数（簇内平方和）： J = ΣΣ||xᵢ - μⱼ||²</p><p>关键参数：</p><ul><li>K值选择</li><li>初始化方法</li><li>距离度量</li></ul><h3 id="q8-主成分分析-pca-的原理" tabindex="-1"><a class="header-anchor" href="#q8-主成分分析-pca-的原理"><span>Q8: 主成分分析（PCA）的原理？</span></a></h3><p><strong>答：</strong> PCA是一种降维技术，通过线性变换将高维数据投影到低维空间。</p><p>原理：</p><ol><li><strong>数据中心化</strong>：减去均值使数据零中心化</li><li><strong>计算协方差矩阵</strong>：衡量特征间的相关性</li><li><strong>特征值分解</strong>：计算协方差矩阵的特征值和特征向量</li><li><strong>选择主成分</strong>：选取最大的k个特征值对应的特征向量</li><li><strong>数据投影</strong>：将原始数据投影到主成分空间</li></ol><p>目标：</p><ul><li>最大化投影后数据的方差</li><li>最小化投影误差</li></ul><h2 id="_4-集成学习" tabindex="-1"><a class="header-anchor" href="#_4-集成学习"><span>4. 集成学习</span></a></h2><h3 id="q9-集成学习的基本思想" tabindex="-1"><a class="header-anchor" href="#q9-集成学习的基本思想"><span>Q9: 集成学习的基本思想？</span></a></h3><p><strong>答：</strong> 集成学习通过组合多个弱学习器来构建强学习器。</p><p>基本思想：</p><ul><li>&quot;三个臭皮匠，顶个诸葛亮&quot;</li><li>通过多样性降低整体误差</li><li>结合多个模型的优势</li></ul><p>主要方法：</p><ol><li><strong>Bagging</strong>：并行训练多个模型，降低方差</li><li><strong>Boosting</strong>：串行训练多个模型，降低偏差</li><li><strong>Stacking</strong>：使用元学习器组合多个基学习器</li></ol><h3 id="q10-随机森林和gbdt的区别" tabindex="-1"><a class="header-anchor" href="#q10-随机森林和gbdt的区别"><span>Q10: 随机森林和GBDT的区别？</span></a></h3><p><strong>答：</strong></p><p><strong>随机森林（Random Forest）</strong>：</p><ul><li>Bagging方法</li><li>并行训练多个决策树</li><li>每棵树独立训练</li><li>通过投票或平均进行预测</li><li>主要降低方差</li></ul><p><strong>GBDT（Gradient Boosting Decision Tree）</strong>：</p><ul><li>Boosting方法</li><li>串行训练多个决策树</li><li>每棵树纠正前一棵树的错误</li><li>通过加法模型进行预测</li><li>主要降低偏差</li></ul><h2 id="_5-模型评估与优化" tabindex="-1"><a class="header-anchor" href="#_5-模型评估与优化"><span>5. 模型评估与优化</span></a></h2><h3 id="q11-如何评估分类模型的性能" tabindex="-1"><a class="header-anchor" href="#q11-如何评估分类模型的性能"><span>Q11: 如何评估分类模型的性能？</span></a></h3><p><strong>答：</strong> 分类模型的评估指标包括：</p><ol><li><p><strong>混淆矩阵</strong>：</p><ul><li>TP（真正例）、TN（真负例）</li><li>FP（假正例）、FN（假负例）</li></ul></li><li><p><strong>基本指标</strong>：</p><ul><li>准确率 Accuracy = (TP+TN)/(TP+TN+FP+FN)</li><li>精确率 Precision = TP/(TP+FP)</li><li>召回率 Recall = TP/(TP+FN)</li><li>F1分数 = 2*(Precision*Recall)/(Precision+Recall)</li></ul></li><li><p><strong>ROC曲线和AUC</strong>：</p><ul><li>ROC：真正例率vs假正例率</li><li>AUC：ROC曲线下面积</li></ul></li></ol><h3 id="q12-过拟合和欠拟合如何解决" tabindex="-1"><a class="header-anchor" href="#q12-过拟合和欠拟合如何解决"><span>Q12: 过拟合和欠拟合如何解决？</span></a></h3><p><strong>答：</strong></p><p><strong>过拟合（Overfitting）</strong>：</p><ul><li>表现：训练误差小，验证误差大</li><li>解决方法： <ul><li>增加训练数据</li><li>简化模型复杂度</li><li>正则化（L1/L2）</li><li>Dropout</li><li>早停法</li></ul></li></ul><p><strong>欠拟合（Underfitting）</strong>：</p><ul><li>表现：训练误差大，验证误差也大</li><li>解决方法： <ul><li>增加模型复杂度</li><li>添加更多特征</li><li>减少正则化强度</li><li>增加训练时间</li></ul></li></ul><h2 id="_6-机器学习实践" tabindex="-1"><a class="header-anchor" href="#_6-机器学习实践"><span>6. 机器学习实践</span></a></h2><h3 id="q13-特征工程的重要性" tabindex="-1"><a class="header-anchor" href="#q13-特征工程的重要性"><span>Q13: 特征工程的重要性？</span></a></h3><p><strong>答：</strong> 特征工程是机器学习中至关重要的环节，常说&quot;数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已&quot;。</p><p>主要内容：</p><ol><li><strong>数据清洗</strong>：处理缺失值、异常值、重复值</li><li><strong>特征构造</strong>：从原始数据中创建新特征</li><li><strong>特征变换</strong>：标准化、归一化、离散化</li><li><strong>特征选择</strong>：选择最有用的特征子集</li></ol><p>常用技术：</p><ul><li>缺失值处理：均值填充、中位数填充、模型预测</li><li>编码技术：独热编码、标签编码、目标编码</li><li>特征缩放：Min-Max标准化、Z-Score标准化</li></ul><h3 id="q14-交叉验证的作用" tabindex="-1"><a class="header-anchor" href="#q14-交叉验证的作用"><span>Q14: 交叉验证的作用？</span></a></h3><p><strong>答：</strong> 交叉验证是一种模型评估技术，用于更可靠地估计模型性能。</p><p>常见方法：</p><ol><li><p><strong>K折交叉验证</strong>：</p><ul><li>将数据分为K个子集</li><li>轮流使用其中一个子集作为验证集，其余作为训练集</li><li>计算K次验证结果的平均值</li></ul></li><li><p><strong>留一交叉验证</strong>：</p><ul><li>K=N的特殊情况</li><li>每次只留一个样本作为验证集</li></ul></li></ol><p>优点：</p><ul><li>更充分地利用数据</li><li>减少评估结果的方差</li><li>更可靠的性能估计</li></ul><h2 id="_7-机器学习发展趋势" tabindex="-1"><a class="header-anchor" href="#_7-机器学习发展趋势"><span>7. 机器学习发展趋势</span></a></h2><h3 id="q15-深度学习与传统机器学习的区别" tabindex="-1"><a class="header-anchor" href="#q15-深度学习与传统机器学习的区别"><span>Q15: 深度学习与传统机器学习的区别？</span></a></h3><p><strong>答：</strong></p><table><thead><tr><th>方面</th><th>传统机器学习</th><th>深度学习</th></tr></thead><tbody><tr><td>特征工程</td><td>手工设计特征</td><td>自动学习特征</td></tr><tr><td>模型复杂度</td><td>相对简单</td><td>非常复杂</td></tr><tr><td>数据需求</td><td>中等规模</td><td>大规模</td></tr><tr><td>计算资源</td><td>较少</td><td>大量GPU资源</td></tr><tr><td>可解释性</td><td>较好</td><td>较差</td></tr><tr><td>应用领域</td><td>结构化数据</td><td>图像、语音、文本</td></tr></tbody></table><h3 id="q16-automl的发展现状" tabindex="-1"><a class="header-anchor" href="#q16-automl的发展现状"><span>Q16: AutoML的发展现状？</span></a></h3><p><strong>答：</strong> AutoML（自动化机器学习）旨在自动化机器学习流程，降低使用门槛。</p><p>主要方向：</p><ol><li><strong>自动化特征工程</strong>：自动构造和选择特征</li><li><strong>自动化模型选择</strong>：自动选择最优算法</li><li><strong>自动化超参数调优</strong>：贝叶斯优化、遗传算法等</li><li><strong>神经网络架构搜索</strong>：NAS技术</li></ol><p>主流工具：</p><ul><li>Google AutoML</li><li>H2O.ai</li><li>Auto-sklearn</li><li>TPOT</li></ul>',92)])])}]]),e=JSON.parse('{"path":"/tutorial/ml/","title":"机器学习学习教程","lang":"zh-CN","frontmatter":{},"headers":[{"level":2,"title":"1. 机器学习基础概念","slug":"_1-机器学习基础概念","link":"#_1-机器学习基础概念","children":[{"level":3,"title":"Q1: 什么是机器学习？","slug":"q1-什么是机器学习","link":"#q1-什么是机器学习","children":[]},{"level":3,"title":"Q2: 机器学习的三大类型是什么？","slug":"q2-机器学习的三大类型是什么","link":"#q2-机器学习的三大类型是什么","children":[]},{"level":3,"title":"Q3: 机器学习的基本流程是什么？","slug":"q3-机器学习的基本流程是什么","link":"#q3-机器学习的基本流程是什么","children":[]}]},{"level":2,"title":"2. 监督学习算法","slug":"_2-监督学习算法","link":"#_2-监督学习算法","children":[{"level":3,"title":"Q4: 线性回归的原理是什么？","slug":"q4-线性回归的原理是什么","link":"#q4-线性回归的原理是什么","children":[]},{"level":3,"title":"Q5: 逻辑回归与线性回归的区别？","slug":"q5-逻辑回归与线性回归的区别","link":"#q5-逻辑回归与线性回归的区别","children":[]},{"level":3,"title":"Q6: 决策树算法的原理？","slug":"q6-决策树算法的原理","link":"#q6-决策树算法的原理","children":[]}]},{"level":2,"title":"3. 无监督学习算法","slug":"_3-无监督学习算法","link":"#_3-无监督学习算法","children":[{"level":3,"title":"Q7: K-means聚类算法的原理？","slug":"q7-k-means聚类算法的原理","link":"#q7-k-means聚类算法的原理","children":[]},{"level":3,"title":"Q8: 主成分分析（PCA）的原理？","slug":"q8-主成分分析-pca-的原理","link":"#q8-主成分分析-pca-的原理","children":[]}]},{"level":2,"title":"4. 集成学习","slug":"_4-集成学习","link":"#_4-集成学习","children":[{"level":3,"title":"Q9: 集成学习的基本思想？","slug":"q9-集成学习的基本思想","link":"#q9-集成学习的基本思想","children":[]},{"level":3,"title":"Q10: 随机森林和GBDT的区别？","slug":"q10-随机森林和gbdt的区别","link":"#q10-随机森林和gbdt的区别","children":[]}]},{"level":2,"title":"5. 模型评估与优化","slug":"_5-模型评估与优化","link":"#_5-模型评估与优化","children":[{"level":3,"title":"Q11: 如何评估分类模型的性能？","slug":"q11-如何评估分类模型的性能","link":"#q11-如何评估分类模型的性能","children":[]},{"level":3,"title":"Q12: 过拟合和欠拟合如何解决？","slug":"q12-过拟合和欠拟合如何解决","link":"#q12-过拟合和欠拟合如何解决","children":[]}]},{"level":2,"title":"6. 机器学习实践","slug":"_6-机器学习实践","link":"#_6-机器学习实践","children":[{"level":3,"title":"Q13: 特征工程的重要性？","slug":"q13-特征工程的重要性","link":"#q13-特征工程的重要性","children":[]},{"level":3,"title":"Q14: 交叉验证的作用？","slug":"q14-交叉验证的作用","link":"#q14-交叉验证的作用","children":[]}]},{"level":2,"title":"7. 机器学习发展趋势","slug":"_7-机器学习发展趋势","link":"#_7-机器学习发展趋势","children":[{"level":3,"title":"Q15: 深度学习与传统机器学习的区别？","slug":"q15-深度学习与传统机器学习的区别","link":"#q15-深度学习与传统机器学习的区别","children":[]},{"level":3,"title":"Q16: AutoML的发展现状？","slug":"q16-automl的发展现状","link":"#q16-automl的发展现状","children":[]}]}],"git":{"contributors":[{"name":"mingwzh","username":"mingwzh","email":"1127699551@qq.com","commits":1,"url":"https://github.com/mingwzh"}],"changelog":[{"hash":"32cee5a7b786b67fd7f03fd78a8211882f7fbb57","time":1765517303000,"email":"1127699551@qq.com","author":"mingwzh","message":"docs(tutorial): 添加嵌入式系统学习教程"}]},"filePathRelative":"tutorial/ml/README.md"}')}}]);