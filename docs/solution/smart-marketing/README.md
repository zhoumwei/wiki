# æ™ºèƒ½è¥é”€è§£å†³æ–¹æ¡ˆ

## 1. æ™ºèƒ½è¥é”€æ¦‚è¿°

### Q1: ä»€ä¹ˆæ˜¯æ™ºèƒ½è¥é”€ï¼Ÿå®ƒè§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿ
**ç­”ï¼š** æ™ºèƒ½è¥é”€ï¼ˆSmart Marketingï¼‰æ˜¯è¿ç”¨äººå·¥æ™ºèƒ½ã€å¤§æ•°æ®åˆ†æã€æœºå™¨å­¦ä¹ ç­‰æŠ€æœ¯ï¼Œå®ç°ç²¾å‡†ç”¨æˆ·æ´å¯Ÿã€ä¸ªæ€§åŒ–æ¨èã€è‡ªåŠ¨åŒ–è¥é”€å’Œæ•ˆæœä¼˜åŒ–çš„ç°ä»£åŒ–è¥é”€æ–¹å¼ã€‚

è§£å†³çš„é—®é¢˜ï¼š
- **ç”¨æˆ·ç”»åƒä¸ç²¾å‡†**ï¼šä¼ ç»Ÿè¥é”€ç¼ºä¹å¯¹ç”¨æˆ·çš„æ·±åº¦ç†è§£
- **è¥é”€å†…å®¹åŒè´¨åŒ–**ï¼šæ— æ³•æä¾›ä¸ªæ€§åŒ–çš„äº§å“å’ŒæœåŠ¡æ¨è
- **æŠ•æ”¾æ•ˆç‡ä½ä¸‹**ï¼šå¹¿å‘ŠæŠ•æ”¾ç¼ºä¹ç²¾å‡†å®šå‘ï¼ŒROIä¸é«˜
- **è¥é”€æ—¶æœºæŠŠæ¡ä¸å‡†**ï¼šæ— æ³•åœ¨æœ€ä½³æ—¶æœºè§¦è¾¾ç”¨æˆ·
- **æ•ˆæœè¯„ä¼°å›°éš¾**ï¼šç¼ºä¹æœ‰æ•ˆçš„æ•°æ®æ”¯æ’‘å’Œå®æ—¶åé¦ˆæœºåˆ¶

### Q2: æ™ºèƒ½è¥é”€çš„æ ¸å¿ƒèƒ½åŠ›æœ‰å“ªäº›ï¼Ÿ
**ç­”ï¼š** æ™ºèƒ½è¥é”€çš„æ ¸å¿ƒèƒ½åŠ›åŒ…æ‹¬ï¼š

1. **ç”¨æˆ·æ´å¯Ÿ**ï¼š
   - 360åº¦ç”¨æˆ·ç”»åƒæ„å»º
   - ç”¨æˆ·è¡Œä¸ºåˆ†æå’Œé¢„æµ‹
   - ç”¨æˆ·åˆ†ç¾¤å’Œæ ‡ç­¾ä½“ç³»

2. **ä¸ªæ€§åŒ–æ¨è**ï¼š
   - ååŒè¿‡æ»¤ç®—æ³•
   - å†…å®¹æ¨èç³»ç»Ÿ
   - å®æ—¶ä¸ªæ€§åŒ–å¼•æ“

3. **ç²¾å‡†æŠ•æ”¾**ï¼š
   - ç¨‹åºåŒ–å¹¿å‘ŠæŠ•æ”¾
   - å¤šæ¸ é“ååŒæŠ•æ”¾
   - åŠ¨æ€åˆ›æ„ä¼˜åŒ–

4. **è¥é”€è‡ªåŠ¨åŒ–**ï¼š
   - è¥é”€å·¥ä½œæµè‡ªåŠ¨åŒ–
   - æ™ºèƒ½å®¢æœå’ŒèŠå¤©æœºå™¨äºº
   - ç”Ÿå‘½å‘¨æœŸè¥é”€ç®¡ç†

5. **æ•ˆæœä¼˜åŒ–**ï¼š
   - A/Bæµ‹è¯•å’Œå¤šå˜é‡æµ‹è¯•
   - å®æ—¶æ•ˆæœç›‘æ§
   - ROIä¼˜åŒ–ç®—æ³•

### Q3: æ™ºèƒ½è¥é”€çš„æŠ€æœ¯æ¶æ„ï¼Ÿ
**ç­”ï¼š** æ™ºèƒ½è¥é”€çš„å…¸å‹æŠ€æœ¯æ¶æ„åˆ†ä¸ºä»¥ä¸‹å‡ å±‚ï¼š

1. **æ•°æ®å±‚**ï¼š
   - æ•°æ®é‡‡é›†ï¼šç”¨æˆ·è¡Œä¸ºæ•°æ®ã€äº¤æ˜“æ•°æ®ã€ç¬¬ä¸‰æ–¹æ•°æ®
   - æ•°æ®å­˜å‚¨ï¼šæ•°æ®ä»“åº“ã€æ•°æ®æ¹–ã€å®æ—¶æ•°æ®åº“
   - æ•°æ®å¤„ç†ï¼šETLã€æµå¤„ç†ã€æ‰¹å¤„ç†

2. **å¹³å°å±‚**ï¼š
   - ç”¨æˆ·ç”»åƒå¹³å°ï¼šæ ‡ç­¾ä½“ç³»ã€äººç¾¤ç®¡ç†
   - ç®—æ³•å¹³å°ï¼šæ¨èç®—æ³•ã€é¢„æµ‹æ¨¡å‹
   - è¥é”€ç¼–æ’ï¼šå·¥ä½œæµå¼•æ“ã€ä»»åŠ¡è°ƒåº¦

3. **åº”ç”¨å±‚**ï¼š
   - ä¸ªæ€§åŒ–æ¨èï¼šå•†å“æ¨èã€å†…å®¹æ¨è
   - ç²¾å‡†è¥é”€ï¼šå¹¿å‘ŠæŠ•æ”¾ã€é‚®ä»¶è¥é”€
   - æ™ºèƒ½å®¢æœï¼šèŠå¤©æœºå™¨äººã€è¯­éŸ³åŠ©æ‰‹

4. **äº¤äº’å±‚**ï¼š
   - è¥é”€æ§åˆ¶å°ï¼šå¯è§†åŒ–é…ç½®ã€æ•ˆæœç›‘æ§
   - æ•°æ®çœ‹æ¿ï¼šå®æ—¶æŠ¥è¡¨ã€è¶‹åŠ¿åˆ†æ
   - APIæ¥å£ï¼šç³»ç»Ÿé›†æˆã€ç¬¬ä¸‰æ–¹æ¥å…¥

## 2. ç”¨æˆ·ç”»åƒä¸æ ‡ç­¾ä½“ç³»

### Q4: å¦‚ä½•æ„å»º360åº¦ç”¨æˆ·ç”»åƒï¼Ÿ
**ç­”ï¼š** 360åº¦ç”¨æˆ·ç”»åƒéœ€è¦æ•´åˆå¤šç»´åº¦ç”¨æˆ·æ•°æ®ï¼š

**ç”¨æˆ·ç”»åƒæ•°æ®ç»´åº¦**ï¼š
```python
class UserProfileBuilder:
    def __init__(self):
        self.data_sources = {
            'behavioral': self.collect_behavioral_data,
            'demographic': self.collect_demographic_data,
            'transactional': self.collect_transactional_data,
            'social': self.collect_social_data,
            'psychographic': self.collect_psychographic_data
        }
    
    def build_user_profile(self, user_id):
        """æ„å»ºå®Œæ•´çš„ç”¨æˆ·ç”»åƒ"""
        profile = {
            'basic_info': self._get_basic_info(user_id),
            'behavioral_traits': self._analyze_behavioral_traits(user_id),
            'purchase_patterns': self._analyze_purchase_patterns(user_id),
            'interest_preferences': self._analyze_interests(user_id),
            'lifecycle_stage': self._determine_lifecycle_stage(user_id),
            'value_segment': self._segment_user_value(user_id),
            'risk_profile': self._assess_risk_profile(user_id)
        }
        
        return profile
    
    def _analyze_behavioral_traits(self, user_id):
        """åˆ†æè¡Œä¸ºç‰¹å¾"""
        behaviors = self.collect_behavioral_data(user_id)
        
        return {
            'activity_level': self._calculate_activity_level(behaviors),
            'engagement_score': self._calculate_engagement_score(behaviors),
            'device_preference': self._determine_device_preference(behaviors),
            'channel_affinity': self._analyze_channel_affinity(behaviors),
            'time_patterns': self._analyze_time_patterns(behaviors)
        }
    
    def _analyze_purchase_patterns(self, user_id):
        """åˆ†æè´­ä¹°æ¨¡å¼"""
        transactions = self.collect_transactional_data(user_id)
        
        return {
            'purchase_frequency': self._calculate_purchase_frequency(transactions),
            'avg_order_value': self._calculate_avg_order_value(transactions),
            'preferred_categories': self._identify_preferred_categories(transactions),
            'seasonal_patterns': self._analyze_seasonal_patterns(transactions),
            'payment_preferences': self._analyze_payment_preferences(transactions)
        }
```

### Q5: ç”¨æˆ·æ ‡ç­¾ä½“ç³»è®¾è®¡ï¼Ÿ
**ç­”ï¼š** ç”¨æˆ·æ ‡ç­¾ä½“ç³»æ˜¯ç”¨æˆ·ç”»åƒçš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼š

**æ ‡ç­¾åˆ†ç±»ä½“ç³»**ï¼š
```python
class TagSystem:
    def __init__(self):
        self.tag_categories = {
            'demographics': {
                'age_group': ['18-24', '25-34', '35-44', '45-54', '55+'],
                'gender': ['male', 'female', 'other'],
                'location': ['first_tier_city', 'second_tier_city', 'third_tier_city', 'rural'],
                'education': ['high_school', 'bachelor', 'master', 'phd'],
                'occupation': ['student', 'professional', 'manager', 'entrepreneur', 'retired']
            },
            'behavioral': {
                'activity_level': ['very_active', 'active', 'moderate', 'low', 'inactive'],
                'engagement_type': ['browser', 'buyer', 'reviewer', 'sharer', 'loyal_customer'],
                'visit_frequency': ['daily', 'weekly', 'monthly', 'occasional'],
                'session_duration': ['short', 'medium', 'long'],
                'conversion_likelihood': ['high', 'medium', 'low']
            },
            'transactional': {
                'customer_value': ['vip', 'premium', 'standard', 'potential'],
                'spending_power': ['high', 'medium', 'low'],
                'purchase_frequency': ['frequent', 'regular', 'occasional', 'new'],
                'brand_loyalty': ['loyal', 'switcher', 'explorer'],
                'payment_method': ['credit_card', 'debit_card', 'mobile_payment', 'cash_on_delivery']
            },
            'psychographic': {
                'lifestyle': ['urban_professional', 'family_oriented', 'adventure_seeker', 'homebody'],
                'interests': ['technology', 'fashion', 'sports', 'travel', 'food', 'books'],
                'values': ['quality', 'price', 'convenience', 'brand', 'sustainability'],
                'shopping_style': ['impulse', 'research', 'deal_hunter', 'brand_loyal'],
                'media_consumption': ['social_media', 'traditional_media', 'online_news', 'blogs']
            }
        }
    
    def generate_dynamic_tags(self, user_profile):
        """ç”ŸæˆåŠ¨æ€æ ‡ç­¾"""
        dynamic_tags = []
        
        # åŸºäºRFMæ¨¡å‹ç”Ÿæˆæ ‡ç­¾
        rfm_score = self._calculate_rfm_score(user_profile)
        dynamic_tags.extend(self._rfm_tags(rfm_score))
        
        # åŸºäºè¡Œä¸ºæ¨¡å¼ç”Ÿæˆæ ‡ç­¾
        behavioral_score = self._calculate_behavioral_score(user_profile)
        dynamic_tags.extend(self._behavioral_tags(behavioral_score))
        
        # åŸºäºç”Ÿå‘½å‘¨æœŸç”Ÿæˆæ ‡ç­¾
        lifecycle_stage = self._determine_lifecycle_stage(user_profile)
        dynamic_tags.append(f'lifecycle_{lifecycle_stage}')
        
        return dynamic_tags
    
    def _calculate_rfm_score(self, user_profile):
        """è®¡ç®—RFMåˆ†æ•°"""
        recency = user_profile['transactional']['days_since_last_purchase']
        frequency = user_profile['transactional']['purchase_frequency']
        monetary = user_profile['transactional']['avg_order_value']
        
        # æ ‡å‡†åŒ–è¯„åˆ†ï¼ˆ1-5åˆ†ï¼‰
        r_score = self._score_recency(recency)
        f_score = self._score_frequency(frequency)
        m_score = self._score_monetary(monetary)
        
        return {'recency': r_score, 'frequency': f_score, 'monetary': m_score}
```

### Q6: ç”¨æˆ·åˆ†ç¾¤ä¸ç»†åˆ†ï¼Ÿ
**ç­”ï¼š** ç”¨æˆ·åˆ†ç¾¤æ˜¯å®ç°ç²¾å‡†è¥é”€çš„åŸºç¡€ï¼š

**èšç±»åˆ†æç®—æ³•**ï¼š
```python
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

class UserSegmentation:
    def __init__(self):
        self.scaler = StandardScaler()
        self.clustering_model = None
    
    def segment_users(self, user_features, n_clusters=5):
        """ç”¨æˆ·åˆ†ç¾¤"""
        # æ•°æ®æ ‡å‡†åŒ–
        scaled_features = self.scaler.fit_transform(user_features)
        
        # K-meansèšç±»
        self.clustering_model = KMeans(n_clusters=n_clusters, random_state=42)
        cluster_labels = self.clustering_model.fit_predict(scaled_features)
        
        # åˆ†æå„ç¾¤ä½“ç‰¹å¾
        segments = self._analyze_segments(user_features, cluster_labels)
        
        return {
            'cluster_labels': cluster_labels,
            'segments': segments,
            'model': self.clustering_model
        }
    
    def _analyze_segments(self, features, labels):
        """åˆ†æå„ç¾¤ä½“ç‰¹å¾"""
        segments = {}
        unique_labels = np.unique(labels)
        
        for label in unique_labels:
            segment_indices = np.where(labels == label)[0]
            segment_features = features[segment_indices]
            
            segments[f'segment_{label}'] = {
                'size': len(segment_indices),
                'percentage': len(segment_indices) / len(features) * 100,
                'characteristics': self._extract_characteristics(segment_features),
                'marketing_strategy': self._suggest_marketing_strategy(label)
            }
        
        return segments
    
    def _extract_characteristics(self, segment_features):
        """æå–ç¾¤ä½“ç‰¹å¾"""
        characteristics = {}
        
        # è®¡ç®—å„é¡¹æŒ‡æ ‡çš„å‡å€¼å’Œæ ‡å‡†å·®
        means = np.mean(segment_features, axis=0)
        stds = np.std(segment_features, axis=0)
        
        characteristics['avg_values'] = means.tolist()
        characteristics['std_deviation'] = stds.tolist()
        characteristics['feature_importance'] = self._calculate_feature_importance(segment_features)
        
        return characteristics
    
    def predict_segment(self, new_user_features):
        """é¢„æµ‹æ–°ç”¨æˆ·æ‰€å±ç¾¤ä½“"""
        if self.clustering_model is None:
            raise ValueError("Clustering model not trained yet")
        
        scaled_features = self.scaler.transform([new_user_features])
        predicted_cluster = self.clustering_model.predict(scaled_features)[0]
        
        return predicted_cluster
```

## 3. ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿ

### Q7: æ¨èç®—æ³•åŸç†ä¸å®ç°ï¼Ÿ
**ç­”ï¼š** ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿçš„æ ¸å¿ƒç®—æ³•åŒ…æ‹¬ï¼š

**ååŒè¿‡æ»¤ç®—æ³•**ï¼š
```python
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

class CollaborativeFiltering:
    def __init__(self):
        self.user_item_matrix = None
        self.item_similarity_matrix = None
    
    def build_user_item_matrix(self, interactions):
        """æ„å»ºç”¨æˆ·-ç‰©å“äº¤äº’çŸ©é˜µ"""
        users = list(set(interaction['user_id'] for interaction in interactions))
        items = list(set(interaction['item_id'] for interaction in interactions))
        
        # åˆ›å»ºç”¨æˆ·å’Œç‰©å“çš„ç´¢å¼•æ˜ å°„
        user_to_idx = {user: idx for idx, user in enumerate(users)}
        item_to_idx = {item: idx for idx, item in enumerate(items)}
        
        # åˆå§‹åŒ–çŸ©é˜µ
        matrix = np.zeros((len(users), len(items)))
        
        # å¡«å……äº¤äº’æ•°æ®
        for interaction in interactions:
            user_idx = user_to_idx[interaction['user_id']]
            item_idx = item_to_idx[interaction['item_id']]
            matrix[user_idx][item_idx] = interaction['rating']
        
        self.user_item_matrix = matrix
        self.user_to_idx = user_to_idx
        self.item_to_idx = item_to_idx
        self.idx_to_user = {idx: user for user, idx in user_to_idx.items()}
        self.idx_to_item = {idx: item for item, idx in item_to_idx.items()}
        
        return matrix
    
    def compute_item_similarity(self):
        """è®¡ç®—ç‰©å“ç›¸ä¼¼åº¦çŸ©é˜µ"""
        if self.user_item_matrix is None:
            raise ValueError("User-item matrix not built yet")
        
        # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—ç‰©å“é—´ç›¸ä¼¼åº¦
        self.item_similarity_matrix = cosine_similarity(self.user_item_matrix.T)
        
        return self.item_similarity_matrix
    
    def recommend_items_user_based(self, user_id, n_recommendations=10):
        """åŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤æ¨è"""
        if user_id not in self.user_to_idx:
            return []
        
        user_idx = self.user_to_idx[user_id]
        user_ratings = self.user_item_matrix[user_idx]
        
        # æ‰¾åˆ°ç›¸ä¼¼ç”¨æˆ·
        user_similarities = cosine_similarity([user_ratings], self.user_item_matrix)[0]
        
        # é¢„æµ‹è¯„åˆ†
        predicted_ratings = np.zeros(self.user_item_matrix.shape[1])
        
        for item_idx in range(self.user_item_matrix.shape[1]):
            if user_ratings[item_idx] == 0:  # ç”¨æˆ·æœªè¯„åˆ†çš„ç‰©å“
                weighted_sum = 0
                similarity_sum = 0
                
                for other_user_idx in range(self.user_item_matrix.shape[0]):
                    if other_user_idx != user_idx and self.user_item_matrix[other_user_idx][item_idx] > 0:
                        similarity = user_similarities[other_user_idx]
                        rating = self.user_item_matrix[other_user_idx][item_idx]
                        weighted_sum += similarity * rating
                        similarity_sum += abs(similarity)
                
                if similarity_sum > 0:
                    predicted_ratings[item_idx] = weighted_sum / similarity_sum
        
        # è·å–æ¨èç‰©å“
        recommended_items = []
        top_indices = np.argsort(predicted_ratings)[::-1][:n_recommendations]
        
        for idx in top_indices:
            if predicted_ratings[idx] > 0:
                recommended_items.append({
                    'item_id': self.idx_to_item[idx],
                    'predicted_rating': predicted_ratings[idx]
                })
        
        return recommended_items
```

**å†…å®¹æ¨èç®—æ³•**ï¼š
```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel

class ContentBasedRecommender:
    def __init__(self):
        self.tfidf_vectorizer = TfidfVectorizer(stop_words='english')
        self.item_profiles = None
        self.item_similarity_matrix = None
    
    def build_item_profiles(self, items):
        """æ„å»ºç‰©å“å†…å®¹ç”»åƒ"""
        # åˆå¹¶ç‰©å“çš„å„ç§æ–‡æœ¬ç‰¹å¾
        item_descriptions = []
        for item in items:
            description = f"{item.get('title', '')} {item.get('description', '')} "
            description += ' '.join(item.get('categories', [])) + ' '
            description += ' '.join(item.get('tags', []))
            item_descriptions.append(description)
        
        # è®¡ç®—TF-IDFå‘é‡
        tfidf_matrix = self.tfidf_vectorizer.fit_transform(item_descriptions)
        
        self.item_profiles = tfidf_matrix
        self.items = items
        self.item_ids = [item['id'] for item in items]
        
        return tfidf_matrix
    
    def compute_item_similarity(self):
        """è®¡ç®—ç‰©å“ç›¸ä¼¼åº¦"""
        if self.item_profiles is None:
            raise ValueError("Item profiles not built yet")
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        self.item_similarity_matrix = linear_kernel(self.item_profiles, self.item_profiles)
        
        return self.item_similarity_matrix
    
    def recommend_items(self, item_id, n_recommendations=10):
        """åŸºäºå†…å®¹çš„æ¨è"""
        if item_id not in self.item_ids:
            return []
        
        # æ‰¾åˆ°ç‰©å“ç´¢å¼•
        item_idx = self.item_ids.index(item_id)
        
        # è·å–ç›¸ä¼¼åº¦åˆ†æ•°
        similarity_scores = list(enumerate(self.item_similarity_matrix[item_idx]))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)
        
        # è·å–æ¨èç‰©å“
        recommendations = []
        for i, (idx, score) in enumerate(similarity_scores[1:n_recommendations+1]):  # è·³è¿‡è‡ªå·±
            if score > 0:
                recommendations.append({
                    'item_id': self.item_ids[idx],
                    'similarity_score': score,
                    'item_info': self.items[idx]
                })
        
        return recommendations
```

### Q8: å®æ—¶æ¨èå¼•æ“ï¼Ÿ
**ç­”ï¼š** å®æ—¶æ¨èå¼•æ“éœ€è¦å¿«é€Ÿå“åº”ç”¨æˆ·è¡Œä¸ºå˜åŒ–ï¼š

**å®æ—¶æ¨èç³»ç»Ÿæ¶æ„**ï¼š
```python
import redis
import json
from datetime import datetime, timedelta

class RealTimeRecommender:
    def __init__(self, redis_client):
        self.redis = redis_client
        self.cf_recommender = CollaborativeFiltering()
        self.content_recommender = ContentBasedRecommender()
    
    def update_user_behavior(self, user_id, item_id, action, timestamp=None):
        """æ›´æ–°ç”¨æˆ·è¡Œä¸ºæ•°æ®"""
        if timestamp is None:
            timestamp = datetime.now().isoformat()
        
        # å­˜å‚¨ç”¨æˆ·æœ€è¿‘è¡Œä¸º
        behavior_key = f"user:{user_id}:recent_behaviors"
        behavior_data = {
            'item_id': item_id,
            'action': action,
            'timestamp': timestamp
        }
        
        # ä½¿ç”¨Redisåˆ—è¡¨å­˜å‚¨æœ€è¿‘100ä¸ªè¡Œä¸º
        self.redis.lpush(behavior_key, json.dumps(behavior_data))
        self.redis.ltrim(behavior_key, 0, 99)
        
        # æ›´æ–°ç”¨æˆ·å…´è¶£æ ‡ç­¾
        self._update_user_interests(user_id, item_id, action)
        
        # è§¦å‘å®æ—¶æ¨èè®¡ç®—
        self._trigger_real_time_recommendations(user_id)
    
    def _update_user_interests(self, user_id, item_id, action):
        """æ›´æ–°ç”¨æˆ·å…´è¶£æ ‡ç­¾"""
        # è·å–ç‰©å“æ ‡ç­¾
        item_tags = self._get_item_tags(item_id)
        
        # æ ¹æ®è¡Œä¸ºç±»å‹è°ƒæ•´æƒé‡
        weight_multiplier = {
            'view': 1.0,
            'click': 1.5,
            'purchase': 2.0,
            'favorite': 1.8,
            'share': 1.7
        }.get(action, 1.0)
        
        # æ›´æ–°ç”¨æˆ·æ ‡ç­¾æƒé‡
        for tag in item_tags:
            tag_key = f"user:{user_id}:tag_weights:{tag}"
            current_weight = float(self.redis.get(tag_key) or 0)
            new_weight = current_weight + (1 * weight_multiplier)
            self.redis.set(tag_key, new_weight)
    
    def get_real_time_recommendations(self, user_id, n_recommendations=10):
        """è·å–å®æ—¶æ¨è"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"user:{user_id}:recommendations"
        cached_recommendations = self.redis.get(cache_key)
        
        if cached_recommendations:
            return json.loads(cached_recommendations)
        
        # è®¡ç®—å®æ—¶æ¨è
        recommendations = self._compute_real_time_recommendations(user_id, n_recommendations)
        
        # ç¼“å­˜ç»“æœï¼ˆ5åˆ†é’Ÿè¿‡æœŸï¼‰
        self.redis.setex(cache_key, 300, json.dumps(recommendations))
        
        return recommendations
    
    def _compute_real_time_recommendations(self, user_id, n_recommendations):
        """è®¡ç®—å®æ—¶æ¨è"""
        # 1. åŸºäºç”¨æˆ·æœ€è¿‘è¡Œä¸ºæ¨è
        recent_items = self._get_recent_interacted_items(user_id, 5)
        
        # 2. åŸºäºç”¨æˆ·å…´è¶£æ ‡ç­¾æ¨è
        interest_based_items = self._get_interest_based_recommendations(user_id, 5)
        
        # 3. åŸºäºçƒ­é—¨ç‰©å“æ¨è
        trending_items = self._get_trending_items(5)
        
        # 4. æ··åˆæ¨èç»“æœ
        recommendations = self._merge_recommendations([
            recent_items,
            interest_based_items,
            trending_items
        ], n_recommendations)
        
        return recommendations
    
    def _get_recent_interacted_items(self, user_id, limit):
        """è·å–æœ€è¿‘äº¤äº’çš„ç‰©å“"""
        behavior_key = f"user:{user_id}:recent_behaviors"
        recent_behaviors = self.redis.lrange(behavior_key, 0, limit-1)
        
        item_ids = []
        for behavior_json in recent_behaviors:
            behavior = json.loads(behavior_json)
            # åŸºäºæœ€è¿‘äº¤äº’çš„ç‰©å“æ¨èç›¸ä¼¼ç‰©å“
            similar_items = self.content_recommender.recommend_items(
                behavior['item_id'], 3
            )
            item_ids.extend([item['item_id'] for item in similar_items])
        
        return list(set(item_ids))[:limit]
    
    def _get_interest_based_recommendations(self, user_id, limit):
        """åŸºäºå…´è¶£çš„æ¨è"""
        # è·å–ç”¨æˆ·æ ‡ç­¾æƒé‡
        tag_pattern = f"user:{user_id}:tag_weights:*"
        tag_keys = self.redis.keys(tag_pattern)
        
        weighted_items = {}
        
        for tag_key in tag_keys:
            tag = tag_key.split(':')[-1]
            weight = float(self.redis.get(tag_key) or 0)
            
            # è·å–å…·æœ‰è¯¥æ ‡ç­¾çš„çƒ­é—¨ç‰©å“
            items_with_tag = self._get_items_by_tag(tag, 10)
            
            for item_id in items_with_tag:
                if item_id not in weighted_items:
                    weighted_items[item_id] = 0
                weighted_items[item_id] += weight
        
        # æŒ‰æƒé‡æ’åº
        sorted_items = sorted(weighted_items.items(), key=lambda x: x[1], reverse=True)
        
        return [item_id for item_id, weight in sorted_items[:limit]]
```

## 4. ç²¾å‡†è¥é”€æŠ•æ”¾

### Q9: ç¨‹åºåŒ–å¹¿å‘ŠæŠ•æ”¾ç³»ç»Ÿï¼Ÿ
**ç­”ï¼š** ç¨‹åºåŒ–å¹¿å‘ŠæŠ•æ”¾ç³»ç»Ÿå®ç°è‡ªåŠ¨åŒ–ç«ä»·å’ŒæŠ•æ”¾ï¼š

**RTBï¼ˆå®æ—¶ç«ä»·ï¼‰ç³»ç»Ÿ**ï¼š
```python
import uuid
from datetime import datetime
from dataclasses import dataclass

@dataclass
class BidRequest:
    auction_id: str
    user_id: str
    device_info: dict
    geo_info: dict
    ad_slot: dict
    timestamp: datetime

@dataclass
class BidResponse:
    auction_id: str
    bid_price: float
    ad_creative: str
    targeting_criteria: dict
    win_notice_url: str

class ProgrammaticAdPlatform:
    def __init__(self):
        self.bidder = RealTimeBidder()
        self.campaign_manager = CampaignManager()
        self.user_profiler = UserProfileBuilder()
        self.ad_server = AdServer()
    
    def handle_bid_request(self, bid_request: BidRequest) -> BidResponse:
        """å¤„ç†ç«ä»·è¯·æ±‚"""
        # 1. ç”¨æˆ·ç”»åƒåˆ†æ
        user_profile = self.user_profiler.get_user_profile(bid_request.user_id)
        
        # 2. åŒ¹é…æ´»è·ƒå¹¿å‘Šæ´»åŠ¨
        active_campaigns = self.campaign_manager.get_active_campaigns(
            bid_request.ad_slot, user_profile
        )
        
        if not active_campaigns:
            return None  # æ— åŒ¹é…å¹¿å‘Š
        
        # 3. è®¡ç®—ç«ä»·ä»·æ ¼
        winning_campaign = self._select_winning_campaign(
            active_campaigns, user_profile, bid_request
        )
        
        if not winning_campaign:
            return None
        
        # 4. ç”Ÿæˆç«ä»·å“åº”
        bid_response = BidResponse(
            auction_id=bid_request.auction_id,
            bid_price=self._calculate_bid_price(winning_campaign, user_profile),
            ad_creative=winning_campaign.creative_id,
            targeting_criteria=winning_campaign.targeting,
            win_notice_url=f"/win_notice/{uuid.uuid4()}"
        )
        
        return bid_response
    
    def _select_winning_campaign(self, campaigns, user_profile, bid_request):
        """é€‰æ‹©è·èƒœå¹¿å‘Šæ´»åŠ¨"""
        campaign_scores = []
        
        for campaign in campaigns:
            # è®¡ç®—åŒ¹é…åº¦åˆ†æ•°
            relevance_score = self._calculate_relevance_score(
                campaign.targeting, user_profile, bid_request
            )
            
            # è®¡ç®—é¢„ç®—å……è¶³åº¦
            budget_score = self._calculate_budget_score(campaign)
            
            # è®¡ç®—å†å²è¡¨ç°
            performance_score = self._calculate_performance_score(campaign)
            
            # ç»¼åˆè¯„åˆ†
            total_score = (
                relevance_score * 0.5 +
                budget_score * 0.3 +
                performance_score * 0.2
            )
            
            campaign_scores.append((campaign, total_score))
        
        # é€‰æ‹©æœ€é«˜åˆ†çš„å¹¿å‘Šæ´»åŠ¨
        if campaign_scores:
            return max(campaign_scores, key=lambda x: x[1])[0]
        
        return None
    
    def _calculate_bid_price(self, campaign, user_profile):
        """è®¡ç®—ç«ä»·ä»·æ ¼"""
        # åŸºç¡€å‡ºä»·
        base_bid = campaign.base_bid
        
        # ç”¨æˆ·ä»·å€¼è°ƒæ•´
        user_value_multiplier = self._calculate_user_value(user_profile)
        
        # æ—¶é—´å› ç´ è°ƒæ•´
        time_multiplier = self._calculate_time_factor()
        
        # ç«äº‰å¯¹æ‰‹åˆ†æè°ƒæ•´
        competition_multiplier = self._analyze_competition(campaign)
        
        final_bid = base_bid * user_value_multiplier * time_multiplier * competition_multiplier
        
        # ç¡®ä¿ä¸è¶…è¿‡é¢„ç®—é™åˆ¶
        return min(final_bid, campaign.daily_budget_remaining / 1000)
    
    def handle_win_notification(self, auction_id, winning_price):
        """å¤„ç†ç«ä»·è·èƒœé€šçŸ¥"""
        # è®°å½•èŠ±è´¹
        self.campaign_manager.record_spend(auction_id, winning_price)
        
        # æ›´æ–°ç»Ÿè®¡æ•°æ®
        self._update_campaign_stats(auction_id, winning_price)
        
        # è§¦å‘å¹¿å‘Šå±•ç¤º
        self.ad_server.serve_ad(auction_id)
```

### Q10: å¤šæ¸ é“ååŒè¥é”€ï¼Ÿ
**ç­”ï¼š** å¤šæ¸ é“ååŒè¥é”€å®ç°å…¨è§¦ç‚¹ç”¨æˆ·è¦†ç›–ï¼š

**è·¨æ¸ é“è¥é”€ç¼–æ’**ï¼š
```python
from enum import Enum
from datetime import datetime, timedelta

class ChannelType(Enum):
    EMAIL = "email"
    SMS = "sms"
    PUSH_NOTIFICATION = "push"
    WECHAT = "wechat"
    DISPLAY_AD = "display_ad"
    SOCIAL_MEDIA = "social_media"

class CrossChannelOrchestrator:
    def __init__(self):
        self.channels = {
            ChannelType.EMAIL: EmailChannel(),
            ChannelType.SMS: SMSChannel(),
            ChannelType.PUSH_NOTIFICATION: PushNotificationChannel(),
            ChannelType.WECHAT: WeChatChannel(),
            ChannelType.DISPLAY_AD: DisplayAdChannel(),
            ChannelType.SOCIAL_MEDIA: SocialMediaChannel()
        }
        self.journey_manager = CustomerJourneyManager()
    
    def create_marketing_journey(self, user_id, campaign_goal, channels_sequence=None):
        """åˆ›å»ºè·¨æ¸ é“è¥é”€æ—…ç¨‹"""
        if channels_sequence is None:
            # åŸºäºç”¨æˆ·åå¥½å’Œè¡Œä¸ºè‡ªåŠ¨é€‰æ‹©æ¸ é“
            channels_sequence = self._optimize_channel_sequence(user_id, campaign_goal)
        
        journey = {
            'journey_id': str(uuid.uuid4()),
            'user_id': user_id,
            'goal': campaign_goal,
            'channels': channels_sequence,
            'created_at': datetime.now(),
            'status': 'planned',
            'executed_steps': []
        }
        
        # ä¿å­˜æ—…ç¨‹é…ç½®
        self.journey_manager.save_journey(journey)
        
        return journey
    
    def execute_journey_step(self, journey_id, step_index):
        """æ‰§è¡Œæ—…ç¨‹æ­¥éª¤"""
        journey = self.journey_manager.get_journey(journey_id)
        if not journey or step_index >= len(journey['channels']):
            return False
        
        channel_type = journey['channels'][step_index]
        channel = self.channels.get(channel_type)
        
        if not channel:
            return False
        
        # ä¸ªæ€§åŒ–å†…å®¹ç”Ÿæˆ
        personalized_content = self._generate_personalized_content(
            journey['user_id'], channel_type, journey['goal']
        )
        
        # å‘é€æ¶ˆæ¯
        send_result = channel.send_message(
            journey['user_id'], 
            personalized_content,
            journey_id
        )
        
        # è®°å½•æ‰§è¡Œç»“æœ
        execution_record = {
            'step_index': step_index,
            'channel': channel_type,
            'sent_at': datetime.now(),
            'result': send_result,
            'content_preview': personalized_content.get('subject', '')[:50]
        }
        
        self.journey_manager.record_step_execution(journey_id, execution_record)
        
        return send_result.get('success', False)
    
    def _optimize_channel_sequence(self, user_id, campaign_goal):
        """ä¼˜åŒ–æ¸ é“åºåˆ—"""
        user_profile = self._get_user_profile(user_id)
        
        # åŸºäºç”¨æˆ·åå¥½æ’åºæ¸ é“
        channel_preferences = user_profile.get('channel_preferences', {})
        
        # åŸºäºè¥é”€ç›®æ ‡é€‰æ‹©æ¸ é“
        goal_based_channels = self._channels_for_goal(campaign_goal)
        
        # ç»“åˆç”¨æˆ·åå¥½å’Œç›®æ ‡éœ€æ±‚æ’åº
        weighted_channels = []
        for channel in goal_based_channels:
            preference_score = channel_preferences.get(channel.value, 0.5)
            goal_relevance = self._channel_goal_relevance(channel, campaign_goal)
            
            total_score = preference_score * 0.6 + goal_relevance * 0.4
            weighted_channels.append((channel, total_score))
        
        # æŒ‰åˆ†æ•°æ’åº
        sorted_channels = sorted(weighted_channels, key=lambda x: x[1], reverse=True)
        
        return [channel for channel, score in sorted_channels]
    
    def _generate_personalized_content(self, user_id, channel_type, goal):
        """ç”Ÿæˆä¸ªæ€§åŒ–å†…å®¹"""
        user_profile = self._get_user_profile(user_id)
        
        content_templates = {
            ChannelType.EMAIL: self._email_template,
            ChannelType.SMS: self._sms_template,
            ChannelType.PUSH_NOTIFICATION: self._push_template,
            ChannelType.WECHAT: self._wechat_template
        }
        
        template_func = content_templates.get(channel_type)
        if template_func:
            return template_func(user_profile, goal)
        else:
            return {'message': 'Hello!'}
    
    def _email_template(self, user_profile, goal):
        """é‚®ä»¶æ¨¡æ¿"""
        user_name = user_profile.get('basic_info', {}).get('name', 'ç”¨æˆ·')
        
        if goal == 're_engagement':
            subject = f"{user_name}ï¼Œæˆ‘ä»¬æƒ³å¿µæ‚¨ï¼å›æ¥äº«å—ä¸“å±ä¼˜æƒ "
            body = f"""
            äº²çˆ±çš„{user_name}ï¼Œ
            
            å¾ˆä¹…æ²¡è§åˆ°æ‚¨äº†ï¼Œæˆ‘ä»¬ä¸ºæ‚¨å‡†å¤‡äº†ä¸“å±å›å½’ç¤¼åŒ…ï¼
            
            ğŸ”¥ é™æ—¶ä¼˜æƒ ï¼šå…¨åœºå•†å“8æŠ˜
            ğŸ ä¸“å±ç¤¼å“ï¼šä»·å€¼100å…ƒä¼˜æƒ åˆ¸
            ğŸš€ å…è´¹é…é€ï¼šè®¢å•æ»¡299å…ƒåŒ…é‚®
            
            ç‚¹å‡»ä¸‹æ–¹é“¾æ¥ç«‹å³æŸ¥çœ‹ï¼š
            [ç«‹å³æŸ¥çœ‹ä¼˜æƒ ](https://example.com/offer)
            
            æœŸå¾…æ‚¨çš„å›å½’ï¼
            """
        elif goal == 'upsell':
            subject = f"{user_name}ï¼Œä¸ºæ‚¨æ¨èæ–°å“"
            body = f"""
            äº²çˆ±çš„{user_name}ï¼Œ
            
            æ ¹æ®æ‚¨çš„æµè§ˆè®°å½•ï¼Œæˆ‘ä»¬ä¸ºæ‚¨ç²¾é€‰äº†å‡ æ¬¾æ–°å“ï¼š
            
            ğŸŒŸ çƒ­é—¨æ¨è
            - [äº§å“A](https://example.com/product-a)
            - [äº§å“B](https://example.com/product-b)
            
            ä¸“å±ä¼˜æƒ ï¼šæ–°å“é¦–è´­ç«‹å‡50å…ƒï¼
            
            [ç«‹å³æŸ¥çœ‹](https://example.com/new-arrivals)
            """
        else:
            subject = "ä¸ºæ‚¨ç²¾å¿ƒæŒ‘é€‰çš„å†…å®¹"
            body = "æ„Ÿè°¢æ‚¨çš„å…³æ³¨ï¼"
        
        return {
            'subject': subject,
            'body': body,
            'personalization_tags': ['user_name', 'recommendations']
        }
```

## 5. è¥é”€è‡ªåŠ¨åŒ–

### Q11: è¥é”€å·¥ä½œæµå¼•æ“ï¼Ÿ
**ç­”ï¼š** è¥é”€å·¥ä½œæµå¼•æ“å®ç°è¥é”€æ´»åŠ¨çš„è‡ªåŠ¨åŒ–æ‰§è¡Œï¼š

**å¯è§†åŒ–å·¥ä½œæµè®¾è®¡å™¨**ï¼š
```python
from abc import ABC, abstractmethod
from typing import Dict, List, Any
import json

class WorkflowNode(ABC):
    """å·¥ä½œæµèŠ‚ç‚¹åŸºç±»"""
    def __init__(self, node_id: str, name: str, config: Dict[str, Any]):
        self.node_id = node_id
        self.name = name
        self.config = config
        self.next_nodes = []
    
    @abstractmethod
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        pass
    
    def add_next_node(self, node):
        self.next_nodes.append(node)

class TriggerNode(WorkflowNode):
    """è§¦å‘å™¨èŠ‚ç‚¹"""
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        trigger_type = self.config.get('trigger_type')
        trigger_condition = self.config.get('condition')
        
        # æ£€æŸ¥è§¦å‘æ¡ä»¶
        if self._check_trigger_condition(trigger_type, trigger_condition, context):
            return {'triggered': True, 'next_nodes': self.next_nodes}
        else:
            return {'triggered': False, 'next_nodes': []}
    
    def _check_trigger_condition(self, trigger_type: str, condition: Dict, context: Dict) -> bool:
        if trigger_type == 'user_behavior':
            user_id = context.get('user_id')
            behavior = context.get('behavior', {})
            
            # æ£€æŸ¥ç”¨æˆ·è¡Œä¸ºæ˜¯å¦ç¬¦åˆæ¡ä»¶
            return self._match_behavior_condition(behavior, condition)
        elif trigger_type == 'scheduled':
            current_time = datetime.now()
            scheduled_time = condition.get('time')
            
            # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾é¢„å®šæ—¶é—´
            return self._is_scheduled_time(current_time, scheduled_time)
        elif trigger_type == 'data_threshold':
            data_value = context.get('data_value', 0)
            threshold = condition.get('threshold', 0)
            operator = condition.get('operator', 'gt')
            
            # æ£€æŸ¥æ•°æ®é˜ˆå€¼æ¡ä»¶
            return self._compare_with_threshold(data_value, threshold, operator)
        
        return False

class ActionNode(WorkflowNode):
    """åŠ¨ä½œèŠ‚ç‚¹"""
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        action_type = self.config.get('action_type')
        action_params = self.config.get('params', {})
        
        # æ‰§è¡Œå…·ä½“åŠ¨ä½œ
        result = self._execute_action(action_type, action_params, context)
        
        return {
            'action_type': action_type,
            'result': result,
            'next_nodes': self.next_nodes
        }
    
    def _execute_action(self, action_type: str, params: Dict, context: Dict) -> Dict[str, Any]:
        if action_type == 'send_email':
            return self._send_email(params, context)
        elif action_type == 'send_sms':
            return self._send_sms(params, context)
        elif action_type == 'update_user_tag':
            return self._update_user_tag(params, context)
        elif action_type == 'assign_score':
            return self._assign_user_score(params, context)
        elif action_type == 'trigger_webhook':
            return self._trigger_webhook(params, context)
        else:
            return {'success': False, 'error': 'Unknown action type'}

class DecisionNode(WorkflowNode):
    """å†³ç­–èŠ‚ç‚¹"""
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        decision_rules = self.config.get('rules', [])
        default_branch = self.config.get('default_branch')
        
        # è¯„ä¼°å†³ç­–è§„åˆ™
        matched_branch = self._evaluate_decision_rules(decision_rules, context)
        
        if matched_branch:
            next_node = self._get_node_by_branch(matched_branch)
            return {'decision': matched_branch, 'next_nodes': [next_node] if next_node else []}
        else:
            # ä½¿ç”¨é»˜è®¤åˆ†æ”¯
            default_node = self._get_node_by_branch(default_branch)
            return {'decision': 'default', 'next_nodes': [default_node] if default_node else []}
    
    def _evaluate_decision_rules(self, rules: List[Dict], context: Dict) -> str:
        for rule in rules:
            condition = rule.get('condition')
            branch = rule.get('branch')
            
            if self._evaluate_condition(condition, context):
                return branch
        
        return None

class MarketingWorkflowEngine:
    """è¥é”€å·¥ä½œæµå¼•æ“"""
    def __init__(self):
        self.workflows = {}
        self.node_types = {
            'trigger': TriggerNode,
            'action': ActionNode,
            'decision': DecisionNode
        }
    
    def create_workflow(self, workflow_definition: Dict) -> str:
        """åˆ›å»ºå·¥ä½œæµ"""
        workflow_id = workflow_definition.get('id', str(uuid.uuid4()))
        
        # è§£æèŠ‚ç‚¹å®šä¹‰
        nodes = {}
        for node_def in workflow_definition.get('nodes', []):
            node_type = node_def.get('type')
            node_class = self.node_types.get(node_type)
            
            if node_class:
                node = node_class(
                    node_def.get('id'),
                    node_def.get('name'),
                    node_def.get('config', {})
                )
                nodes[node.node_id] = node
        
        # å»ºç«‹èŠ‚ç‚¹è¿æ¥å…³ç³»
        for connection in workflow_definition.get('connections', []):
            from_node_id = connection.get('from')
            to_node_id = connection.get('to')
            
            if from_node_id in nodes and to_node_id in nodes:
                nodes[from_node_id].add_next_node(nodes[to_node_id])
        
        self.workflows[workflow_id] = {
            'definition': workflow_definition,
            'nodes': nodes,
            'status': 'active'
        }
        
        return workflow_id
    
    def execute_workflow(self, workflow_id: str, trigger_context: Dict[str, Any]):
        """æ‰§è¡Œå·¥ä½œæµ"""
        workflow = self.workflows.get(workflow_id)
        if not workflow:
            raise ValueError(f"Workflow {workflow_id} not found")
        
        if workflow['status'] != 'active':
            raise ValueError(f"Workflow {workflow_id} is not active")
        
        # ä»è§¦å‘å™¨èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
        start_nodes = self._find_start_nodes(workflow['nodes'])
        
        execution_context = {
            'workflow_id': workflow_id,
            'start_time': datetime.now(),
            'trigger_context': trigger_context,
            'execution_path': [],
            'variables': {}
        }
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰èµ·å§‹èŠ‚ç‚¹
        for start_node in start_nodes:
            self._execute_node(start_node, execution_context)
    
    def _execute_node(self, node: WorkflowNode, context: Dict[str, Any]):
        """æ‰§è¡Œå•ä¸ªèŠ‚ç‚¹"""
        try:
            # è®°å½•æ‰§è¡Œè·¯å¾„
            context['execution_path'].append({
                'node_id': node.node_id,
                'node_name': node.name,
                'start_time': datetime.now()
            })
            
            # æ‰§è¡ŒèŠ‚ç‚¹
            result = node.execute(context)
            
            # æ›´æ–°ç»“æŸæ—¶é—´
            context['execution_path'][-1]['end_time'] = datetime.now()
            context['execution_path'][-1]['result'] = result
            
            # æ‰§è¡Œåç»­èŠ‚ç‚¹
            for next_node in result.get('next_nodes', []):
                self._execute_node(next_node, context)
                
        except Exception as e:
            # è®°å½•é”™è¯¯å¹¶ç»§ç»­æ‰§è¡Œå…¶ä»–åˆ†æ”¯
            context['execution_path'][-1]['error'] = str(e)
            self._log_execution_error(node, context, e)
```

### Q12: æ™ºèƒ½å®¢æœä¸èŠå¤©æœºå™¨äººï¼Ÿ
**ç­”ï¼š** æ™ºèƒ½å®¢æœç³»ç»Ÿæå‡ç”¨æˆ·æœåŠ¡ä½“éªŒï¼š

**å¯¹è¯ç®¡ç†å¼•æ“**ï¼š
```python
import re
from typing import Dict, List, Tuple
from dataclasses import dataclass

@dataclass
class Intent:
    name: str
    confidence: float
    entities: Dict[str, str]

@dataclass
class DialogState:
    session_id: str
    current_intent: str
    entities: Dict[str, str]
    conversation_history: List[Dict]
    context_variables: Dict[str, Any]

class ChatbotEngine:
    def __init__(self):
        self.intent_classifier = IntentClassifier()
        self.entity_extractor = EntityExtractor()
        self.dialog_manager = DialogManager()
        self.response_generator = ResponseGenerator()
        self.session_store = SessionStore()
    
    def process_user_message(self, session_id: str, user_message: str) -> str:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
        # è·å–ä¼šè¯çŠ¶æ€
        dialog_state = self.session_store.get_session(session_id)
        if not dialog_state:
            dialog_state = DialogState(
                session_id=session_id,
                current_intent=None,
                entities={},
                conversation_history=[],
                context_variables={}
            )
        
        # æ„å›¾è¯†åˆ«
        intent = self.intent_classifier.classify(user_message)
        
        # å®ä½“æŠ½å–
        entities = self.entity_extractor.extract(user_message)
        
        # æ›´æ–°å¯¹è¯çŠ¶æ€
        dialog_state = self._update_dialog_state(
            dialog_state, intent, entities, user_message
        )
        
        # ç”Ÿæˆå›å¤
        response = self.response_generator.generate(
            intent, entities, dialog_state
        )
        
        # ä¿å­˜ä¼šè¯çŠ¶æ€
        self.session_store.save_session(dialog_state)
        
        return response
    
    def _update_dialog_state(self, state: DialogState, intent: Intent, 
                           entities: Dict[str, str], user_message: str) -> DialogState:
        """æ›´æ–°å¯¹è¯çŠ¶æ€"""
        # æ›´æ–°æ„å›¾
        if intent.confidence > 0.7:  # ç½®ä¿¡åº¦é˜ˆå€¼
            state.current_intent = intent.name
        
        # åˆå¹¶å®ä½“
        state.entities.update(entities)
        
        # æ›´æ–°å¯¹è¯å†å²
        state.conversation_history.append({
            'turn': len(state.conversation_history) + 1,
            'user_message': user_message,
            'intent': intent.name if intent.confidence > 0.7 else None,
            'entities': entities,
            'timestamp': datetime.now()
        })
        
        # æ›´æ–°ä¸Šä¸‹æ–‡å˜é‡
        state = self.dialog_manager.update_context(state, intent, entities)
        
        return state

class IntentClassifier:
    """æ„å›¾åˆ†ç±»å™¨"""
    def __init__(self):
        self.intents = {
            'greeting': [
                r'ä½ å¥½|æ‚¨å¥½|hi|hello|æ—©ä¸Šå¥½|ä¸‹åˆå¥½|æ™šä¸Šå¥½',
                r'åœ¨å—|æœ‰äººå—'
            ],
            'product_inquiry': [
                r'æˆ‘æƒ³äº†è§£.*äº§å“',
                r'.*äº§å“.*æ€ä¹ˆæ ·',
                r'æœ‰æ²¡æœ‰.*äº§å“',
                r'.*äº§å“çš„.*ä¿¡æ¯'
            ],
            'order_status': [
                r'æˆ‘çš„è®¢å•.*çŠ¶æ€',
                r'è®¢å•.*åˆ°å“ªäº†',
                r'æŸ¥è¯¢è®¢å•.*å·',
                r'ç‰©æµä¿¡æ¯'
            ],
            'complaint': [
                r'æŠ•è¯‰|ä¸æ»¡æ„|é—®é¢˜|åäº†|ä¸å¥½',
                r'é€€æ¬¾|é€€è´§',
                r'å®¢æœ.*åœ¨å“ªé‡Œ'
            ],
            'purchase': [
                r'æˆ‘è¦ä¹°|æˆ‘æƒ³ä¹°|è´­ä¹°|ä¸‹å•',
                r'ä»·æ ¼.*å¤šå°‘',
                r'æ€ä¹ˆä»˜æ¬¾'
            ]
        }
    
    def classify(self, message: str) -> Intent:
        """åˆ†ç±»ç”¨æˆ·æ„å›¾"""
        best_intent = None
        best_confidence = 0.0
        
        for intent_name, patterns in self.intents.items():
            for pattern in patterns:
                if re.search(pattern, message, re.IGNORECASE):
                    confidence = self._calculate_confidence(message, pattern)
                    if confidence > best_confidence:
                        best_confidence = confidence
                        best_intent = intent_name
        
        return Intent(
            name=best_intent or 'unknown',
            confidence=best_confidence,
            entities={}
        )
    
    def _calculate_confidence(self, message: str, pattern: str) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦"""
        # ç®€å•çš„ç½®ä¿¡åº¦è®¡ç®—
        match = re.search(pattern, message, re.IGNORECASE)
        if match:
            # åŒ¹é…æ–‡æœ¬è¶Šé•¿ï¼Œç½®ä¿¡åº¦è¶Šé«˜
            match_length = len(match.group())
            message_length = len(message)
            return min(match_length / message_length, 1.0)
        return 0.0

class ResponseGenerator:
    """å›å¤ç”Ÿæˆå™¨"""
    def __init__(self):
        self.responses = {
            'greeting': [
                "æ‚¨å¥½ï¼å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
                "æ‚¨å¥½ï¼Œæ¬¢è¿å’¨è¯¢ï¼è¯·é—®æ‚¨æƒ³äº†è§£ä»€ä¹ˆï¼Ÿ",
                "Hiï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ"
            ],
            'product_inquiry': [
                "å…³äº{product}äº§å“ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›è¯¦ç»†ä¿¡æ¯ã€‚è¯·é—®æ‚¨æƒ³äº†è§£äº§å“çš„å“ªäº›æ–¹é¢å‘¢ï¼Ÿ",
                "æˆ‘ä»¬æœ‰å¤šæ¬¾{product}äº§å“ï¼Œæ‚¨å…·ä½“æƒ³äº†è§£å“ªä¸€æ¬¾å‘¢ï¼Ÿ",
                "è®©æˆ‘ä¸ºæ‚¨ä»‹ç»ä¸€ä¸‹{product}äº§å“..."
            ],
            'order_status': [
                "è¯·æä¾›æ‚¨çš„è®¢å•å·ï¼Œæˆ‘æ¥å¸®æ‚¨æŸ¥è¯¢è®¢å•çŠ¶æ€ã€‚",
                "ä¸ºäº†æŸ¥è¯¢æ‚¨çš„è®¢å•ï¼Œè¯·å‘Šè¯‰æˆ‘è®¢å•å·ç ã€‚",
                "è¯·è¾“å…¥è®¢å•å·ï¼Œæˆ‘é©¬ä¸Šä¸ºæ‚¨æŸ¥è¯¢ç‰©æµä¿¡æ¯ã€‚"
            ],
            'complaint': [
                "éå¸¸æŠ±æ­‰ç»™æ‚¨å¸¦æ¥äº†ä¸ä¾¿ï¼Œæˆ‘ä¼šå°½åŠ›å¸®æ‚¨è§£å†³é—®é¢˜ã€‚",
                "å¾ˆæŠ±æ­‰å¬åˆ°æ‚¨é‡åˆ°äº†é—®é¢˜ï¼Œè¯·è¯¦ç»†æè¿°ä¸€ä¸‹æƒ…å†µã€‚",
                "æˆ‘ç†è§£æ‚¨çš„å›°æ‰°ï¼Œè®©æˆ‘ä»¬ä¸€èµ·æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚"
            ],
            'purchase': [
                "å¾ˆé«˜å…´æ‚¨æƒ³è¦è´­ä¹°æˆ‘ä»¬çš„äº§å“ï¼è¯·é—®æ‚¨æƒ³äº†è§£å“ªæ¬¾äº§å“å‘¢ï¼Ÿ",
                "æˆ‘ä»¬æœ‰å¾ˆå¤šä¼˜è´¨çš„äº§å“å¯ä¾›é€‰æ‹©ï¼Œæ‚¨æœ‰ç‰¹åˆ«æ„Ÿå…´è¶£çš„å•†å“å—ï¼Ÿ",
                "è´­ä¹°æµç¨‹å¾ˆç®€å•ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨è¯¦ç»†ä»‹ç»ã€‚"
            ],
            'unknown': [
                "æŠ±æ­‰ï¼Œæˆ‘ä¸å¤ªæ˜ç™½æ‚¨çš„æ„æ€ã€‚æ‚¨å¯ä»¥æ¢ä¸ªè¯´æ³•æˆ–è€…é—®æˆ‘å…¶ä»–é—®é¢˜ã€‚",
                "æˆ‘æ²¡æœ‰ç†è§£æ‚¨çš„é—®é¢˜ï¼Œèƒ½å¦è¯·æ‚¨å†è§£é‡Šå¾—æ¸…æ¥šä¸€äº›ï¼Ÿ",
                "è¿™ä¸ªé—®é¢˜æˆ‘æš‚æ—¶æ— æ³•å›ç­”ï¼Œå·²ç»è®°å½•ä¸‹æ¥ä¼šå°½å¿«å›å¤æ‚¨ã€‚"
            ]
        }
    
    def generate(self, intent: Intent, entities: Dict[str, str], 
                dialog_state: DialogState) -> str:
        """ç”Ÿæˆå›å¤"""
        intent_name = intent.name
        possible_responses = self.responses.get(intent_name, self.responses['unknown'])
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªå›å¤æ¨¡æ¿
        response_template = possible_responses[hash(str(dialog_state.session_id)) % len(possible_responses)]
        
        # æ›¿æ¢æ¨¡æ¿ä¸­çš„å˜é‡
        response = response_template
        for entity_name, entity_value in entities.items():
            response = response.replace(f'{{{entity_name}}}', entity_value)
        
        return response
```

## 6. æ•ˆæœä¼˜åŒ–ä¸A/Bæµ‹è¯•

### Q13: A/Bæµ‹è¯•æ¡†æ¶è®¾è®¡ï¼Ÿ
**ç­”ï¼š** A/Bæµ‹è¯•æ¡†æ¶å¸®åŠ©ä¼˜åŒ–è¥é”€æ•ˆæœï¼š

**å®éªŒç®¡ç†å¹³å°**ï¼š
```python
import hashlib
import random
from datetime import datetime
from typing import Dict, List, Any
from dataclasses import dataclass

@dataclass
class Experiment:
    id: str
    name: str
    description: str
    hypothesis: str
    variants: List[Dict[str, Any]]
    metrics: List[str]
    start_date: datetime
    end_date: datetime
    status: str  # draft, running, completed
    audience_allocation: Dict[str, float]  # variant_id: percentage

@dataclass
class ExperimentResult:
    experiment_id: str
    variant_results: Dict[str, Dict[str, Any]]
    statistical_significance: bool
    winner_variant: str
    confidence_interval: float

class ABTestingFramework:
    def __init__(self):
        self.experiments = {}
        self.event_tracker = EventTracker()
        self.statistics_calculator = StatisticsCalculator()
    
    def create_experiment(self, experiment_config: Dict) -> str:
        """åˆ›å»ºA/Bæµ‹è¯•å®éªŒ"""
        experiment_id = experiment_config.get('id', str(uuid.uuid4()))
        
        experiment = Experiment(
            id=experiment_id,
            name=experiment_config['name'],
            description=experiment_config.get('description', ''),
            hypothesis=experiment_config.get('hypothesis', ''),
            variants=experiment_config['variants'],
            metrics=experiment_config['metrics'],
            start_date=datetime.fromisoformat(experiment_config['start_date']),
            end_date=datetime.fromisoformat(experiment_config['end_date']),
            status='draft',
            audience_allocation=experiment_config.get('audience_allocation', {})
        )
        
        self.experiments[experiment_id] = experiment
        return experiment_id
    
    def start_experiment(self, experiment_id: str):
        """å¯åŠ¨å®éªŒ"""
        experiment = self.experiments.get(experiment_id)
        if not experiment:
            raise ValueError(f"Experiment {experiment_id} not found")
        
        if experiment.status != 'draft':
            raise ValueError(f"Experiment {experiment_id} is not in draft status")
        
        experiment.status = 'running'
        self._log_experiment_status_change(experiment_id, 'started')
    
    def assign_variant(self, experiment_id: str, user_id: str) -> str:
        """ä¸ºç”¨æˆ·åˆ†é…å®éªŒå˜ä½“"""
        experiment = self.experiments.get(experiment_id)
        if not experiment or experiment.status != 'running':
            return 'control'  # é»˜è®¤è¿”å›å¯¹ç…§ç»„
        
        # åŸºäºç”¨æˆ·IDå’Œå®éªŒIDç”Ÿæˆç¨³å®šçš„å“ˆå¸Œå€¼
        hash_input = f"{experiment_id}:{user_id}"
        hash_value = int(hashlib.md5(hash_input.encode()).hexdigest(), 16)
        percentage = (hash_value % 10000) / 100.0  # 0-100ä¹‹é—´çš„ç™¾åˆ†æ¯”
        
        # æ ¹æ®é¢„è®¾çš„åˆ†é…æ¯”ä¾‹åˆ†é…å˜ä½“
        cumulative_percentage = 0
        for variant_id, allocation in experiment.audience_allocation.items():
            cumulative_percentage += allocation
            if percentage <= cumulative_percentage:
                return variant_id
        
        return 'control'  # é»˜è®¤è¿”å›å¯¹ç…§ç»„
    
    def track_event(self, experiment_id: str, variant_id: str, 
                   user_id: str, event_name: str, event_properties: Dict = None):
        """è·Ÿè¸ªå®éªŒäº‹ä»¶"""
        self.event_tracker.track_event(
            experiment_id=experiment_id,
            variant_id=variant_id,
            user_id=user_id,
            event_name=event_name,
            event_properties=event_properties or {}
        )
    
    def analyze_experiment(self, experiment_id: str) -> ExperimentResult:
        """åˆ†æå®éªŒç»“æœ"""
        experiment = self.experiments.get(experiment_id)
        if not experiment:
            raise ValueError(f"Experiment {experiment_id} not found")
        
        if experiment.status != 'completed':
            raise ValueError(f"Experiment {experiment_id} is not completed yet")
        
        # è·å–å®éªŒæ•°æ®
        experiment_data = self.event_tracker.get_experiment_data(experiment_id)
        
        # è®¡ç®—å„å˜ä½“çš„æŒ‡æ ‡
        variant_results = {}
        for variant_id in experiment.audience_allocation.keys():
            variant_data = experiment_data.get(variant_id, {})
            variant_results[variant_id] = self._calculate_variant_metrics(
                variant_data, experiment.metrics
            )
        
        # ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
        significance_result = self.statistics_calculator.check_significance(
            variant_results, experiment.metrics
        )
        
        # ç¡®å®šè·èƒœå˜ä½“
        winner_variant = self._determine_winner(variant_results, experiment.metrics)
        
        result = ExperimentResult(
            experiment_id=experiment_id,
            variant_results=variant_results,
            statistical_significance=significance_result['significant'],
            winner_variant=winner_variant,
            confidence_interval=significance_result['confidence']
        )
        
        return result
    
    def _calculate_variant_metrics(self, variant_data: Dict, metrics: List[str]) -> Dict[str, Any]:
        """è®¡ç®—å˜ä½“æŒ‡æ ‡"""
        results = {}
        
        for metric in metrics:
            if metric == 'conversion_rate':
                conversions = len([e for e in variant_data.get('events', []) 
                                 if e['event_name'] == 'conversion'])
                total_visitors = len(set([e['user_id'] for e in variant_data.get('events', [])]))
                results[metric] = conversions / total_visitors if total_visitors > 0 else 0
            
            elif metric == 'revenue_per_visitor':
                total_revenue = sum([e.get('properties', {}).get('revenue', 0) 
                                   for e in variant_data.get('events', [])])
                total_visitors = len(set([e['user_id'] for e in variant_data.get('events', [])]))
                results[metric] = total_revenue / total_visitors if total_visitors > 0 else 0
            
            elif metric == 'click_through_rate':
                clicks = len([e for e in variant_data.get('events', []) 
                            if e['event_name'] == 'click'])
                impressions = len([e for e in variant_data.get('events', []) 
                                 if e['event_name'] == 'impression'])
                results[metric] = clicks / impressions if impressions > 0 else 0
        
        return results
    
    def _determine_winner(self, variant_results: Dict[str, Dict], metrics: List[str]) -> str:
        """ç¡®å®šè·èƒœå˜ä½“"""
        if not variant_results:
            return 'control'
        
        # å‡è®¾ç¬¬ä¸€ä¸ªæŒ‡æ ‡æ˜¯æœ€é‡è¦çš„ä¼˜åŒ–ç›®æ ‡
        primary_metric = metrics[0] if metrics else 'conversion_rate'
        
        best_variant = 'control'
        best_value = variant_results.get('control', {}).get(primary_metric, 0)
        
        for variant_id, metrics_dict in variant_results.items():
            value = metrics_dict.get(primary_metric, 0)
            if value > best_value:
                best_value = value
                best_variant = variant_id
        
        return best_variant

class StatisticsCalculator:
    """ç»Ÿè®¡è®¡ç®—å™¨"""
    def check_significance(self, variant_results: Dict[str, Dict], 
                          metrics: List[str]) -> Dict[str, Any]:
        """æ£€æŸ¥ç»Ÿè®¡æ˜¾è‘—æ€§"""
        if len(variant_results) < 2:
            return {'significant': False, 'confidence': 0.0}
        
        # ç®€åŒ–çš„æ˜¾è‘—æ€§æ£€éªŒï¼ˆå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨æ›´å¤æ‚çš„ç»Ÿè®¡æ–¹æ³•ï¼‰
        control_results = variant_results.get('control', {})
        variant_ids = [vid for vid in variant_results.keys() if vid != 'control']
        
        significant = False
        max_confidence = 0.0
        
        for variant_id in variant_ids:
            variant_results_data = variant_results.get(variant_id, {})
            
            # å¯¹æ¯ä¸ªæŒ‡æ ‡è¿›è¡Œæ£€éªŒ
            for metric in metrics:
                control_value = control_results.get(metric, 0)
                variant_value = variant_results_data.get(metric, 0)
                
                if control_value > 0:
                    improvement = (variant_value - control_value) / control_value
                    
                    # ç®€åŒ–çš„ç½®ä¿¡åº¦è®¡ç®—
                    confidence = self._calculate_simple_confidence(
                        improvement, control_value, variant_value
                    )
                    
                    if confidence > max_confidence:
                        max_confidence = confidence
                    
                    # å¦‚æœæ”¹å–„è¶…è¿‡5%ä¸”ç½®ä¿¡åº¦è¶…è¿‡90%ï¼Œè®¤ä¸ºæ˜¾è‘—
                    if improvement > 0.05 and confidence > 0.9:
                        significant = True
        
        return {
            'significant': significant,
            'confidence': max_confidence
        }
    
    def _calculate_simple_confidence(self, improvement: float, 
                                  control_value: float, variant_value: float) -> float:
        """ç®€åŒ–çš„ç½®ä¿¡åº¦è®¡ç®—"""
        # è¿™æ˜¯ä¸€ä¸ªéå¸¸ç®€åŒ–çš„å®ç°ï¼Œå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨ç»Ÿè®¡æ£€éªŒæ–¹æ³•
        # å¦‚tæ£€éªŒã€å¡æ–¹æ£€éªŒç­‰
        
        # åŸºäºæ”¹å–„å¹…åº¦å’ŒåŸºå‡†å€¼çš„ç®€å•ä¼°ç®—
        base_confidence = min(abs(improvement) * 10, 1.0)  # æ”¹å–„è¶Šå¤§ï¼Œç½®ä¿¡åº¦è¶Šé«˜
        value_confidence = min(control_value * 10, 1.0)    # åŸºå‡†å€¼è¶Šå¤§ï¼Œç½®ä¿¡åº¦è¶Šé«˜
        
        return (base_confidence + value_confidence) / 2
```

### Q14: å®æ—¶æ•ˆæœç›‘æ§ä¸ä¼˜åŒ–ï¼Ÿ
**ç­”ï¼š** å®æ—¶ç›‘æ§ç³»ç»Ÿç¡®ä¿è¥é”€æ´»åŠ¨æ•ˆæœå¯è§†åŒ–ï¼š

**å®æ—¶ç›‘æ§ä»ªè¡¨æ¿**ï¼š
```python
import asyncio
import websockets
from datetime import datetime, timedelta
from collections import defaultdict, deque
import json

class RealTimeMonitoringDashboard:
    def __init__(self):
        self.metrics_store = MetricsStore()
        self.alert_manager = AlertManager()
        self.websocket_connections = set()
        self.real_time_processors = {
            'conversion_rate': self._process_conversion_rate,
            'revenue': self._process_revenue,
            'traffic': self._process_traffic,
            'engagement': self._process_engagement
        }
    
    async def start_real_time_monitoring(self):
        """å¯åŠ¨å®æ—¶ç›‘æ§"""
        # å¯åŠ¨WebSocketæœåŠ¡å™¨
        start_server = websockets.serve(self.websocket_handler, "localhost", 8765)
        await start_server
    
    async def websocket_handler(self, websocket, path):
        """WebSocketè¿æ¥å¤„ç†å™¨"""
        self.websocket_connections.add(websocket)
        try:
            async for message in websocket:
                # å¤„ç†å®¢æˆ·ç«¯æ¶ˆæ¯
                await self._handle_client_message(websocket, message)
        finally:
            self.websocket_connections.remove(websocket)
    
    async def _handle_client_message(self, websocket, message):
        """å¤„ç†å®¢æˆ·ç«¯æ¶ˆæ¯"""
        try:
            data = json.loads(message)
            action = data.get('action')
            
            if action == 'subscribe':
                # è®¢é˜…ç‰¹å®šæŒ‡æ ‡
                metrics = data.get('metrics', [])
                await self._subscribe_to_metrics(websocket, metrics)
            elif action == 'unsubscribe':
                # å–æ¶ˆè®¢é˜…
                metrics = data.get('metrics', [])
                await self._unsubscribe_from_metrics(websocket, metrics)
        except json.JSONDecodeError:
            await websocket.send(json.dumps({'error': 'Invalid JSON'}))
    
    async def process_real_time_event(self, event_type: str, event_data: Dict):
        """å¤„ç†å®æ—¶äº‹ä»¶"""
        # å­˜å‚¨äº‹ä»¶æ•°æ®
        self.metrics_store.store_event(event_type, event_data)
        
        # å¤„ç†ç‰¹å®šç±»å‹çš„äº‹ä»¶
        processor = self.real_time_processors.get(event_type)
        if processor:
            processed_metrics = processor(event_data)
            
            # æ£€æŸ¥å‘Šè­¦æ¡ä»¶
            alerts = self.alert_manager.check_alerts(processed_metrics)
            if alerts:
                await self._broadcast_alerts(alerts)
            
            # å¹¿æ’­å®æ—¶æŒ‡æ ‡æ›´æ–°
            await self._broadcast_metrics_update(event_type, processed_metrics)
    
    def _process_conversion_rate(self, event_data: Dict) -> Dict:
        """å¤„ç†è½¬åŒ–ç‡æŒ‡æ ‡"""
        # è®¡ç®—å®æ—¶è½¬åŒ–ç‡
        time_window = timedelta(minutes=5)
        recent_conversions = self.metrics_store.get_events(
            'conversion', 
            datetime.now() - time_window
        )
        recent_visits = self.metrics_store.get_events(
            'visit', 
            datetime.now() - time_window
        )
        
        conversion_rate = (
            len(recent_conversions) / len(recent_visits) * 100 
            if recent_visits else 0
        )
        
        # è®¡ç®—åŒæ¯”å’Œç¯æ¯”å˜åŒ–
        prev_period_conversions = self.metrics_store.get_events(
            'conversion',
            datetime.now() - time_window * 2,
            datetime.now() - time_window
        )
        prev_period_visits = self.metrics_store.get_events(
            'visit',
            datetime.now() - time_window * 2,
            datetime.now() - time_window
        )
        
        prev_conversion_rate = (
            len(prev_period_conversions) / len(prev_period_visits) * 100
            if prev_period_visits else 0
        )
        
        trend = conversion_rate - prev_conversion_rate
        
        return {
            'current_rate': conversion_rate,
            'previous_rate': prev_conversion_rate,
            'trend': trend,
            'sample_size': len(recent_visits)
        }
    
    def _process_revenue(self, event_data: Dict) -> Dict:
        """å¤„ç†æ”¶å…¥æŒ‡æ ‡"""
        time_window = timedelta(hours=1)
        recent_revenue_events = self.metrics_store.get_events(
            'revenue',
            datetime.now() - time_window
        )
        
        total_revenue = sum(
            event.get('amount', 0) for event in recent_revenue_events
        )
        
        # è®¡ç®—å®¢å•ä»·
        conversion_events = self.metrics_store.get_events(
            'conversion',
            datetime.now() - time_window
        )
        
        avg_order_value = (
            total_revenue / len(conversion_events)
            if conversion_events else 0
        )
        
        return {
            'hourly_revenue': total_revenue,
            'avg_order_value': avg_order_value,
            'transaction_count': len(conversion_events)
        }
    
    async def _broadcast_metrics_update(self, metric_type: str, metrics: Dict):
        """å¹¿æ’­æŒ‡æ ‡æ›´æ–°"""
        update_message = {
            'type': 'metrics_update',
            'metric_type': metric_type,
            'data': metrics,
            'timestamp': datetime.now().isoformat()
        }
        
        # å‘æ‰€æœ‰è¿æ¥çš„å®¢æˆ·ç«¯å¹¿æ’­
        if self.websocket_connections:
            await asyncio.gather(
                *[conn.send(json.dumps(update_message)) 
                  for conn in self.websocket_connections],
                return_exceptions=True
            )
    
    async def _broadcast_alerts(self, alerts: List[Dict]):
        """å¹¿æ’­å‘Šè­¦ä¿¡æ¯"""
        alert_message = {
            'type': 'alerts',
            'data': alerts,
            'timestamp': datetime.now().isoformat()
        }
        
        if self.websocket_connections:
            await asyncio.gather(
                *[conn.send(json.dumps(alert_message))
                  for conn in self.websocket_connections],
                return_exceptions=True
            )

class MetricsStore:
    """æŒ‡æ ‡å­˜å‚¨"""
    def __init__(self):
        # ä½¿ç”¨å†…å­˜å­˜å‚¨è¿‘æœŸæ•°æ®ï¼Œç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨Redisæˆ–æ—¶åºæ•°æ®åº“
        self.events = defaultdict(deque)
        self.max_events_per_type = 10000  # æ¯ç§äº‹ä»¶ç±»å‹æœ€å¤šå­˜å‚¨10000æ¡
    
    def store_event(self, event_type: str, event_data: Dict):
        """å­˜å‚¨äº‹ä»¶"""
        event_data['timestamp'] = datetime.now()
        self.events[event_type].append(event_data)
        
        # é™åˆ¶å­˜å‚¨æ•°é‡
        if len(self.events[event_type]) > self.max_events_per_type:
            self.events[event_type].popleft()
    
    def get_events(self, event_type: str, start_time: datetime = None, 
                   end_time: datetime = None) -> List[Dict]:
        """è·å–äº‹ä»¶"""
        events = list(self.events[event_type])
        
        if start_time:
            events = [e for e in events if e['timestamp'] >= start_time]
        
        if end_time:
            events = [e for e in events if e['timestamp'] <= end_time]
        
        return events

class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨"""
    def __init__(self):
        self.alert_rules = [
            {
                'name': 'conversion_rate_drop',
                'metric': 'conversion_rate',
                'condition': lambda x: x['trend'] < -10,  # è½¬åŒ–ç‡ä¸‹é™è¶…è¿‡10%
                'severity': 'high',
                'message': 'è½¬åŒ–ç‡æ€¥å‰§ä¸‹é™ï¼Œè¯·ç«‹å³æ£€æŸ¥ï¼'
            },
            {
                'name': 'revenue_spike',
                'metric': 'revenue',
                'condition': lambda x: x['hourly_revenue'] > 100000,  # å°æ—¶æ”¶å…¥è¶…è¿‡10ä¸‡
                'severity': 'info',
                'message': 'æ”¶å…¥åˆ›æ–°é«˜ï¼'
            },
            {
                'name': 'low_traffic',
                'metric': 'traffic',
                'condition': lambda x: x['visitors'] < 100,  # è®¿å®¢æ•°ä½äº100
                'severity': 'medium',
                'message': 'æµé‡å¼‚å¸¸åä½ï¼Œè¯·æ£€æŸ¥æ¨å¹¿æ¸ é“ã€‚'
            }
        ]
    
    def check_alerts(self, metrics: Dict) -> List[Dict]:
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        alerts = []
        
        for rule in self.alert_rules:
            metric_data = metrics.get(rule['metric'])
            if metric_data and rule['condition'](metric_data):
                alerts.append({
                    'rule_name': rule['name'],
                    'severity': rule['severity'],
                    'message': rule['message'],
                    'metric': rule['metric'],
                    'value': metric_data,
                    'timestamp': datetime.now().isoformat()
                })
        
        return alerts
```

## 7. æ•°æ®éšç§ä¸åˆè§„

### Q15: ç”¨æˆ·æ•°æ®ä¿æŠ¤ä¸éšç§åˆè§„ï¼Ÿ
**ç­”ï¼š** ç¡®ä¿ç”¨æˆ·æ•°æ®å®‰å…¨å’Œéšç§åˆè§„æ˜¯æ™ºèƒ½è¥é”€çš„åŸºç¡€ï¼š

**æ•°æ®éšç§ä¿æŠ¤æ¡†æ¶**ï¼š
```python
import hashlib
import hmac
from cryptography.fernet import Fernet
from typing import Dict, Any, Optional
import json

class DataPrivacyManager:
    def __init__(self):
        self.encryption_key = self._load_or_generate_key()
        self.cipher_suite = Fernet(self.encryption_key)
        self.consent_manager = ConsentManager()
        self.data_minimizer = DataMinimizer()
    
    def encrypt_sensitive_data(self, data: str) -> str:
        """åŠ å¯†æ•æ„Ÿæ•°æ®"""
        encrypted_data = self.cipher_suite.encrypt(data.encode())
        return encrypted_data.decode()
    
    def decrypt_sensitive_data(self, encrypted_data: str) -> str:
        """è§£å¯†æ•æ„Ÿæ•°æ®"""
        decrypted_data = self.cipher_suite.decrypt(encrypted_data.encode())
        return decrypted_data.decode()
    
    def anonymize_user_data(self, user_data: Dict[str, Any]) -> Dict[str, Any]:
        """åŒ¿ååŒ–ç”¨æˆ·æ•°æ®"""
        anonymized_data = user_data.copy()
        
        # åŒ¿ååŒ–æ•æ„Ÿå­—æ®µ
        sensitive_fields = ['phone', 'email', 'address', 'id_card']
        for field in sensitive_fields:
            if field in anonymized_data:
                anonymized_data[field] = self._anonymize_field(
                    anonymized_data[field]
                )
        
        return anonymized_data
    
    def _anonymize_field(self, value: str) -> str:
        """åŒ¿ååŒ–å•ä¸ªå­—æ®µ"""
        if '@' in value:  # é‚®ç®±
            parts = value.split('@')
            return f"{parts[0][:2]}***@{parts[1]}"
        elif value.replace('-', '').isdigit():  # ç”µè¯å·ç 
            return f"{value[:3]}****{value[-4:]}" if len(value) > 7 else "***"
        else:  # å…¶ä»–æ•æ„Ÿä¿¡æ¯
            return hashlib.sha256(value.encode()).hexdigest()[:16]
    
    def process_user_request(self, request_type: str, user_id: str, 
                           request_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·æ•°æ®æƒåˆ©è¯·æ±‚"""
        if request_type == 'data_access':
            return self._handle_data_access_request(user_id)
        elif request_type == 'data_deletion':
            return self._handle_data_deletion_request(user_id)
        elif request_type == 'data_portability':
            return self._handle_data_portability_request(user_id)
        elif request_type == 'consent_withdrawal':
            return self._handle_consent_withdrawal(user_id, request_data)
        else:
            raise ValueError(f"Unsupported request type: {request_type}")
    
    def _handle_data_access_request(self, user_id: str) -> Dict[str, Any]:
        """å¤„ç†æ•°æ®è®¿é—®è¯·æ±‚"""
        # æ£€æŸ¥ç”¨æˆ·åŒæ„çŠ¶æ€
        consent_status = self.consent_manager.get_user_consent(user_id)
        if not consent_status.get('data_access', False):
            return {
                'success': False,
                'error': 'User has not consented to data access'
            }
        
        # è·å–ç”¨æˆ·æ•°æ®
        user_data = self._get_user_data(user_id)
        
        # æœ€å°åŒ–æ•°æ®è¾“å‡º
        minimized_data = self.data_minimizer.minimize_for_access(user_data)
        
        return {
            'success': True,
            'data': minimized_data,
            'timestamp': datetime.now().isoformat()
        }
    
    def _handle_data_deletion_request(self, user_id: str) -> Dict[str, Any]:
        """å¤„ç†æ•°æ®åˆ é™¤è¯·æ±‚"""
        # æ£€æŸ¥æ˜¯å¦æœ‰æ³•å¾‹ä¹‰åŠ¡ä¿ç•™æ•°æ®
        if self._has_legal_retention_obligation(user_id):
            return {
                'success': False,
                'error': 'Legal retention obligation prevents deletion'
            }
        
        # æ‰§è¡Œæ•°æ®åˆ é™¤
        deletion_result = self._delete_user_data(user_id)
        
        # è®°å½•åˆ é™¤æ“ä½œ
        self._log_deletion_operation(user_id, deletion_result)
        
        return {
            'success': deletion_result,
            'message': 'User data has been deleted' if deletion_result else 'Deletion failed'
        }
    
    def ensure_compliance(self, marketing_activity: Dict[str, Any]) -> bool:
        """ç¡®ä¿è¥é”€æ´»åŠ¨åˆè§„"""
        user_id = marketing_activity.get('user_id')
        activity_type = marketing_activity.get('activity_type')
        
        # æ£€æŸ¥ç”¨æˆ·åŒæ„çŠ¶æ€
        consent_status = self.consent_manager.get_user_consent(user_id)
        
        # æ£€æŸ¥ç‰¹å®šæ´»åŠ¨ç±»å‹çš„åŒæ„
        required_consents = {
            'email_marketing': 'email',
            'sms_marketing': 'sms',
            'personalized_ads': 'targeted_advertising',
            'data_sharing': 'data_sharing'
        }
        
        required_consent = required_consents.get(activity_type)
        if required_consent and not consent_status.get(required_consent, False):
            return False
        
        # æ£€æŸ¥æ•°æ®ä½¿ç”¨ç›®çš„
        intended_use = marketing_activity.get('purpose')
        if intended_use and not consent_status.get(f'purpose_{intended_use}', False):
            return False
        
        return True

class ConsentManager:
    """ç”¨æˆ·åŒæ„ç®¡ç†å™¨"""
    def __init__(self):
        self.consent_store = ConsentStore()
    
    def record_user_consent(self, user_id: str, consent_data: Dict[str, Any]) -> bool:
        """è®°å½•ç”¨æˆ·åŒæ„"""
        consent_record = {
            'user_id': user_id,
            'consent_data': consent_data,
            'timestamp': datetime.now().isoformat(),
            'version': '1.0'
        }
        
        # è®¡ç®—åŒæ„è®°å½•çš„ç­¾åä»¥ç¡®ä¿å®Œæ•´æ€§
        consent_record['signature'] = self._sign_consent_record(consent_record)
        
        return self.consent_store.save_consent(consent_record)
    
    def get_user_consent(self, user_id: str) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·åŒæ„çŠ¶æ€"""
        consent_record = self.consent_store.get_latest_consent(user_id)
        if not consent_record:
            return {}
        
        # éªŒè¯ç­¾å
        if not self._verify_consent_signature(consent_record):
            raise ValueError("Consent record signature verification failed")
        
        return consent_record.get('consent_data', {})
    
    def withdraw_consent(self, user_id: str, consent_types: List[str]) -> bool:
        """æ’¤é”€ç”¨æˆ·åŒæ„"""
        current_consent = self.get_user_consent(user_id)
        
        # æ›´æ–°åŒæ„çŠ¶æ€
        for consent_type in consent_types:
            if consent_type in current_consent:
                current_consent[consent_type] = False
        
        # è®°å½•æ›´æ–°
        return self.record_user_consent(user_id, current_consent)
    
    def _sign_consent_record(self, record: Dict) -> str:
        """å¯¹åŒæ„è®°å½•è¿›è¡Œç­¾å"""
        record_copy = record.copy()
        record_copy.pop('signature', None)  # ç§»é™¤ç­¾åå­—æ®µ
        
        record_string = json.dumps(record_copy, sort_keys=True)
        signature = hmac.new(
            b'secret_key_for_signing',  # å®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨å®‰å…¨çš„å¯†é’¥ç®¡ç†
            record_string.encode(),
            hashlib.sha256
        ).hexdigest()
        
        return signature
    
    def _verify_consent_signature(self, record: Dict) -> bool:
        """éªŒè¯åŒæ„è®°å½•ç­¾å"""
        original_signature = record.get('signature')
        if not original_signature:
            return False
        
        record_copy = record.copy()
        record_copy.pop('signature', None)
        
        calculated_signature = self._sign_consent_record(record_copy)
        return hmac.compare_digest(original_signature, calculated_signature)

class GDPRComplianceChecker:
    """GDPRåˆè§„æ£€æŸ¥å™¨"""
    def __init__(self):
        self.privacy_manager = DataPrivacyManager()
        self.consent_manager = ConsentManager()
    
    def check_compliance(self, marketing_campaign: Dict[str, Any]) -> Dict[str, Any]:
        """æ£€æŸ¥GDPRåˆè§„æ€§"""
        compliance_report = {
            'compliant': True,
            'violations': [],
            'recommendations': []
        }
        
        # æ£€æŸ¥æ•°æ®å¤„ç†åˆæ³•æ€§
        if not self._check_legal_basis(marketing_campaign):
            compliance_report['compliant'] = False
            compliance_report['violations'].append('No legal basis for data processing')
            compliance_report['recommendations'].append('Obtain explicit consent or establish legitimate interest')
        
        # æ£€æŸ¥ç”¨æˆ·åŒæ„
        user_id = marketing_campaign.get('target_audience', [{}])[0].get('user_id')
        if user_id:
            consent_status = self.consent_manager.get_user_consent(user_id)
            if not consent_status.get('marketing', False):
                compliance_report['compliant'] = False
                compliance_report['violations'].append('No marketing consent obtained')
                compliance_report['recommendations'].append('Request marketing consent from user')
        
        # æ£€æŸ¥æ•°æ®æœ€å°åŒ–åŸåˆ™
        if not self._check_data_minimization(marketing_campaign):
            compliance_report['violations'].append('Data minimization principle violated')
            compliance_report['recommendations'].append('Collect only necessary personal data')
        
        # æ£€æŸ¥å­˜å‚¨æœŸé™
        if not self._check_storage_limitation(marketing_campaign):
            compliance_report['violations'].append('Storage limitation principle violated')
            compliance_report['recommendations'].append('Implement data retention policies')
        
        return compliance_report
    
    def _check_legal_basis(self, campaign: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ•°æ®å¤„ç†çš„æ³•å¾‹ä¾æ®"""
        legal_bases = campaign.get('legal_basis', [])
        valid_bases = ['consent', 'contract', 'legal_obligation', 'vital_interest', 'public_task', 'legitimate_interest']
        
        return any(basis in valid_bases for basis in legal_bases)
    
    def _check_data_minimization(self, campaign: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ•°æ®æœ€å°åŒ–åŸåˆ™"""
        collected_data = campaign.get('collected_data', [])
        necessary_data = campaign.get('necessary_data', [])
        
        # æ£€æŸ¥æ”¶é›†çš„æ•°æ®æ˜¯å¦è¶…å‡ºå¿…è¦èŒƒå›´
        return set(collected_data).issubset(set(necessary_data))
    
    def _check_storage_limitation(self, campaign: Dict[str, Any]) -> bool:
        """æ£€æŸ¥å­˜å‚¨æœŸé™é™åˆ¶"""
        retention_period = campaign.get('data_retention_period')
        if not retention_period:
            return False
        
        # æ£€æŸ¥æ˜¯å¦è®¾ç½®äº†åˆç†çš„æ•°æ®ä¿ç•™æœŸé™
        max_retention_days = 365 * 3  # æœ€é•¿3å¹´
        return retention_period <= max_retention_days
```

### Q16: æ™ºèƒ½è¥é”€å¹³å°å®‰å…¨æ¶æ„ï¼Ÿ
**ç­”ï¼š** æ„å»ºå®‰å…¨çš„æ™ºèƒ½è¥é”€å¹³å°æ¶æ„ï¼š

**é›¶ä¿¡ä»»å®‰å…¨æ¶æ„**ï¼š
```python
import jwt
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
import base64
from typing import Dict, List, Optional
import time

class ZeroTrustSecurityFramework:
    def __init__(self):
        self.identity_provider = IdentityProvider()
        self.access_controller = AccessController()
        self.threat_detector = ThreatDetector()
        self.audit_logger = AuditLogger()
    
    def authenticate_user(self, credentials: Dict[str, str]) -> Dict[str, Any]:
        """ç”¨æˆ·èº«ä»½è®¤è¯"""
        # å¤šå› ç´ è®¤è¯
        auth_result = self.identity_provider.authenticate(credentials)
        
        if not auth_result['success']:
            self.audit_logger.log_authentication_failure(credentials.get('username'))
            return auth_result
        
        # ç”ŸæˆJWTä»¤ç‰Œ
        token = self._generate_jwt_token(
            auth_result['user_id'],
            auth_result['permissions']
        )
        
        self.audit_logger.log_authentication_success(
            auth_result['user_id'],
            credentials.get('username')
