# 11 Workflow   Workflow



```python
# æ¸…ç†ç¯å¢ƒä¿¡æ¯ï¼Œä¸ä¸Šè¯¾å†…å®¹æ— å…³
import os
os.environ["LANGCHAIN_PROJECT"] = ""
os.environ["LANGCHAIN_API_KEY"] = ""
os.environ["LANGCHAIN_ENDPOINT"] = ""
os.environ["LANGCHAIN_TRACING_V2"] = ""
```

```python
# å®‰è£…æ‰€éœ€è¦ä½¿ç”¨çš„åŒ…
!pip install openai langgraph Agently==3.3.4.5 mermaid-python nest_asyncio

# å› ä¸ºæœ¬è¯¾ä½¿ç”¨çš„langgraphå¯èƒ½éœ€è¦ä¾èµ–langchain 0.2.10ç‰ˆæœ¬ï¼Œä½†å…¶ä»–è¯¾ä»¶ä¾èµ–langchain 0.1.20ç‰ˆæœ¬
# è¯·å­¦ä¹ å®Œæœ¬è¯¾ä¹‹åå¯¹langchainè¿›è¡Œé™çº§ï¼Œä»¥å…åœ¨å…¶ä»–è¯¾ç¨‹å‡ºç°è¿è¡Œé”™è¯¯
#!pip install langchain==0.1.20
#!pip install langchain-openai==0.1.6
#!pip install langchain-community==0.0.38
```

```python
# ä½¿ç”¨nest_asyncioç¡®ä¿å¼‚æ­¥ç¨³å®šæ€§
import nest_asyncio
nest_asyncio.apply()
```

## ğŸ’¡ è¿™èŠ‚è¯¾ä¼šå¸¦ç»™ä½ 

1. äº†è§£å·¥ä½œæµå¯¹å¤§æ¨¡å‹è¿›è¡Œé«˜è´¨é‡å·¥ä½œçš„è¾…åŠ©æ„ä¹‰
2. å­¦ä¼šå¤ç°å´æ©è¾¾åšå£«çš„ç¿»è¯‘å·¥ä½œæµå¼€æºé¡¹ç›®
3. äº†è§£æ„æˆå¤§æ¨¡å‹å·¥ä½œæµç³»ç»Ÿçš„å…³é”®å…ƒç´ 
4. å­¦ä¼šæ­å»ºä¸€ä¸ªæ›´å¤æ‚çš„ä¸šåŠ¡åœºæ™¯å·¥ä½œæµ

## ğŸ“ è¿™èŠ‚è¯¾æ€ä¹ˆå­¦

ä»£ç èƒ½åŠ›è¦æ±‚ï¼š**ä¸­**ï¼ŒAI/æ•°å­¦åŸºç¡€è¦æ±‚ï¼š**ä½**

1. æœ‰ç¼–ç¨‹åŸºç¡€çš„åŒå­¦
    - èƒ½å¤Ÿè‡ªå·±åŠ¨æ‰‹å®ç°ä¸€å¥—å¤æ‚çš„å¤§æ¨¡å‹å·¥ä½œæµ
2. æ²¡æœ‰ç¼–ç¨‹åŸºç¡€çš„åŒå­¦
    - å¯ä»¥å…³æ³¨å’Œç†è§£å·¥ä½œæµå¯¹äºå¤§æ¨¡å‹åº”ç”¨çš„æ„ä¹‰ã€å…³é”®å…ƒç´ å’Œæ„å»ºæ€è·¯
    - ä¸éœ€è¦å¤æ‚ç¼–ç¨‹çŸ¥è¯†ï¼Œå¯ä»¥å°è¯•å¤ç°ç®€å•çš„ç¿»è¯‘å·¥ä½œæµ

## ä¸€ã€ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦å·¥ä½œæµï¼Ÿ

### â“ ä»€ä¹ˆæ ·çš„èŒåœºæ‰“å·¥äººæ˜¯åˆæ ¼çš„æ‰“å·¥äººï¼Ÿ

- ååº”å¿«ï¼Œç†è§£èƒ½åŠ›å¼ºï¼Ÿ
- æœ‰ç›¸å…³ç»éªŒï¼Œå­¦è¿‡ç›¸å…³å­¦ç§‘ï¼Ÿ
- æœ‰è¡ŒåŠ¨åŠ›ï¼Œä¸çº¸ä¸Šè°ˆå…µï¼Œè¿˜è¦èƒ½ä¸‹åœ°å¹²æ´»ï¼Ÿ

### â“ å“ªäº›å› ç´ ä¼šå½±å“å¤§æ¨¡å‹åº”ç”¨çš„æ•ˆæœï¼Ÿ

- æ¨¡å‹èƒ½åŠ›ï¼ˆæ™ºåŠ›ï¼‰
    - é€šè¯†ç†è§£å’Œæ³›åŒ–èƒ½åŠ›
    - è¾“å…¥ä¿¡æ¯ç†è§£ã€æ¨ç†ã€è§„åˆ’èƒ½åŠ›
    - è¾“å…¥ä¿¡æ¯è¡¥å……çŸ¥è¯†å­¦ä¹ èƒ½åŠ›
    - æ–‡å­—ç”Ÿæˆåˆ›ä½œçš„é£æ ¼
- ç›¸å…³ä¿¡æ¯ï¼ˆçŸ¥è¯†ï¼‰
    - ä¸ä»»åŠ¡ç›¸å…³çš„ä¿¡æ¯
    - ä¸äº’åŠ¨èƒŒæ™¯ç›¸å…³çš„ä¿¡æ¯
- æ¨¡å‹è¾“å‡ºæ§åˆ¶ï¼ˆè¡ŒåŠ¨æ–¹æ³•ï¼‰
    - å•æ¬¡è¯·æ±‚æ§åˆ¶
        - Promptè¡¨è¾¾ä¼˜åŒ–
        - ä»¥CoTä¸ºä»£è¡¨çš„æ€ç»´é“¾æ§åˆ¶æ–¹æ³•
        - è¾“å‡ºæ ¼å¼æ§åˆ¶ï¼ˆæ–‡æœ¬æ ¼å¼è¯­æ³•ã€å·¥ç¨‹ç»“æ„åŒ–æ•°æ®è¾“å‡ºâ€¦ï¼‰
    - å¤šæ¬¡è¯·æ±‚æ§åˆ¶
        - ä»¥ReActï¼ˆAction-Observation-Reflectionï¼‰ä¸ºä»£è¡¨çš„å¤šè½®è‡ªæˆ‘åæ€ä¼˜åŒ–
        - å¤æ‚ä»»åŠ¡çš„æ‰§è¡Œè¿‡ç¨‹ç¼–æ’ç®¡ç†

### å•æ¬¡è¯·æ±‚çš„å±€é™æ€§

- ä¸Šä¸‹æ–‡çª—å£é•¿åº¦é™åˆ¶ã€è¾“å‡ºé•¿åº¦é™åˆ¶ï¼ˆæ—©æœŸçš„LangChainé•¿æ–‡æœ¬Summarizeï¼‰
- ç›´æ¥è¿›è¡ŒCoTæ§åˆ¶ï¼ˆå°¤å…¶æ˜¯ç”¨è‡ªç„¶è¯­è¨€è¡¨è¾¾CoTï¼‰ä¼šè¾“å‡ºæ€è€ƒè¿‡ç¨‹ï¼Œä½†æˆ‘ä»¬ä¸å¸Œæœ›ç”¨æˆ·çœ‹åˆ°è¿™ä¸ªè¿‡ç¨‹
- éšç€å·¥ä½œè¿›å±•å‡ºç°çš„æ–°ä¿¡æ¯ï¼Œå¯¹ä»»åŠ¡æ—¶åºã€ç¼–æ’æœ‰ä¾èµ–çš„ä¿¡æ¯ï¼Œä¸ä¸€å®šèƒ½åœ¨å•æ¬¡è¯·æ±‚ä¸­ä¸€æ¬¡æ€§å®Œæˆè¾“å…¥

### å·¥ä½œæµçš„ä¼˜åŠ¿

- å°†å·¥ä½œä»»åŠ¡æ‹†åˆ†æˆå¤šä¸ªå·¥ä½œèŠ‚ç‚¹
- èƒ½å¤Ÿå°†æ¨¡å‹å•æ¬¡è¯·æ±‚è°ƒç”¨è§†ä½œä¸€ä¸ªå·¥ä½œèŠ‚ç‚¹
- èƒ½å¤Ÿçµæ´»å°†å…¶ä»–ä»£ç é€»è¾‘ä¹Ÿå†™å…¥å·¥ä½œèŠ‚ç‚¹
- èƒ½å¤Ÿå¯¹å·¥ä½œèŠ‚ç‚¹è¿›è¡Œä»»åŠ¡ç¼–æ’
- èƒ½å¤Ÿåœ¨å·¥ä½œèŠ‚ç‚¹ä¹‹é—´è¿›è¡Œæ•°æ®ä¼ é€’

[è¯•ä¸€è¯•]

ç›´æ¥è¯·æ±‚æ¨¡å‹çš„æ•ˆæœï¼š

```python
from ENV import deep_seek_url, deep_seek_api_key, deep_seek_default_model
import Agently
agent = (
    Agently.create_agent()
        .set_settings("current_model", "OAIClient")
        .set_settings("model.OAIClient.url", deep_seek_url)
        .set_settings("model.OAIClient.auth", { "api_key": deep_seek_api_key })
        .set_settings("model.OAIClient.options", { "model": deep_seek_default_model })
)

result = agent.input(input("[è¯·è¾“å…¥æ‚¨çš„è¦æ±‚]: ")).start()
print("[å›å¤]: ", result)
```

**Output:**
```
[è¯·è¾“å…¥æ‚¨çš„è¦æ±‚]:  æˆ‘æƒ³è¦é€€è´§ï¼Œè¿™ä¸ªé‹å­ä¸åˆè„š
[å›å¤]:  å¦‚æœæ‚¨è´­ä¹°çš„é‹å­ä¸åˆè„šï¼Œæ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å°è¯•é€€è´§ï¼š

1. **æ£€æŸ¥é€€è´§æ”¿ç­–**ï¼šé¦–å…ˆï¼ŒæŸ¥çœ‹æ‚¨è´­ä¹°æ—¶çš„é€€è´§æ”¿ç­–ã€‚å¤§å¤šæ•°é›¶å”®å•†éƒ½æœ‰ä¸€å®šçš„é€€è´§æœŸé™ï¼Œé€šå¸¸æ˜¯è´­ä¹°åçš„30å¤©å†…ã€‚ç¡®ä¿æ‚¨çš„é€€è´§è¯·æ±‚åœ¨æœŸé™å†…ã€‚

2. **ä¿ç•™æ”¶æ®å’ŒåŒ…è£…**ï¼šä¿ç•™æ‚¨çš„è´­ä¹°æ”¶æ®å’Œé‹å­çš„åŸå§‹åŒ…è£…ã€‚è¿™äº›é€šå¸¸æ˜¯é€€è´§æ—¶å¿…éœ€çš„ã€‚

3. **è”ç³»å®¢æœ**ï¼šé€šè¿‡ç”µè¯ã€ç”µå­é‚®ä»¶æˆ–åœ¨çº¿èŠå¤©è”ç³»é›¶å”®å•†çš„å®¢æœéƒ¨é—¨ã€‚è¯´æ˜æ‚¨çš„æƒ…å†µï¼Œå¹¶è¯¢é—®é€€è´§æµç¨‹ã€‚

4. **å‡†å¤‡é€€è´§ç‰©å“**ï¼šæŒ‰ç…§é›¶å”®å•†çš„è¦æ±‚å‡†å¤‡é€€è´§ç‰©å“ã€‚å¯èƒ½éœ€è¦æ‚¨å°†é‹å­æ”¾å›åŸå§‹åŒ…è£…ä¸­ï¼Œå¹¶é™„ä¸Šæ”¶æ®ã€‚

5. **é€€è´§æ–¹å¼**ï¼šæ ¹æ®é›¶å”®å•†çš„æŒ‡ç¤ºï¼Œæ‚¨å¯èƒ½éœ€è¦äº²è‡ªåˆ°åº—é“ºé€€è´§ï¼Œæˆ–è€…é€šè¿‡é‚®å¯„çš„æ–¹å¼é€€è´§ã€‚å¦‚æœæ˜¯é‚®å¯„ï¼Œç¡®ä¿ä½¿ç”¨å¯è¿½è¸ªçš„é‚®å¯„æœåŠ¡ï¼Œå¹¶ä¿ç•™é‚®å¯„å‡­è¯ã€‚

6. **ç­‰å¾…å¤„ç†**ï¼šä¸€æ—¦é›¶å”®å•†æ”¶åˆ°æ‚¨çš„é€€è´§ç‰©å“ï¼Œä»–ä»¬å°†è¿›è¡Œæ£€æŸ¥å¹¶å¤„ç†é€€æ¬¾ã€‚é€€æ¬¾é€šå¸¸ä¼šé€€å›åˆ°æ‚¨åŸæ”¯ä»˜æ–¹å¼ä¸­ã€‚

7. **è·Ÿè¿›**ï¼šå¦‚æœåœ¨åˆç†çš„æ—¶é—´å†…æ²¡æœ‰æ”¶åˆ°é€€æ¬¾ï¼ŒåŠæ—¶è·Ÿè¿›å¹¶è”ç³»å®¢æœè¯¢é—®é€€æ¬¾çŠ¶æ€ã€‚

è¯·æ³¨æ„ï¼Œä¸åŒçš„é›¶å”®å•†å¯èƒ½æœ‰ä¸åŒçš„é€€è´§æ”¿ç­–å’Œæµç¨‹ï¼Œæ‰€ä»¥æœ€å¥½æ˜¯ç›´æ¥å’¨è¯¢æ‚¨è´­ä¹°é‹å­çš„é›¶å”®å•†ä»¥è·å–æœ€å‡†ç¡®çš„ä¿¡æ¯ã€‚å¦‚æœæ˜¯åœ¨çº¿è´­ä¹°ï¼Œé€šå¸¸å¯ä»¥åœ¨ç½‘ç«™çš„â€œå¸®åŠ©â€æˆ–â€œå®¢æˆ·æœåŠ¡â€éƒ¨åˆ†æ‰¾åˆ°é€€è´§æŒ‡å—ã€‚
```

ä½¿ç”¨å·¥ä½œæµï¼š

```python
workflow = Agently.Workflow()

@workflow.chunk()
def user_input(inputs, storage):
    storage.set("user_input", input("[è¯·è¾“å…¥æ‚¨çš„è¦æ±‚]: "))
    return

@workflow.chunk()
def judge_intent_and_quick_reply(inputs, storage):
    result = (
        agent
            .input(storage.get("user_input"))
            .output({
                "user_intent": ("é—²èŠ | å”®åé—®é¢˜ | å…¶ä»–", "åˆ¤æ–­ç”¨æˆ·æäº¤çš„{input}å†…å®¹å±äºç»™å®šé€‰é¡¹ä¸­çš„å“ªä¸€ç§"),
                "quick_reply": (
                    "str",
"""å¦‚æœ{user_intent}=='é—²èŠ'ï¼Œé‚£ä¹ˆç›´æ¥ç»™å‡ºä½ çš„å›åº”ï¼›
å¦‚æœ{user_intent}=='å”®åé—®é¢˜'ï¼Œé‚£ä¹ˆè¯·ç”¨åˆé€‚çš„æ–¹å¼å‘Šè¯‰ç”¨æˆ·ä½ å·²ç»æ˜ç™½ç”¨æˆ·çš„è¯‰æ±‚ï¼Œå®‰æŠšå®¢æˆ·æƒ…ç»ªå¹¶è¯·ç¨ç­‰ä½ å»çœ‹çœ‹åº”è¯¥å¦‚ä½•å¤„ç†ï¼›
å¦‚æœ{user_intent}=='å…¶ä»–'ï¼Œæ­¤é¡¹è¾“å‡ºnull""")
            })
            .start()
    )
    storage.set("reply", result["quick_reply"])
    return result["user_intent"]

@workflow.chunk()
def generate_after_sales_reply(inputs, storage):
    storage.set("reply", (
        agent
            .input(storage.get("user_input"))
            .instruct(
"""è¯·æ ¹æ®{input}çš„è¦æ±‚ï¼Œä»¥ä¸€ä¸ªä¸“ä¸šå®¢æˆ·æœåŠ¡äººå‘˜çš„è§’è‰²ç»™å‡ºå›å¤ï¼Œéµå¾ªå¦‚ä¸‹æ¨¡æ¿è¿›è¡Œå›å¤ï¼š
äº²çˆ±çš„å®¢æˆ·ï¼Œæ„Ÿè°¢æ‚¨çš„è€å¿ƒç­‰å¾…ã€‚
æˆ‘ç†è§£æ‚¨å¸Œæœ›{{å¤è¿°å®¢æˆ·çš„è¦æ±‚}}ï¼Œæ˜¯å› ä¸º{{å¤è¿°å®¢æˆ·è¦æ±‚æå‡ºè¦æ±‚çš„ç†ç”±}}ï¼Œæ‚¨çš„å¿ƒæƒ…ä¸€å®šéå¸¸{{é˜è¿°ä½ å¯¹å®¢æˆ·å¿ƒæƒ…/æ„Ÿå—çš„ç†è§£}}ã€‚
{{ç»™å‡ºå¯¹å®¢æˆ·å½“å‰å¿ƒæƒ…çš„æŠšæ…°æ€§è¯è¯­}}ã€‚
æˆ‘ä»¬ä¼šå°½å¿«å’Œç›¸å…³äººå‘˜æ²Ÿé€šï¼Œå¹¶å°½é‡è¿›è¡Œæ»¡è¶³ã€‚è¯·ç•™ä¸‹æ‚¨çš„è”ç³»æ–¹å¼ä»¥æ–¹ä¾¿æˆ‘ä»¬å°½å¿«å¤„ç†åä¸æ‚¨è”ç³»ã€‚
"""
)
            .start()
    ))
    return

@workflow.chunk()
def generate_other_topic_reply(inputs, storage):
    storage.set("reply", "æˆ‘ä»¬å¥½åƒä¸åº”è¯¥èŠè¿™ä¸ªï¼Œè¿˜æ˜¯å›åˆ°æ‚¨çš„é—®é¢˜æˆ–è¯‰æ±‚ä¸Šæ¥å§ã€‚")
    return

@workflow.chunk_class()
def reply(inputs, storage):
    print("[å›å¤]: ", storage.get("reply"))
    return

(
    workflow
        .connect_to("user_input")
        .connect_to("judge_intent_and_quick_reply")
        .if_condition(lambda return_value, storage: return_value=="é—²èŠ")
            .connect_to("@reply")
            .connect_to("end")
        .elif_condition(lambda return_value, storage: return_value=="å”®åé—®é¢˜")
            .connect_to("@reply")
            .connect_to("generate_after_sales_reply")
            .connect_to("@reply")
            .connect_to("user_input")
        .else_condition()
            .connect_to("generate_other_topic_reply")
            .connect_to("@reply")
            .connect_to("END")
)

workflow.start()
pass
```

**Output:**
```
[è¯·è¾“å…¥æ‚¨çš„è¦æ±‚]:  æˆ‘æƒ³è¦é€€è´§ï¼Œè¿™ä¸ªé‹å­ä¸åˆè„š
[å›å¤]:  éå¸¸æŠ±æ­‰ç»™æ‚¨å¸¦æ¥ä¸ä¾¿ï¼Œæˆ‘æ˜ç™½æ‚¨æƒ³è¦é€€è´§å› ä¸ºé‹å­ä¸åˆè„šã€‚è¯·ç¨ç­‰ï¼Œæˆ‘ä¼šç«‹å³æŸ¥çœ‹å¦‚ä½•ä¸ºæ‚¨å¤„ç†é€€è´§äº‹å®œã€‚
[å›å¤]:  äº²çˆ±çš„å®¢æˆ·ï¼Œæ„Ÿè°¢æ‚¨çš„è€å¿ƒç­‰å¾…ã€‚
æˆ‘ç†è§£æ‚¨å¸Œæœ›é€€è´§ï¼Œæ˜¯å› ä¸ºé‹å­ä¸åˆè„šï¼Œæ‚¨çš„å¿ƒæƒ…ä¸€å®šéå¸¸å¤±æœ›ã€‚
è¯·ä¸è¦æ‹…å¿ƒï¼Œæˆ‘ä»¬ä¼šå°½åŠ›å¸®åŠ©æ‚¨è§£å†³è¿™ä¸ªé—®é¢˜ã€‚æˆ‘ä»¬ä¼šå°½å¿«å’Œç›¸å…³äººå‘˜æ²Ÿé€šï¼Œå¹¶å°½é‡è¿›è¡Œæ»¡è¶³ã€‚è¯·ç•™ä¸‹æ‚¨çš„è”ç³»æ–¹å¼ä»¥æ–¹ä¾¿æˆ‘ä»¬å°½å¿«å¤„ç†åä¸æ‚¨è”ç³»ã€‚
```

![intent.jpg]( ./assets/11-workflow/attachment:34715195-d8d4-4c3f-8c33-a270bcfc3d08.jpg)

## äºŒã€è®©æˆ‘ä»¬ä»å´æ©è¾¾åšå£«çš„å¼€æºç¿»è¯‘å·¥ä½œæµé¡¹ç›®è¯´èµ·

- é¡¹ç›®åœ°å€ï¼š[https://github.com/andrewyng/translation-agent](https://github.com/andrewyng/translation-agent)

- é¡¹ç›®åŸºæœ¬æ€è·¯ï¼š

    - è®©æ¨¡å‹åœ¨å®Œæˆé¦–è½®ç¿»è¯‘ä¹‹åï¼Œé€šè¿‡è‡ªæˆ‘åæ€åä¿®æ­£çš„å·¥ä½œæµä¼˜åŒ–ç¿»è¯‘ç»“æœï¼Œä»¥æå‡æœ€ç»ˆæ–‡æœ¬ç¿»è¯‘çš„è´¨é‡
 
- å…³é”®æ­¥éª¤ï¼š

    1. ç¬¬ä¸€æ­¥ï¼š
       
        - è¾“å…¥ä¿¡æ¯ï¼š**åŸå§‹æ–‡æœ¬è¯­è¨€(source_lang)** ã€**ç¿»è¯‘ç›®æ ‡è¯­è¨€(target_lang)** å’Œ **åŸå§‹æ–‡æœ¬(source_text)**
        - è§’è‰²è®¾å®šï¼šä»¥ç¿»è¯‘æ–‡æœ¬ä¸ºä»»åŠ¡ç›®æ ‡çš„è¯­è¨€å­¦å®¶
        - è¾“å‡ºç»“æœï¼šåŸºäºæ‰€æœ‰è¾“å…¥ä¿¡æ¯ï¼Œå¯¹ **åŸå§‹æ–‡æœ¬(source_text)** è¿›è¡Œ **ç¬¬ä¸€è½®ç¿»è¯‘çš„ç»“æœ(translation_1)**ï¼›
  
    2. ç¬¬äºŒæ­¥ï¼š
       
        - è¾“å…¥ä¿¡æ¯ï¼š**åŸå§‹æ–‡æœ¬è¯­è¨€(source_lang)** ã€**ç¿»è¯‘ç›®æ ‡è¯­è¨€(target_lang)** ã€ **åŸå§‹æ–‡æœ¬(source_text)** å’Œ **ç¬¬ä¸€è½®ç¿»è¯‘ç»“æœ(translation_1)**
        - è§’è‰²è®¾å®šï¼šä»¥é˜…è¯»åŸå§‹æ–‡æœ¬å’Œç¿»è¯‘æ–‡æœ¬ï¼Œå¹¶ç»™å‡ºç¿»è¯‘æ”¹è¿›æ„è§ä¸ºä»»åŠ¡ç›®æ ‡çš„è¯­è¨€å­¦å®¶
        - è¾“å‡ºç»“æœï¼šåŸºäºæ‰€æœ‰è¾“å…¥ä¿¡æ¯ï¼Œå¯¹ **ç¬¬ä¸€è½®ç¿»è¯‘ç»“æœ(translation_1)** æå‡ºçš„ **æ”¹è¿›æ„è§åæ€(reflection)**
  
    3. ç¬¬ä¸‰æ­¥ï¼š
       
        - è¾“å…¥ä¿¡æ¯ï¼š**åŸå§‹æ–‡æœ¬è¯­è¨€(source_lang)** ã€**ç¿»è¯‘ç›®æ ‡è¯­è¨€(target_lang)** ã€ **åŸå§‹æ–‡æœ¬(source_text)** ã€ **ç¬¬ä¸€è½®ç¿»è¯‘ç»“æœ(translation_1)** å’Œ **æ”¹è¿›æ„è§åæ€(reflection)**
        - è§’è‰²è®¾å®šï¼šä»¥ç¿»è¯‘æ–‡æœ¬ä¸ºä»»åŠ¡ç›®æ ‡çš„è¯­è¨€å­¦å®¶ï¼ˆå’Œç¬¬ä¸€æ­¥ç›¸åŒï¼‰
        - è¾“å‡ºç»“æœï¼šåŸºäºæ‰€æœ‰è¾“å…¥ä¿¡æ¯ï¼Œç»™å‡ºçš„**ç¬¬äºŒè½®ä¼˜åŒ–åç¿»è¯‘ç»“æœ(translation_2)**

- å…³é”®ä»£ç æ–‡ä»¶ï¼š[https://github.com/andrewyng/translation-agent/blob/main/src/translation_agent/utils.py](https://github.com/andrewyng/translation-agent/blob/main/src/translation_agent/utils.py)
  
- å…³é”®ä»£ç ç‰‡æ®µï¼š

```python
def one_chunk_initial_translation(
    source_lang: str, target_lang: str, source_text: str
) -> str:
    """
    Translate the entire text as one chunk using an LLM.

    Args:
        source_lang (str): The source language of the text.
        target_lang (str): The target language for translation.
        source_text (str): The text to be translated.

    Returns:
        str: The translated text.
    """

    system_message = f"You are an expert linguist, specializing in translation from {source_lang} to {target_lang}."

    translation_prompt = f"""This is an {source_lang} to {target_lang} translation, please provide the {target_lang} translation for this text. \
Do not provide any explanations or text apart from the translation.
{source_lang}: {source_text}

{target_lang}:"""

    prompt = translation_prompt.format(source_text=source_text)

    translation = get_completion(prompt, system_message=system_message)

    return translation


def one_chunk_reflect_on_translation(
    source_lang: str,
    target_lang: str,
    source_text: str,
    translation_1: str,
    country: str = "",
) -> str:
    """
    Use an LLM to reflect on the translation, treating the entire text as one chunk.

    Args:
        source_lang (str): The source language of the text.
        target_lang (str): The target language of the translation.
        source_text (str): The original text in the source language.
        translation_1 (str): The initial translation of the source text.
        country (str): Country specified for target language.

    Returns:
        str: The LLM's reflection on the translation, providing constructive criticism and suggestions for improvement.
    """

    system_message = f"You are an expert linguist specializing in translation from {source_lang} to {target_lang}. \
You will be provided with a source text and its translation and your goal is to improve the translation."

    if country != "":
        reflection_prompt = f"""Your task is to carefully read a source text and a translation from {source_lang} to {target_lang}, and then give constructive criticism and helpful suggestions to improve the translation. \
The final style and tone of the translation should match the style of {target_lang} colloquially spoken in {country}.

The source text and initial translation, delimited by XML tags <SOURCE_TEXT></SOURCE_TEXT> and <TRANSLATION></TRANSLATION>, are as follows:

<SOURCE_TEXT>
{source_text}
</SOURCE_TEXT>

<TRANSLATION>
{translation_1}
</TRANSLATION>

When writing suggestions, pay attention to whether there are ways to improve the translation's \n\
(i) accuracy (by correcting errors of addition, mistranslation, omission, or untranslated text),\n\
(ii) fluency (by applying {target_lang} grammar, spelling and punctuation rules, and ensuring there are no unnecessary repetitions),\n\
(iii) style (by ensuring the translations reflect the style of the source text and takes into account any cultural context),\n\
(iv) terminology (by ensuring terminology use is consistent and reflects the source text domain; and by only ensuring you use equivalent idioms {target_lang}).\n\

Write a list of specific, helpful and constructive suggestions for improving the translation.
Each suggestion should address one specific part of the translation.
Output only the suggestions and nothing else."""

    else:
        reflection_prompt = f"""Your task is to carefully read a source text and a translation from {source_lang} to {target_lang}, and then give constructive criticism and helpful suggestions to improve the translation. \

The source text and initial translation, delimited by XML tags <SOURCE_TEXT></SOURCE_TEXT> and <TRANSLATION></TRANSLATION>, are as follows:

<SOURCE_TEXT>
{source_text}
</SOURCE_TEXT>

<TRANSLATION>
{translation_1}
</TRANSLATION>

When writing suggestions, pay attention to whether there are ways to improve the translation's \n\
(i) accuracy (by correcting errors of addition, mistranslation, omission, or untranslated text),\n\
(ii) fluency (by applying {target_lang} grammar, spelling and punctuation rules, and ensuring there are no unnecessary repetitions),\n\
(iii) style (by ensuring the translations reflect the style of the source text and takes into account any cultural context),\n\
(iv) terminology (by ensuring terminology use is consistent and reflects the source text domain; and by only ensuring you use equivalent idioms {target_lang}).\n\

Write a list of specific, helpful and constructive suggestions for improving the translation.
Each suggestion should address one specific part of the translation.
Output only the suggestions and nothing else."""

    prompt = reflection_prompt.format(
        source_lang=source_lang,
        target_lang=target_lang,
        source_text=source_text,
        translation_1=translation_1,
    )
    reflection = get_completion(prompt, system_message=system_message)
    return reflection


def one_chunk_improve_translation(
    source_lang: str,
    target_lang: str,
    source_text: str,
    translation_1: str,
    reflection: str,
) -> str:
    """
    Use the reflection to improve the translation, treating the entire text as one chunk.

    Args:
        source_lang (str): The source language of the text.
        target_lang (str): The target language for the translation.
        source_text (str): The original text in the source language.
        translation_1 (str): The initial translation of the source text.
        reflection (str): Expert suggestions and constructive criticism for improving the translation.

    Returns:
        str: The improved translation based on the expert suggestions.
    """

    system_message = f"You are an expert linguist, specializing in translation editing from {source_lang} to {target_lang}."

    prompt = f"""Your task is to carefully read, then edit, a translation from {source_lang} to {target_lang}, taking into
account a list of expert suggestions and constructive criticisms.

The source text, the initial translation, and the expert linguist suggestions are delimited by XML tags <SOURCE_TEXT></SOURCE_TEXT>, <TRANSLATION></TRANSLATION> and <EXPERT_SUGGESTIONS></EXPERT_SUGGESTIONS> \
as follows:

<SOURCE_TEXT>
{source_text}
</SOURCE_TEXT>

<TRANSLATION>
{translation_1}
</TRANSLATION>

<EXPERT_SUGGESTIONS>
{reflection}
</EXPERT_SUGGESTIONS>

Please take into account the expert suggestions when editing the translation. Edit the translation by ensuring:

(i) accuracy (by correcting errors of addition, mistranslation, omission, or untranslated text),
(ii) fluency (by applying {target_lang} grammar, spelling and punctuation rules and ensuring there are no unnecessary repetitions), \
(iii) style (by ensuring the translations reflect the style of the source text)
(iv) terminology (inappropriate for context, inconsistent use), or
(v) other errors.

Output only the new translation and nothing else."""

    translation_2 = get_completion(prompt, system_message)

    return translation_2


def one_chunk_translate_text(
    source_lang: str, target_lang: str, source_text: str, country: str = ""
) -> str:
    """
    Translate a single chunk of text from the source language to the target language.

    This function performs a two-step translation process:
    1. Get an initial translation of the source text.
    2. Reflect on the initial translation and generate an improved translation.

    Args:
        source_lang (str): The source language of the text.
        target_lang (str): The target language for the translation.
        source_text (str): The text to be translated.
        country (str): Country specified for target language.
    Returns:
        str: The improved translation of the source text.
    """
    translation_1 = one_chunk_initial_translation(
        source_lang, target_lang, source_text
    )

    reflection = one_chunk_reflect_on_translation(
        source_lang, target_lang, source_text, translation_1, country
    )
    translation_2 = one_chunk_improve_translation(
        source_lang, target_lang, source_text, translation_1, reflection
    )

    return translation_2
```

## ä¸‰ã€ä½¿ç”¨LangGraphå’ŒAgently Workflowåˆ†åˆ«å¤ç°è¿™ä¸ªå·¥ä½œæµ

### 3.1 LangGraph

LangGraphæ‰‹å†Œï¼š[https://langchain-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/)

```python
import json
import openai
from ENV import deep_seek_url, deep_seek_api_key, deep_seek_default_model
from langgraph.graph import StateGraph, START, END
import os

# æ¨¡å‹è¯·æ±‚å‡†å¤‡
client = openai.OpenAI(
    api_key = deep_seek_api_key,
    base_url =deep_seek_url
)
default_model = deep_seek_default_model

def get_completion(
    prompt: str,
    system_message: str = "You are a helpful assistant.",
    model: str = default_model,
    temperature: float = 0.3,
    json_mode: bool = False,
):
    response = client.chat.completions.create(
        model=model,
        temperature=temperature,
        top_p=1,
        messages=[
            {"role": "system", "content": system_message},
            {"role": "user", "content": prompt},
        ],
    )
    return response.choices[0].message.content

# å®šä¹‰ä¼ é€’çš„ä¿¡æ¯ç»“æ„
from typing import TypedDict, Optional
class State(TypedDict):
    source_lang: str
    target_lang: str
    source_text: str
    country: Optional[str] = None
    translation_1: Optional[str] = None
    reflection: Optional[str] = None
    translation_2: Optional[str] = None

# åˆ›å»ºä¸€ä¸ªå·¥ä½œæµå¯¹è±¡
workflow = StateGraph(State)

# å®šä¹‰ä¸‰ä¸ªå·¥ä½œå—
"""
è·å–stateä¸­çš„ä¿¡æ¯ï¼šstate.get("key_name")
æ›´æ–°stateä¸­çš„ä¿¡æ¯ï¼šreturn { "key_name": new_value }
"""
def initial_translation(state):
    source_lang = state.get("source_lang")
    target_lang = state.get("target_lang")
    source_text = state.get("source_text")

    system_message = f"You are an expert linguist, specializing in translation from {source_lang} to {target_lang}."

    prompt = f"""This is an {source_lang} to {target_lang} translation, please provide the {target_lang} translation for this text. \
Do not provide any explanations or text apart from the translation.
{source_lang}: {source_text}

{target_lang}:"""

    translation = get_completion(prompt, system_message=system_message)

    print("[åˆæ¬¡ç¿»è¯‘ç»“æœ]: \n", translation)

    return { "translation_1": translation }

def reflect_on_translation(state):
    source_lang = state.get("source_lang")
    target_lang = state.get("target_lang")
    source_text = state.get("source_text")
    country = state.get("country") or ""
    translation_1 = state.get("translation_1")
    
    system_message = f"You are an expert linguist specializing in translation from {source_lang} to {target_lang}. \
You will be provided with a source text and its translation and your goal is to improve the translation."

    additional_rule = (
        f"The final style and tone of the translation should match the style of {target_lang} colloquially spoken in {country}."
        if country != ""
        else ""
    )
    
    prompt = f"""Your task is to carefully read a source text and a translation from {source_lang} to {target_lang}, and then give constructive criticism and helpful suggestions to improve the translation. \
{additional_rule}

The source text and initial translation, delimited by XML tags <SOURCE_TEXT></SOURCE_TEXT> and <TRANSLATION></TRANSLATION>, are as follows:

<SOURCE_TEXT>
{source_text}
</SOURCE_TEXT>

<TRANSLATION>
{translation_1}
</TRANSLATION>

When writing suggestions, pay attention to whether there are ways to improve the translation's \n\
(i) accuracy (by correcting errors of addition, mistranslation, omission, or untranslated text),\n\
(ii) fluency (by applying {target_lang} grammar, spelling and punctuation rules, and ensuring there are no unnecessary repetitions),\n\
(iii) style (by ensuring the translations reflect the style of the source text and takes into account any cultural context),\n\
(iv) terminology (by ensuring terminology use is consistent and reflects the source text domain; and by only ensuring you use equivalent idioms {target_lang}).\n\

Write a list of specific, helpful and constructive suggestions for improving the translation.
Each suggestion should address one specific part of the translation.
Output only the suggestions and nothing else."""

    reflection = get_completion(prompt, system_message=system_message)

    print("[åˆæ¬¡ç¿»è¯‘ç»“æœ]: \n", reflection)

    return { "reflection": reflection }

def improve_translation(state):
    source_lang = state.get("source_lang")
    target_lang = state.get("target_lang")
    source_text = state.get("source_text")
    translation_1 = state.get("translation_1")
    reflection = state.get("reflection")
    
    system_message = f"You are an expert linguist, specializing in translation editing from {source_lang} to {target_lang}."

    prompt = f"""Your task is to carefully read, then edit, a translation from {source_lang} to {target_lang}, taking into
account a list of expert suggestions and constructive criticisms.

The source text, the initial translation, and the expert linguist suggestions are delimited by XML tags <SOURCE_TEXT></SOURCE_TEXT>, <TRANSLATION></TRANSLATION> and <EXPERT_SUGGESTIONS></EXPERT_SUGGESTIONS> \
as follows:

<SOURCE_TEXT>
{source_text}
</SOURCE_TEXT>

<TRANSLATION>
{translation_1}
</TRANSLATION>

<EXPERT_SUGGESTIONS>
{reflection}
</EXPERT_SUGGESTIONS>

Please take into account the expert suggestions when editing the translation. Edit the translation by ensuring:

(i) accuracy (by correcting errors of addition, mistranslation, omission, or untranslated text),
(ii) fluency (by applying {target_lang} grammar, spelling and punctuation rules and ensuring there are no unnecessary repetitions), \
(iii) style (by ensuring the translations reflect the style of the source text)
(iv) terminology (inappropriate for context, inconsistent use), or
(v) other errors.

Output only the new translation and nothing else."""

    translation_2 = get_completion(prompt, system_message)

    print("[åˆæ¬¡ç¿»è¯‘ç»“æœ]: \n", translation_2)

    return { "translation_2": translation_2 }

# è§„åˆ’æ‰§è¡Œä»»åŠ¡
## èŠ‚ç‚¹ï¼ˆnodeï¼‰æ³¨å†Œ
workflow.add_node("initial_translation", initial_translation)
workflow.add_node("reflect_on_translation", reflect_on_translation)
workflow.add_node("improve_translation", improve_translation)
## è¿æ¥èŠ‚ç‚¹
workflow.set_entry_point("initial_translation")
#workflow.add_edge(START, )
workflow.add_edge("initial_translation", "reflect_on_translation")
workflow.add_edge("reflect_on_translation", "improve_translation")
workflow.add_edge("improve_translation", END)

# å¼€å§‹æ‰§è¡Œ
app = workflow.compile()
result = app.invoke({
    "source_lang": "English",
    "target_lang": "ä¸­æ–‡",
    "source_text": """Translation Agent: Agentic translation using reflection workflow
This is a Python demonstration of a reflection agentic workflow for machine translation. The main steps are:

Prompt an LLM to translate a text from source_language to target_language;
Have the LLM reflect on the translation to come up with constructive suggestions for improving it;
Use the suggestions to improve the translation.
Customizability
By using an LLM as the heart of the translation engine, this system is highly steerable. For example, by changing the prompts, it is easier using this workflow than a traditional machine translation (MT) system to:

Modify the output's style, such as formal/informal.
Specify how to handle idioms and special terms like names, technical terms, and acronyms. For example, including a glossary in the prompt lets you make sure particular terms (such as open source, H100 or GPU) are translated consistently.
Specify specific regional use of the language, or specific dialects, to serve a target audience. For example, Spanish spoken in Latin America is different from Spanish spoken in Spain; French spoken in Canada is different from how it is spoken in France.
This is not mature software, and is the result of Andrew playing around with translations on weekends the past few months, plus collaborators (Joaquin Dominguez, Nedelina Teneva, John Santerre) helping refactor the code.

According to our evaluations using BLEU score on traditional translation datasets, this workflow is sometimes competitive with, but also sometimes worse than, leading commercial offerings. However, weâ€™ve also occasionally gotten fantastic results (superior to commercial offerings) with this approach. We think this is just a starting point for agentic translations, and that this is a promising direction for translation, with significant headroom for further improvement, which is why weâ€™re releasing this demonstration to encourage more discussion, experimentation, research and open-source contributions.

If agentic translations can generate better results than traditional architectures (such as an end-to-end transformer that inputs a text and directly outputs a translation) -- which are often faster/cheaper to run than our approach here -- this also provides a mechanism to automatically generate training data (parallel text corpora) that can be used to further train and improve traditional algorithms. (See also this article in The Batch on using LLMs to generate training data.)

Comments and suggestions for how to improve this are very welcome!"""
})

print(result)
```

```python
# ç»˜åˆ¶æµç¨‹å›¾
from mermaid import Mermaid
Mermaid(app.get_graph().draw_mermaid())
```

**Output:**
```
<mermaid.mermaid.Mermaid at 0x7f323ee38a50>
```

### 3.2 Agently Workflow

- Agentlyå®˜ç½‘ï¼š[Agently.cn](https://Agently.cn)
- Agently Workflowä¸LangGraphçš„è¯¦ç»†æ¯”è¾ƒï¼š[ç‚¹å‡»æŸ¥çœ‹](https://github.com/Maplemx/Agently/blob/main/playground/constrast_between_Agently_workflow_and_LangGraph.ipynb)
- Agently Workflowè¯¦ç»†æ•™ç¨‹ï¼š[ç‚¹å‡»æŸ¥çœ‹](https://agently.cn/guides/workflow/index.html)

```python
import json
from ENV import deep_seek_url, deep_seek_api_key, deep_seek_default_model
import Agently
import os 

# å°†æ¨¡å‹è¯·æ±‚é…ç½®è®¾ç½®åˆ°agentå·¥å‚ï¼Œåç»­å·¥å‚åˆ›å»ºçš„agentå¯¹è±¡éƒ½å¯ä»¥ç»§æ‰¿è¿™ä¸ªé…ç½®
agent_factory = (
    Agently.AgentFactory()
        .set_settings("current_model", "OAIClient")
        .set_settings("model.OAIClient.url", deep_seek_url)
        .set_settings("model.OAIClient.auth", { "api_key": deep_seek_api_key })
        .set_settings("model.OAIClient.options", { "model": deep_seek_default_model })
)

# åˆ›å»ºå·¥ä½œæµ
workflow = Agently.Workflow()

# å®šä¹‰å…³é”®å¤„ç†èŠ‚ç‚¹
## é¦–æ¬¡ç¿»è¯‘
@workflow.chunk()
def initial_translation(inputs, storage):
    source_lang = storage.get("source_lang")
    target_lang = storage.get("target_lang")
    source_text = storage.get("source_text")

    # åˆ›å»ºä¸€ä¸ªç¿»è¯‘agentæ¥æ‰§è¡Œä»»åŠ¡
    translate_agent = agent_factory.create_agent()
    
    # ç»™ç¿»è¯‘agentè®¾ç½®systemä¿¡æ¯
    translate_agent.set_agent_prompt(
        "role",
        f"You are an expert linguist, specializing in translation from {source_lang} to {target_lang}."
    )

    # å‘ç¿»è¯‘agentå‘èµ·ç¿»è¯‘ä»»åŠ¡è¯·æ±‚
    translation_1 = (
        translate_agent
        .input(
f"""This is an {source_lang} to {target_lang} translation, please provide the {target_lang} translation for this text. \
Do not provide any explanations or text apart from the translation.
{source_lang}: {source_text}

{target_lang}:"""
        )
        .start()
    )

    # ä¿å­˜ç¿»è¯‘ç»“æœ
    storage.set("translation_1", translation_1)
    # ä¿å­˜ç¿»è¯‘agentå¤‡ç”¨
    storage.set("translate_agent", translate_agent)
    return {
        "stage": "initial translation",
        "result": translation_1
    }

## åæ€ä¼˜åŒ–
@workflow.chunk()
def reflect_on_translation(inputs, storage):
    source_lang = storage.get("source_lang")
    target_lang = storage.get("target_lang")
    source_text = storage.get("source_text")
    country = storage.get("country", "")
    translation_1 = storage.get("translation_1")

    # åˆ›å»ºä¸€ä¸ªåæ€agentæ¥æ‰§è¡Œä»»åŠ¡
    reflection_agent = agent_factory.create_agent()

    # ç»™åæ€agentè®¾ç½®systemä¿¡æ¯
    reflection_agent.set_agent_prompt(
        "role",
        f"You are an expert linguist specializing in translation from {source_lang} to {target_lang}. \
You will be provided with a source text and its translation and your goal is to improve the translation."
    )

    additional_rule = (
        "The final style and tone of the translation should match the style of {target_lang} colloquially spoken in {country}."
        if country != ""
        else ""
    )

    # å‘åæ€agentå‘èµ·åæ€ä»»åŠ¡
    reflection = (
        reflection_agent
            .input(
f"""Your task is to carefully read a source text and a translation from {source_lang} to {target_lang}, and then give constructive criticism and helpful suggestions to improve the translation. \
{additional_rule}

The source text and initial translation, delimited by XML tags <SOURCE_TEXT></SOURCE_TEXT> and <TRANSLATION></TRANSLATION>, are as follows:

<SOURCE_TEXT>
{source_text}
</SOURCE_TEXT>

<TRANSLATION>
{translation_1}
</TRANSLATION>

When writing suggestions, pay attention to whether there are ways to improve the translation's \n\
(i) accuracy (by correcting errors of addition, mistranslation, omission, or untranslated text),\n\
(ii) fluency (by applying {target_lang} grammar, spelling and punctuation rules, and ensuring there are no unnecessary repetitions),\n\
(iii) style (by ensuring the translations reflect the style of the source text and takes into account any cultural context),\n\
(iv) terminology (by ensuring terminology use is consistent and reflects the source text domain; and by only ensuring you use equivalent idioms {target_lang}).\n\

Write a list of specific, helpful and constructive suggestions for improving the translation.
Each suggestion should address one specific part of the translation.
Output only the suggestions and nothing else."""
            )
            .start()
    )

    # ä¿å­˜åæ€ç»“æœ
    storage.set("reflection", reflection)
    return {
        "stage": "reflection",
        "result": reflection
    }

## äºŒæ¬¡ç¿»è¯‘
@workflow.chunk()
def improve_translation(inputs, storage):
    source_lang = storage.get("source_lang")
    target_lang = storage.get("target_lang")
    source_text = storage.get("source_text")
    translation_1 = storage.get("translation_1")
    reflection = storage.get("reflection")

    # ä½¿ç”¨ä¿å­˜ä¸‹æ¥çš„ç¿»è¯‘agent
    translate_agent = storage.get("translate_agent")

    # ç›´æ¥å‘èµ·äºŒæ¬¡ç¿»è¯‘ä»»åŠ¡
    translation_2 = (
        translate_agent
            .input(
f"""Your task is to carefully read, then edit, a translation from {source_lang} to {target_lang}, taking into
account a list of expert suggestions and constructive criticisms.

The source text, the initial translation, and the expert linguist suggestions are delimited by XML tags <SOURCE_TEXT></SOURCE_TEXT>, <TRANSLATION></TRANSLATION> and <EXPERT_SUGGESTIONS></EXPERT_SUGGESTIONS> \
as follows:

<SOURCE_TEXT>
{source_text}
</SOURCE_TEXT>

<TRANSLATION>
{translation_1}
</TRANSLATION>

<EXPERT_SUGGESTIONS>
{reflection}
</EXPERT_SUGGESTIONS>

Please take into account the expert suggestions when editing the translation. Edit the translation by ensuring:

(i) accuracy (by correcting errors of addition, mistranslation, omission, or untranslated text),
(ii) fluency (by applying {target_lang} grammar, spelling and punctuation rules and ensuring there are no unnecessary repetitions), \
(iii) style (by ensuring the translations reflect the style of the source text)
(iv) terminology (inappropriate for context, inconsistent use), or
(v) other errors.

Output only the new translation and nothing else."""
            )
            .start()
    )

    # ä¿å­˜äºŒæ¬¡ç¿»è¯‘ç»“æœ
    storage.set("translation_2", translation_2)
    return {
        "stage": "improve translation",
        "result": translation_2
    }

# è¿æ¥å·¥ä½œå—
(
    workflow
        .connect_to("initial_translation")
        .connect_to("reflect_on_translation")
        .connect_to("improve_translation")
        .connect_to("end")
)

# æ·»åŠ è¿‡ç¨‹è¾“å‡ºä¼˜åŒ–
@workflow.chunk_class()
def output_stage_result(inputs, storage):
    print(f"[{ inputs['default']['stage'] }]:\n", inputs["default"]["result"])
    return

(
    workflow.chunks["initial_translation"]
        .connect_to("@output_stage_result")
        .connect_to("reflect_on_translation.wait")
)
(
    workflow.chunks["reflect_on_translation"]
        .connect_to("@output_stage_result")
        .connect_to("improve_translation.wait")
)
(
    workflow.chunks["improve_translation"]
        .connect_to("@output_stage_result")
)

# å¯åŠ¨å·¥ä½œæµ
result = workflow.start(storage = {
    "source_lang": "English",
    "target_lang": "ä¸­æ–‡",
    "source_text": """Translation Agent: Agentic translation using reflection workflow
This is a Python demonstration of a reflection agentic workflow for machine translation. The main steps are:

Prompt an LLM to translate a text from source_language to target_language;
Have the LLM reflect on the translation to come up with constructive suggestions for improving it;
Use the suggestions to improve the translation.
Customizability
By using an LLM as the heart of the translation engine, this system is highly steerable. For example, by changing the prompts, it is easier using this workflow than a traditional machine translation (MT) system to:

Modify the output's style, such as formal/informal.
Specify how to handle idioms and special terms like names, technical terms, and acronyms. For example, including a glossary in the prompt lets you make sure particular terms (such as open source, H100 or GPU) are translated consistently.
Specify specific regional use of the language, or specific dialects, to serve a target audience. For example, Spanish spoken in Latin America is different from Spanish spoken in Spain; French spoken in Canada is different from how it is spoken in France.
This is not mature software, and is the result of Andrew playing around with translations on weekends the past few months, plus collaborators (Joaquin Dominguez, Nedelina Teneva, John Santerre) helping refactor the code.

According to our evaluations using BLEU score on traditional translation datasets, this workflow is sometimes competitive with, but also sometimes worse than, leading commercial offerings. However, weâ€™ve also occasionally gotten fantastic results (superior to commercial offerings) with this approach. We think this is just a starting point for agentic translations, and that this is a promising direction for translation, with significant headroom for further improvement, which is why weâ€™re releasing this demonstration to encourage more discussion, experimentation, research and open-source contributions.

If agentic translations can generate better results than traditional architectures (such as an end-to-end transformer that inputs a text and directly outputs a translation) -- which are often faster/cheaper to run than our approach here -- this also provides a mechanism to automatically generate training data (parallel text corpora) that can be used to further train and improve traditional algorithms. (See also this article in The Batch on using LLMs to generate training data.)

Comments and suggestions for how to improve this are very welcome!"""
})

# æ‰“å°æ‰§è¡Œç»“æœ
#print(workflow.storage.get("translation_1"))
#print(workflow.storage.get("reflection"))
#print(workflow.storage.get("translation_2"))
print(json.dumps(result, indent=4, ensure_ascii=False))
```

**Output:**
```
[initial translation]:
 ç¿»è¯‘ä»£ç†ï¼šä½¿ç”¨åå°„å·¥ä½œæµçš„ä»£ç†ç¿»è¯‘
è¿™æ˜¯ä¸€ä¸ªå±•ç¤ºæœºå™¨ç¿»è¯‘ä¸­åå°„ä»£ç†å·¥ä½œæµçš„Pythonæ¼”ç¤ºã€‚ä¸»è¦æ­¥éª¤åŒ…æ‹¬ï¼š

1. æç¤ºLLMå°†æ–‡æœ¬ä»æºè¯­è¨€ç¿»è¯‘åˆ°ç›®æ ‡è¯­è¨€ï¼›
2. è®©LLMå¯¹ç¿»è¯‘è¿›è¡Œåæ€ï¼Œæå‡ºæ”¹è¿›å»ºè®®ï¼›
3. åˆ©ç”¨è¿™äº›å»ºè®®æ”¹è¿›ç¿»è¯‘ã€‚

å¯å®šåˆ¶æ€§
é€šè¿‡å°†LLMä½œä¸ºç¿»è¯‘å¼•æ“çš„æ ¸å¿ƒï¼Œè¯¥ç³»ç»Ÿå…·æœ‰é«˜åº¦å¯æ“æ§æ€§ã€‚ä¾‹å¦‚ï¼Œé€šè¿‡æ”¹å˜æç¤ºï¼Œä½¿ç”¨è¿™ç§å·¥ä½œæµæ¯”ä¼ ç»Ÿçš„æœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰ç³»ç»Ÿæ›´å®¹æ˜“ï¼š

- è°ƒæ•´è¾“å‡ºé£æ ¼ï¼Œå¦‚æ­£å¼/éæ­£å¼ã€‚
- æŒ‡å®šå¦‚ä½•å¤„ç†ä¹ è¯­å’Œç‰¹æ®Šæœ¯è¯­ï¼Œå¦‚åç§°ã€æŠ€æœ¯æœ¯è¯­å’Œç¼©ç•¥è¯ã€‚ä¾‹å¦‚ï¼Œåœ¨æç¤ºä¸­åŒ…å«æœ¯è¯­è¡¨å¯ä»¥ç¡®ä¿ç‰¹å®šæœ¯è¯­ï¼ˆå¦‚å¼€æºã€H100æˆ–GPUï¼‰çš„ç¿»è¯‘ä¸€è‡´ã€‚
- æŒ‡å®šç‰¹å®šåœ°åŒºçš„è¯­è¨€ä½¿ç”¨æˆ–ç‰¹å®šæ–¹è¨€ï¼Œä»¥æœåŠ¡ç›®æ ‡å—ä¼—ã€‚ä¾‹å¦‚ï¼Œæ‹‰ä¸ç¾æ´²çš„è¥¿ç­ç‰™è¯­ä¸è¥¿ç­ç‰™çš„è¥¿ç­ç‰™è¯­ä¸åŒï¼›åŠ æ‹¿å¤§çš„æ³•è¯­ä¸æ³•å›½çš„æ³•è¯­ä¸åŒã€‚

è¿™ä¸æ˜¯æˆç†Ÿçš„è½¯ä»¶ï¼Œæ˜¯Andrewåœ¨è¿‡å»å‡ ä¸ªæœˆçš„å‘¨æœ«ç©è½¬ç¿»è¯‘çš„ç»“æœï¼ŒåŠ ä¸Šåˆä½œè€…ï¼ˆJoaquin Dominguezã€Nedelina Tenevaã€John Santerreï¼‰å¸®åŠ©é‡æ„ä»£ç ã€‚

æ ¹æ®æˆ‘ä»¬ä½¿ç”¨BLEUè¯„åˆ†åœ¨ä¼ ç»Ÿç¿»è¯‘æ•°æ®é›†ä¸Šçš„è¯„ä¼°ï¼Œè¿™ç§å·¥ä½œæµæœ‰æ—¶ä¸é¢†å…ˆçš„å•†ä¸šäº§å“ç«äº‰ï¼Œæœ‰æ—¶ä¹Ÿè¡¨ç°ä¸å¦‚å®ƒä»¬ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬ä¹Ÿå¶å°”é€šè¿‡è¿™ç§æ–¹æ³•è·å¾—äº†æ¯”å•†ä¸šäº§å“æ›´å‡ºè‰²çš„ç»“æœã€‚æˆ‘ä»¬è®¤ä¸ºè¿™åªæ˜¯ä»£ç†ç¿»è¯‘çš„èµ·ç‚¹ï¼Œè¿™æ˜¯ä¸€ä¸ªæœ‰å‰é€”çš„ç¿»è¯‘æ–¹å‘ï¼Œæœ‰æ˜¾è‘—çš„æ”¹è¿›ç©ºé—´ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘ä»¬å‘å¸ƒè¿™ä¸ªæ¼”ç¤ºä»¥é¼“åŠ±æ›´å¤šè®¨è®ºã€å®éªŒã€ç ”ç©¶å’Œå¼€æºè´¡çŒ®çš„åŸå› ã€‚

å¦‚æœä»£ç†ç¿»è¯‘èƒ½äº§ç”Ÿæ¯”ä¼ ç»Ÿæ¶æ„ï¼ˆå¦‚è¾“å…¥æ–‡æœ¬å¹¶ç›´æ¥è¾“å‡ºç¿»è¯‘çš„ç«¯åˆ°ç«¯è½¬æ¢å™¨ï¼‰æ›´å¥½çš„ç»“æœâ€”â€”è¿™äº›æ¶æ„é€šå¸¸æ¯”æˆ‘ä»¬çš„æ–¹æ³•æ›´å¿«/æ›´ä¾¿å®œâ€”â€”è¿™ä¹Ÿæä¾›äº†ä¸€ç§è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆå¹³è¡Œæ–‡æœ¬è¯­æ–™åº“ï¼‰çš„æœºåˆ¶ï¼Œå¯ç”¨äºè¿›ä¸€æ­¥è®­ç»ƒå’Œæ”¹è¿›ä¼ ç»Ÿç®—æ³•ã€‚ï¼ˆå¦è§ã€ŠThe Batchã€‹ä¸­å…³äºä½¿ç”¨LLMç”Ÿæˆè®­ç»ƒæ•°æ®çš„æ–‡ç« ã€‚ï¼‰

éå¸¸æ¬¢è¿å¯¹å¦‚ä½•æ”¹è¿›çš„æ„è§å’Œå»ºè®®ï¼
[reflection]:
 1. å°†â€œç¿»è¯‘ä»£ç†ï¼šä½¿ç”¨åå°„å·¥ä½œæµçš„ä»£ç†ç¿»è¯‘â€æ”¹ä¸ºâ€œä»£ç†ç¿»è¯‘ï¼šåˆ©ç”¨åå°„å·¥ä½œæµçš„ç¿»è¯‘ä»£ç†â€ï¼Œä»¥æ›´ç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯ã€‚
2. å°†â€œè¿™æ˜¯ä¸€ä¸ªå±•ç¤ºæœºå™¨ç¿»è¯‘ä¸­åå°„ä»£ç†å·¥ä½œæµçš„Pythonæ¼”ç¤ºã€‚â€æ”¹ä¸ºâ€œè¿™æ˜¯ä¸€ä¸ªå±•ç¤ºåˆ©ç”¨åå°„å·¥ä½œæµè¿›è¡Œæœºå™¨ç¿»è¯‘çš„Pythonæ¼”ç¤ºã€‚â€ï¼Œä»¥æé«˜è¯­å¥çš„æµç•…æ€§å’Œå‡†ç¡®æ€§ã€‚
3. å°†â€œé€šè¿‡å°†LLMä½œä¸ºç¿»è¯‘å¼•æ“çš„æ ¸å¿ƒï¼Œè¯¥ç³»ç»Ÿå…·æœ‰é«˜åº¦å¯æ“æ§æ€§ã€‚â€æ”¹ä¸ºâ€œé€šè¿‡å°†LLMç½®äºç¿»è¯‘å¼•æ“çš„æ ¸å¿ƒï¼Œè¯¥ç³»ç»Ÿå±•ç°å‡ºé«˜åº¦å¯æ“æ§æ€§ã€‚â€ï¼Œä»¥å¢å¼ºè¯­å¥çš„æµç•…æ€§ã€‚
4. å°†â€œä¾‹å¦‚ï¼Œé€šè¿‡æ”¹å˜æç¤ºï¼Œä½¿ç”¨è¿™ç§å·¥ä½œæµæ¯”ä¼ ç»Ÿçš„æœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰ç³»ç»Ÿæ›´å®¹æ˜“ï¼šâ€æ”¹ä¸ºâ€œä¾‹å¦‚ï¼Œé€šè¿‡è°ƒæ•´æç¤ºï¼Œä½¿ç”¨è¿™ç§å·¥ä½œæµæ¯”ä¼ ç»Ÿæœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰ç³»ç»Ÿæ›´ä¸ºä¾¿æ·ï¼šâ€ï¼Œä»¥æé«˜è¯­å¥çš„å‡†ç¡®æ€§å’Œæµç•…æ€§ã€‚
5. å°†â€œè¿™ä¸æ˜¯æˆç†Ÿçš„è½¯ä»¶ï¼Œæ˜¯Andrewåœ¨è¿‡å»å‡ ä¸ªæœˆçš„å‘¨æœ«ç©è½¬ç¿»è¯‘çš„ç»“æœï¼ŒåŠ ä¸Šåˆä½œè€…ï¼ˆJoaquin Dominguezã€Nedelina Tenevaã€John Santerreï¼‰å¸®åŠ©é‡æ„ä»£ç ã€‚â€æ”¹ä¸ºâ€œè¿™ä¸æ˜¯ä¸€æ¬¾æˆç†Ÿçš„è½¯ä»¶ï¼Œè€Œæ˜¯Andrewåœ¨è¿‡å»å‡ ä¸ªæœˆçš„å‘¨æœ«è¿›è¡Œç¿»è¯‘å®éªŒçš„æˆæœï¼Œä»¥åŠåˆä½œè€…ï¼ˆJoaquin Dominguezã€Nedelina Tenevaã€John Santerreï¼‰ååŠ©é‡æ„ä»£ç çš„ç»“æœã€‚â€ï¼Œä»¥æé«˜è¯­å¥çš„å‡†ç¡®æ€§å’Œæµç•…æ€§ã€‚
6. å°†â€œæ ¹æ®æˆ‘ä»¬ä½¿ç”¨BLEUè¯„åˆ†åœ¨ä¼ ç»Ÿç¿»è¯‘æ•°æ®é›†ä¸Šçš„è¯„ä¼°ï¼Œè¿™ç§å·¥ä½œæµæœ‰æ—¶ä¸é¢†å…ˆçš„å•†ä¸šäº§å“ç«äº‰ï¼Œæœ‰æ—¶ä¹Ÿè¡¨ç°ä¸å¦‚å®ƒä»¬ã€‚â€æ”¹ä¸ºâ€œæ ¹æ®æˆ‘ä»¬ä½¿ç”¨BLEUè¯„åˆ†åœ¨ä¼ ç»Ÿç¿»è¯‘æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœï¼Œè¿™ç§å·¥ä½œæµæœ‰æ—¶èƒ½ä¸é¢†å…ˆå•†ä¸šäº§å“ç«äº‰ï¼Œæœ‰æ—¶åˆ™è¡¨ç°ä¸åŠå®ƒä»¬ã€‚â€ï¼Œä»¥æé«˜è¯­å¥çš„å‡†ç¡®æ€§å’Œæµç•…æ€§ã€‚
7. å°†â€œå¦‚æœä»£ç†ç¿»è¯‘èƒ½äº§ç”Ÿæ¯”ä¼ ç»Ÿæ¶æ„ï¼ˆå¦‚è¾“å…¥æ–‡æœ¬å¹¶ç›´æ¥è¾“å‡ºç¿»è¯‘çš„ç«¯åˆ°ç«¯è½¬æ¢å™¨ï¼‰æ›´å¥½çš„ç»“æœâ€”â€”è¿™äº›æ¶æ„é€šå¸¸æ¯”æˆ‘ä»¬çš„æ–¹æ³•æ›´å¿«/æ›´ä¾¿å®œâ€”â€”è¿™ä¹Ÿæä¾›äº†ä¸€ç§è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆå¹³è¡Œæ–‡æœ¬è¯­æ–™åº“ï¼‰çš„æœºåˆ¶ï¼Œå¯ç”¨äºè¿›ä¸€æ­¥è®­ç»ƒå’Œæ”¹è¿›ä¼ ç»Ÿç®—æ³•ã€‚â€æ”¹ä¸ºâ€œå¦‚æœä»£ç†ç¿»è¯‘èƒ½äº§ç”Ÿæ¯”ä¼ ç»Ÿæ¶æ„ï¼ˆä¾‹å¦‚è¾“å…¥æ–‡æœ¬å¹¶ç›´æ¥è¾“å‡ºç¿»è¯‘çš„ç«¯åˆ°ç«¯è½¬æ¢å™¨ï¼‰æ›´ä¼˜çš„ç»“æœâ€”â€”è¿™äº›æ¶æ„é€šå¸¸æ¯”æˆ‘ä»¬çš„æ–¹æ³•æ›´å¿«/æ›´ç»æµâ€”â€”è¿™ä¹Ÿæä¾›äº†ä¸€ç§è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆå¹³è¡Œæ–‡æœ¬è¯­æ–™åº“ï¼‰çš„æœºåˆ¶ï¼Œå¯ç”¨äºè¿›ä¸€æ­¥è®­ç»ƒå’Œä¼˜åŒ–ä¼ ç»Ÿç®—æ³•ã€‚â€ï¼Œä»¥æé«˜è¯­å¥çš„å‡†ç¡®æ€§å’Œæµç•…æ€§ã€‚
8. å°†â€œéå¸¸æ¬¢è¿å¯¹å¦‚ä½•æ”¹è¿›çš„æ„è§å’Œå»ºè®®ï¼â€æ”¹ä¸ºâ€œæˆ‘ä»¬éå¸¸æ¬¢è¿å…³äºå¦‚ä½•æ”¹è¿›çš„æ„è§å’Œå»ºè®®ï¼â€ï¼Œä»¥å¢å¼ºè¯­å¥çš„æ­£å¼æ€§å’Œæµç•…æ€§ã€‚
[improve translation]:
 ä»£ç†ç¿»è¯‘ï¼šåˆ©ç”¨åå°„å·¥ä½œæµçš„ç¿»è¯‘ä»£ç†
è¿™æ˜¯ä¸€ä¸ªå±•ç¤ºåˆ©ç”¨åå°„å·¥ä½œæµè¿›è¡Œæœºå™¨ç¿»è¯‘çš„Pythonæ¼”ç¤ºã€‚ä¸»è¦æ­¥éª¤åŒ…æ‹¬ï¼š

1. æç¤ºLLMå°†æ–‡æœ¬ä»æºè¯­è¨€ç¿»è¯‘åˆ°ç›®æ ‡è¯­è¨€ï¼›
2. è®©LLMå¯¹ç¿»è¯‘è¿›è¡Œåæ€ï¼Œæå‡ºæ”¹è¿›å»ºè®®ï¼›
3. åˆ©ç”¨è¿™äº›å»ºè®®æ”¹è¿›ç¿»è¯‘ã€‚

å¯å®šåˆ¶æ€§
é€šè¿‡å°†LLMç½®äºç¿»è¯‘å¼•æ“çš„æ ¸å¿ƒï¼Œè¯¥ç³»ç»Ÿå±•ç°å‡ºé«˜åº¦å¯æ“æ§æ€§ã€‚ä¾‹å¦‚ï¼Œé€šè¿‡è°ƒæ•´æç¤ºï¼Œä½¿ç”¨è¿™ç§å·¥ä½œæµæ¯”ä¼ ç»Ÿæœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰ç³»ç»Ÿæ›´ä¸ºä¾¿æ·ï¼š

- è°ƒæ•´è¾“å‡ºé£æ ¼ï¼Œå¦‚æ­£å¼/éæ­£å¼ã€‚
- æŒ‡å®šå¦‚ä½•å¤„ç†ä¹ è¯­å’Œç‰¹æ®Šæœ¯è¯­ï¼Œå¦‚åç§°ã€æŠ€æœ¯æœ¯è¯­å’Œç¼©ç•¥è¯ã€‚ä¾‹å¦‚ï¼Œåœ¨æç¤ºä¸­åŒ…å«æœ¯è¯­è¡¨å¯ä»¥ç¡®ä¿ç‰¹å®šæœ¯è¯­ï¼ˆå¦‚å¼€æºã€H100æˆ–GPUï¼‰çš„ç¿»è¯‘ä¸€è‡´ã€‚
- æŒ‡å®šç‰¹å®šåœ°åŒºçš„è¯­è¨€ä½¿ç”¨æˆ–ç‰¹å®šæ–¹è¨€ï¼Œä»¥æœåŠ¡ç›®æ ‡å—ä¼—ã€‚ä¾‹å¦‚ï¼Œæ‹‰ä¸ç¾æ´²çš„è¥¿ç­ç‰™è¯­ä¸è¥¿ç­ç‰™çš„è¥¿ç­ç‰™è¯­ä¸åŒï¼›åŠ æ‹¿å¤§çš„æ³•è¯­ä¸æ³•å›½çš„æ³•è¯­ä¸åŒã€‚

è¿™ä¸æ˜¯ä¸€æ¬¾æˆç†Ÿçš„è½¯ä»¶ï¼Œè€Œæ˜¯Andrewåœ¨è¿‡å»å‡ ä¸ªæœˆçš„å‘¨æœ«è¿›è¡Œç¿»è¯‘å®éªŒçš„æˆæœï¼Œä»¥åŠåˆä½œè€…ï¼ˆJoaquin Dominguezã€Nedelina Tenevaã€John Santerreï¼‰ååŠ©é‡æ„ä»£ç çš„ç»“æœã€‚

æ ¹æ®æˆ‘ä»¬ä½¿ç”¨BLEUè¯„åˆ†åœ¨ä¼ ç»Ÿç¿»è¯‘æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœï¼Œè¿™ç§å·¥ä½œæµæœ‰æ—¶èƒ½ä¸é¢†å…ˆå•†ä¸šäº§å“ç«äº‰ï¼Œæœ‰æ—¶åˆ™è¡¨ç°ä¸åŠå®ƒä»¬ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬ä¹Ÿå¶å°”é€šè¿‡è¿™ç§æ–¹æ³•è·å¾—äº†æ¯”å•†ä¸šäº§å“æ›´å‡ºè‰²çš„ç»“æœã€‚æˆ‘ä»¬è®¤ä¸ºè¿™åªæ˜¯ä»£ç†ç¿»è¯‘çš„èµ·ç‚¹ï¼Œè¿™æ˜¯ä¸€ä¸ªæœ‰å‰é€”çš„ç¿»è¯‘æ–¹å‘ï¼Œæœ‰æ˜¾è‘—çš„æ”¹è¿›ç©ºé—´ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘ä»¬å‘å¸ƒè¿™ä¸ªæ¼”ç¤ºä»¥é¼“åŠ±æ›´å¤šè®¨è®ºã€å®éªŒã€ç ”ç©¶å’Œå¼€æºè´¡çŒ®çš„åŸå› ã€‚

å¦‚æœä»£ç†ç¿»è¯‘èƒ½äº§ç”Ÿæ¯”ä¼ ç»Ÿæ¶æ„ï¼ˆä¾‹å¦‚è¾“å…¥æ–‡æœ¬å¹¶ç›´æ¥è¾“å‡ºç¿»è¯‘çš„ç«¯åˆ°ç«¯è½¬æ¢å™¨ï¼‰æ›´ä¼˜çš„ç»“æœâ€”â€”è¿™äº›æ¶æ„é€šå¸¸æ¯”æˆ‘ä»¬çš„æ–¹æ³•æ›´å¿«/æ›´ç»æµâ€”â€”è¿™ä¹Ÿæä¾›äº†ä¸€ç§è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆå¹³è¡Œæ–‡æœ¬è¯­æ–™åº“ï¼‰çš„æœºåˆ¶ï¼Œå¯ç”¨äºè¿›ä¸€æ­¥è®­ç»ƒå’Œä¼˜åŒ–ä¼ ç»Ÿç®—æ³•ã€‚ï¼ˆå¦è§ã€ŠThe Batchã€‹ä¸­å…³äºä½¿ç”¨LLMç”Ÿæˆè®­ç»ƒæ•°æ®çš„æ–‡ç« ã€‚ï¼‰

æˆ‘ä»¬éå¸¸æ¬¢è¿å…³äºå¦‚ä½•æ”¹è¿›çš„æ„è§å’Œå»ºè®®ï¼
{
    "default": {
        "stage": "improve translation",
        "result": "ä»£ç†ç¿»è¯‘ï¼šåˆ©ç”¨åå°„å·¥ä½œæµçš„ç¿»è¯‘ä»£ç†\nè¿™æ˜¯ä¸€ä¸ªå±•ç¤ºåˆ©ç”¨åå°„å·¥ä½œæµè¿›è¡Œæœºå™¨ç¿»è¯‘çš„Pythonæ¼”ç¤ºã€‚ä¸»è¦æ­¥éª¤åŒ…æ‹¬ï¼š\n\n1. æç¤ºLLMå°†æ–‡æœ¬ä»æºè¯­è¨€ç¿»è¯‘åˆ°ç›®æ ‡è¯­è¨€ï¼›\n2. è®©LLMå¯¹ç¿»è¯‘è¿›è¡Œåæ€ï¼Œæå‡ºæ”¹è¿›å»ºè®®ï¼›\n3. åˆ©ç”¨è¿™äº›å»ºè®®æ”¹è¿›ç¿»è¯‘ã€‚\n\nå¯å®šåˆ¶æ€§\né€šè¿‡å°†LLMç½®äºç¿»è¯‘å¼•æ“çš„æ ¸å¿ƒï¼Œè¯¥ç³»ç»Ÿå±•ç°å‡ºé«˜åº¦å¯æ“æ§æ€§ã€‚ä¾‹å¦‚ï¼Œé€šè¿‡è°ƒæ•´æç¤ºï¼Œä½¿ç”¨è¿™ç§å·¥ä½œæµæ¯”ä¼ ç»Ÿæœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰ç³»ç»Ÿæ›´ä¸ºä¾¿æ·ï¼š\n\n- è°ƒæ•´è¾“å‡ºé£æ ¼ï¼Œå¦‚æ­£å¼/éæ­£å¼ã€‚\n- æŒ‡å®šå¦‚ä½•å¤„ç†ä¹ è¯­å’Œç‰¹æ®Šæœ¯è¯­ï¼Œå¦‚åç§°ã€æŠ€æœ¯æœ¯è¯­å’Œç¼©ç•¥è¯ã€‚ä¾‹å¦‚ï¼Œåœ¨æç¤ºä¸­åŒ…å«æœ¯è¯­è¡¨å¯ä»¥ç¡®ä¿ç‰¹å®šæœ¯è¯­ï¼ˆå¦‚å¼€æºã€H100æˆ–GPUï¼‰çš„ç¿»è¯‘ä¸€è‡´ã€‚\n- æŒ‡å®šç‰¹å®šåœ°åŒºçš„è¯­è¨€ä½¿ç”¨æˆ–ç‰¹å®šæ–¹è¨€ï¼Œä»¥æœåŠ¡ç›®æ ‡å—ä¼—ã€‚ä¾‹å¦‚ï¼Œæ‹‰ä¸ç¾æ´²çš„è¥¿ç­ç‰™è¯­ä¸è¥¿ç­ç‰™çš„è¥¿ç­ç‰™è¯­ä¸åŒï¼›åŠ æ‹¿å¤§çš„æ³•è¯­ä¸æ³•å›½çš„æ³•è¯­ä¸åŒã€‚\n\nè¿™ä¸æ˜¯ä¸€æ¬¾æˆç†Ÿçš„è½¯ä»¶ï¼Œè€Œæ˜¯Andrewåœ¨è¿‡å»å‡ ä¸ªæœˆçš„å‘¨æœ«è¿›è¡Œç¿»è¯‘å®éªŒçš„æˆæœï¼Œä»¥åŠåˆä½œè€…ï¼ˆJoaquin Dominguezã€Nedelina Tenevaã€John Santerreï¼‰ååŠ©é‡æ„ä»£ç çš„ç»“æœã€‚\n\næ ¹æ®æˆ‘ä»¬ä½¿ç”¨BLEUè¯„åˆ†åœ¨ä¼ ç»Ÿç¿»è¯‘æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœï¼Œè¿™ç§å·¥ä½œæµæœ‰æ—¶èƒ½ä¸é¢†å…ˆå•†ä¸šäº§å“ç«äº‰ï¼Œæœ‰æ—¶åˆ™è¡¨ç°ä¸åŠå®ƒä»¬ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬ä¹Ÿå¶å°”é€šè¿‡è¿™ç§æ–¹æ³•è·å¾—äº†æ¯”å•†ä¸šäº§å“æ›´å‡ºè‰²çš„ç»“æœã€‚æˆ‘ä»¬è®¤ä¸ºè¿™åªæ˜¯ä»£ç†ç¿»è¯‘çš„èµ·ç‚¹ï¼Œè¿™æ˜¯ä¸€ä¸ªæœ‰å‰é€”çš„ç¿»è¯‘æ–¹å‘ï¼Œæœ‰æ˜¾è‘—çš„æ”¹è¿›ç©ºé—´ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘ä»¬å‘å¸ƒè¿™ä¸ªæ¼”ç¤ºä»¥é¼“åŠ±æ›´å¤šè®¨è®ºã€å®éªŒã€ç ”ç©¶å’Œå¼€æºè´¡çŒ®çš„åŸå› ã€‚\n\nå¦‚æœä»£ç†ç¿»è¯‘èƒ½äº§ç”Ÿæ¯”ä¼ ç»Ÿæ¶æ„ï¼ˆä¾‹å¦‚è¾“å…¥æ–‡æœ¬å¹¶ç›´æ¥è¾“å‡ºç¿»è¯‘çš„ç«¯åˆ°ç«¯è½¬æ¢å™¨ï¼‰æ›´ä¼˜çš„ç»“æœâ€”â€”è¿™äº›æ¶æ„é€šå¸¸æ¯”æˆ‘ä»¬çš„æ–¹æ³•æ›´å¿«/æ›´ç»æµâ€”â€”è¿™ä¹Ÿæä¾›äº†ä¸€ç§è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆå¹³è¡Œæ–‡æœ¬è¯­æ–™åº“ï¼‰çš„æœºåˆ¶ï¼Œå¯ç”¨äºè¿›ä¸€æ­¥è®­ç»ƒå’Œä¼˜åŒ–ä¼ ç»Ÿç®—æ³•ã€‚ï¼ˆå¦è§ã€ŠThe Batchã€‹ä¸­å…³äºä½¿ç”¨LLMç”Ÿæˆè®­ç»ƒæ•°æ®çš„æ–‡ç« ã€‚ï¼‰\n\næˆ‘ä»¬éå¸¸æ¬¢è¿å…³äºå¦‚ä½•æ”¹è¿›çš„æ„è§å’Œå»ºè®®ï¼"
    }
}
```

```python
print(workflow.draw())
```

**Output:**
```
%%{ init: { 'flowchart': { 'curve': 'linear' }, 'theme': 'neutral' } }%%
%% Rendered By Agently %%
flowchart LR
classDef chunk_style fill:#fbfcdb,stroke:#666,stroke-width:1px,color:#333;
classDef loop_style fill:#f5f7fa,stroke:#666,stroke-width:1px,color:#333,stroke-dasharray: 5 5
    f5667478-2ef6-48b3-806c-1a29df1c343f("start"):::chunk_style -.-> |"* -->-- default"| aa45d001-0a9b-4724-926b-b81bc04b87a3("initial_translation"):::chunk_style
    aa45d001-0a9b-4724-926b-b81bc04b87a3("initial_translation"):::chunk_style -.-> |"* -->-- default"| d1933f62-80c0-473e-9eaf-56b5d025a22d("reflect_on_translation"):::chunk_style
    d1933f62-80c0-473e-9eaf-56b5d025a22d("reflect_on_translation"):::chunk_style -.-> |"* -->-- default"| 90d4411d-505d-41d8-9519-a54e8c3ad833("improve_translation"):::chunk_style
    90d4411d-505d-41d8-9519-a54e8c3ad833("improve_translation"):::chunk_style -.-> |"* -->-- default"| 17a88c3b-ed5f-4ae3-b5eb-551505a3c8f3("end"):::chunk_style
    aa45d001-0a9b-4724-926b-b81bc04b87a3("initial_translation"):::chunk_style -.-> |"* -->-- default"| 83b817af-86e9-4c15-8bfc-a0a4cc1be58e("@output_stage_result"):::chunk_style
    83b817af-86e9-4c15-8bfc-a0a4cc1be58e("@output_stage_result"):::chunk_style -.-> |"* -->-- wait"| d1933f62-80c0-473e-9eaf-56b5d025a22d("reflect_on_translation"):::chunk_style
    d1933f62-80c0-473e-9eaf-56b5d025a22d("reflect_on_translation"):::chunk_style -.-> |"* -->-- default"| 0cd60452-a39d-4f36-8e7b-9d9c395c055f("@output_stage_result"):::chunk_style
    0cd60452-a39d-4f36-8e7b-9d9c395c055f("@output_stage_result"):::chunk_style -.-> |"* -->-- wait"| 90d4411d-505d-41d8-9519-a54e8c3ad833("improve_translation"):::chunk_style
    90d4411d-505d-41d8-9519-a54e8c3ad833("improve_translation"):::chunk_style -.-> |"* -->-- default"| 5cf69740-8561-4f89-9f7d-49eabad65388("@output_stage_result"):::chunk_style
```

<img width="1440" src="./Agently_Translation.jpg" />

## å››ã€å¤§æ¨¡å‹åº”ç”¨å·¥ä½œæµçš„å…³é”®è¦ç´ è§£æ

### 4.1 åŸºæœ¬è¦ç´ 

- å·¥ä½œæµåŸºæœ¬è¦ç´ 
    - ğŸŸ© å·¥ä½œå—/å·¥ä½œèŠ‚ç‚¹
    - ğŸ”€ è¿æ¥å…³ç³»
        - æ™®é€šè¿æ¥
        - æ¡ä»¶è¿æ¥
    - ğŸ“¡ æ•°æ®é€šè®¯
        - å—é—´æ•°æ®ä¼ é€’
        - å·¥ä½œæµå†…æ•°æ®ä¼ é€’

<img width="768" src="./basic_elements.png" />

### 4.2 å¤§æ¨¡å‹åº”ç”¨å·¥ä½œæµéœ€è¦å…·å¤‡çš„ç‰¹æ€§

- **ğŸ’« èƒ½å¤Ÿæˆç¯**

  ä»¥æ”¯æŒåœ¨ç‰¹å®šå·¥ä½œç¯ï¼ˆå¤šæ­¥å·¥ä½œï¼‰ä¸­åå¤å°è¯•ï¼Œå°è¯•ç»“æœä¸ç¬¦åˆé¢„æœŸå¯ä»¥å›åˆ°ç¬¬ä¸€æ­¥é‡è¯•
  
- **ğŸ›œ èƒ½å¤ŸæŒ‰æ¡ä»¶åˆ†å‘**

  ä»¥æ”¯æŒæ„å›¾è¯†åˆ«ã€è·¯å¾„è§„åˆ’ã€å·¥å…·é€‰æ‹©ã€å¤šagentè·¯ç”±ç­‰åœºæ™¯ä¸­ï¼Œæ ¹æ®æ¨ç†ç»“æœè¿›å…¥ä¸åŒçš„ä¸‹æ¸¸å·¥ä½œæµï¼ŒåŒæ—¶ä¹Ÿèƒ½æ”¯æŒç¬¦åˆç‰¹å®šæ¡ä»¶åè·³å‡ºç¯

- **â­ï¸ èƒ½å¤Ÿå¤šåˆ†æ”¯å¹¶è¡Œæ‰§è¡Œå¹¶åœ¨ç»ˆç‚¹è¢«ç­‰å¾…**

  ä»¥æ”¯æŒé¢å¯¹å¤æ‚ä»»åŠ¡æ—¶ï¼Œèƒ½å¤Ÿå‘èµ·ä¸åŒåˆ†æ”¯ä»ä¸åŒå¤„ç†è§’åº¦/ç”¨ä¸åŒå¤„ç†æ–¹å¼å¯¹ä»»åŠ¡è¿›è¡Œå¤„ç†

- **ğŸ“‹ èƒ½å¤Ÿå¯¹åˆ—è¡¨å‹æ•°æ®è¿›è¡Œæ‹†åˆ†å¤„ç†å¹¶å›æ”¶å¤„ç†ç»“æœ**

  ä¾‹å¦‚ç”Ÿæˆè¡ŒåŠ¨æ¸…å•ã€æçº²ç­‰åˆ—è¡¨æ€§è´¨çš„ç»“æœåï¼Œæ ¹æ®åˆ—è¡¨é¡¹è¿›è¡Œé€é¡¹å¤„ç†ï¼Œæˆ–æ‰§è¡Œç±»ä¼¼Map-Reduceçš„é€»è¾‘
  
- **ğŸ“¡ å¯åœ¨å·¥ä½œæµä¸­è¿›è¡Œå¤æ‚é€šè®¯**ï¼š
  
    - **ğŸ›°ï¸ ä½¿ç”¨å…¨å±€ç¯å¢ƒæ•°æ®é€šè®¯**

      å·¥ä½œæµç›¸å½“äºæä¾›äº†ä¸€ä¸ªå¤æ‚çš„æ²™ç›’ç¯å¢ƒï¼Œæ²™ç›’ç¯å¢ƒä¸­çš„å…¨å±€ç¯å¢ƒæ•°æ®ä¼šå½±å“å·¥ä½œæµè¿è¡ŒçŠ¶æ€ï¼Œå¹¶å­˜å‚¨å·¥ä½œæµè¿è¡Œè¿‡ç¨‹ä¸­çš„è¿‡ç¨‹æ•°æ®å’Œæœ€ç»ˆæˆæœ
      
    - **ğŸ“¨ å·¥ä½œå—é—´è¿è¡Œä¸Šä¸‹æ¸¸é€šè®¯**

      åœ¨å¤æ‚å·¥ä½œæµä¸­ï¼Œå¦‚æœæ‰€æœ‰çš„æ•°æ®éƒ½ä½¿ç”¨å…¨å±€ç¯å¢ƒæ•°æ®é€šè®¯ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒå·¥ä½œå—ä¸­å¯¹åŒä¸€ä¸ªé”®æŒ‡å‘çš„æ•°æ®è¿›è¡Œæ“ä½œæ—¶ï¼Œä¼šå› ä¸ºå¯¹è¿è¡Œæ—¶åºçš„åˆ¤æ–­å›°éš¾è€Œå¯¼è‡´æ•°æ®ç®¡ç†æ··ä¹±ï¼Œè¿™æ—¶å€™ï¼Œéœ€è¦é€šè¿‡å—é—´æ•°æ®ä¼ é€’æ¥ç¡®ä¿æ•°æ®å˜åŒ–ä¸è¿è¡Œæ—¶åºæœŸæœ›ä¸€è‡´ï¼Œç”¨å¤§ç™½è¯è¯´ï¼Œå°±æ˜¯ç¡®ä¿â€œå—2â€èƒ½å¤Ÿæ­£ç¡®ä½¿ç”¨å®ƒçš„å‰ä¸€ä¸ªå—â€œå—1â€ç”Ÿæˆçš„æ•°æ®è¿›è¡Œå·¥ä½œã€‚

### 4.3 LangGraphçš„å·¥ä½œæµè¦ç´ å›¾ç¤º

<img width="1024" src="./LangGraph_key_features.png" />

### 4.4 Agently Workflowçš„å·¥ä½œæµè¦ç´ å›¾ç¤º

<img width="1024" src="./Agently_Workflow_key_features.png" />

### 4.5 LangGraphå’ŒAgently Workflowçš„èƒ½åŠ›å¯¹æ¯”è¡¨

|èƒ½åŠ›é¡¹|LangGraph|Agently Workflow|
|---|---|---|
|å…è®¸æˆç¯|âœ…|âœ…|
|æŒ‰æ¡ä»¶åˆ†å‘|âœ…|âœ…|
|å¹¶è¡Œåˆ†æ”¯|âŒ|âœ…|
|åˆ—è¡¨æ‹†è§£|ğŸŸ å¯ä»¥é€šè¿‡Send+conditional_edgesç”¨è¾ƒä¸ºå¤æ‚çš„æ–¹å¼è§£å†³|âœ…|
|å…¨å±€ç¯å¢ƒé€šè®¯|âœ…|âœ…|
|å·¥ä½œå—ä¸Šä¸‹æ¸¸é€šè®¯|âŒ|âœ…|

æ›´è¯¦ç»†å¯¹æ¯”å¯[è®¿é—®æ­¤é¡µé¢äº†è§£](https://github.com/Maplemx/Agently/blob/main/playground/constrast_between_Agently_workflow_and_LangGraph.ipynb)

## äº”ã€å¤æ‚çš„å·¥ä½œæµï¼šæ•…äº‹åˆ›ä½œ

### 5.1 è®¾è®¡æ€è·¯

<img width="1024" src="./story_design.png"/>

### 5.2 å®ç°æ–¹æ¡ˆ

```python
import json
from ENV import deep_seek_url, deep_seek_api_key, deep_seek_default_model
import Agently
import os 

# åˆ›å»ºä¸€ä¸ªä½œå®¶agent

writer = (
    Agently.create_agent()
        .set_settings("current_model", "OAIClient")
        .set_settings("model.OAIClient.url", os.environ["DEEPSEEK_BASE_URL"])
        .set_settings("model.OAIClient.auth", { "api_key": os.environ["DEEPSEEK_API_KEY"] })
        .set_settings("model.OAIClient.options", { "model": os.environ["DEEP_SEEK_DEFAULT_MODEL"] })
)

# åˆ›å»ºä¸¤ä¸ªå·¥ä½œæµï¼šä¸»å·¥ä½œæµå’Œåˆ†å—åˆ›ä½œå·¥ä½œæµ
main_workflow = Agently.Workflow()
block_workflow = Agently.Workflow()

# å®šä¹‰ä¸»å·¥ä½œæµçš„å·¥ä½œå—
## è¾“å…¥ä¸€å¥è¯æè¿°
@main_workflow.chunk()
def input_story_idea(inputs, storage):
    storage.set("story_idea", input("[ğŸ’¡è¯·è¾“å…¥æ‚¨çš„æ•…äº‹çµæ„Ÿ]: "))
    return

## åˆ›å»ºä¸–ç•Œè§‚èƒŒæ™¯æ•…äº‹
@main_workflow.chunk()
def generate_background(inputs, storage):
    story_idea = storage.get("story_idea")
    background = (
        writer
            .input({
                "æ•…äº‹çµæ„Ÿ": story_idea
            })
            .instruct(
"""è¯·æ ¹æ®{æ•…äº‹çµæ„Ÿ}åˆ›ä½œæ•…äº‹çš„ä¸–ç•Œä¿¡æ¯å’ŒèƒŒæ™¯æ•…äº‹ï¼Œå…¶ä¸­ï¼š
ä¸–ç•Œä¿¡æ¯éœ€è¦åŒ…æ‹¬ä¸–ç•Œçš„ä¸»è¦å›½å®¶æˆ–åœ°åŒºåˆ†å¸ƒï¼Œä¸åŒå›½å®¶æˆ–åœ°åŒºçš„ç¯å¢ƒæå†™ï¼Œç§‘æŠ€æ°´å¹³ï¼Œä¿¡ä»°æƒ…å†µç­‰
ä¸–ç•ŒèƒŒæ™¯æ•…äº‹éœ€è¦ä»¥æ—¶é—´çº¿çš„å½¢å¼æè¿°ä¸–ç•Œçš„ä¸»è¦å†å²æ²¿é©ï¼Œå›½å®¶æˆ–åœ°åŒºä¹‹é—´çš„é‡å¤§äº‹ä»¶åŠå¸¦æ¥çš„å½±å“å˜åŒ–ç­‰"""
            )
            .output({
                "ä¸–ç•Œåç§°": ("str", ),
                "ä¸»è¦å›½å®¶æˆ–åœ°åŒº": [{
                    "åç§°": ("str", ),
                    "å…³é”®ä¿¡æ¯": ("str", ),
                }],
                "ä¸–ç•ŒèƒŒæ™¯æ•…äº‹": [("str", )],
            })
            .start()
    )
    storage.set("background", background)
    return {
        "title": "ä¸–ç•Œè§‚èƒŒæ™¯æ•…äº‹",
        "result": background,
    }

## åˆ›å»ºå…³é”®æƒ…èŠ‚çº¿
@main_workflow.chunk()
def generate_storyline(inputs, storage):
    story_idea = storage.get("story_idea")
    background = storage.get("background")
    storyline = (
        writer
            .input({
                "æ•…äº‹çµæ„Ÿ": story_idea,
                "ä¸–ç•Œè§‚èƒŒæ™¯æ•…äº‹": background,
            })
            .instruct(
"""è¯·æ ¹æ®{ä¸–ç•Œè§‚èƒŒæ™¯æ•…äº‹}ï¼Œå›´ç»•{æ•…äº‹çµæ„Ÿ}ï¼Œåˆ›ä½œæ•…äº‹çš„å…³é”®æƒ…èŠ‚çº¿å®‰æ’"""
            )
            .output({
                "æƒ…èŠ‚ç»“æ„ç±»å‹": ("str", "åŸºäºå¸¸è§çš„æ•…äº‹ã€å°è¯´ã€å‰§ä½œåˆ›ä½œæ–¹æ³•ï¼Œè¾“å‡ºä½ å°†è¦ä½¿ç”¨çš„å‰§æƒ…ç»“æ„ç±»å‹åç§°"),
                "æƒ…èŠ‚ç»“æ„ç‰¹ç‚¹": ("str", "é˜è¿°{å‰§æƒ…ç»“æ„ç±»å‹}çš„å‰§æƒ…ç»“æ„æ‰‹æ³•ã€ç‰¹ç‚¹"),
                "æ•…äº‹çº¿è¯¦ç»†åˆ›ä½œ": [{
                    "æœ¬æ®µæ•…äº‹ä½œç”¨": ("str", "æè¿°æœ¬æ®µæ•…äº‹åœ¨æ•´ä½“ç»“æ„ä¸­å‘æŒ¥çš„ä½œç”¨"),
                    "å…³é”®æƒ…èŠ‚": ([("str", )], "æŒ‰æ—¶åºæè¿°æœ¬æ®µæ•…äº‹ä¸­çš„å…³é”®æƒ…èŠ‚ï¼Œä»¥åŠæƒ…èŠ‚ä¸­çš„å…³é”®ç»†èŠ‚"),
                    "æ¶‰åŠå…³é”®äººç‰©": ([("str", )], "ç»™å‡ºæœ¬æ®µæ•…äº‹ä¸­æ¶‰åŠçš„å…³é”®äººç‰©å"),
                }],
            })
            .start()
    )
    storage.set("storyline", storyline)
    return {
        "title": "å…³é”®æƒ…èŠ‚çº¿",
        "result": storyline,
    }

## åˆ†å‘æ•…äº‹æ®µè½è®¾è®¡
@main_workflow.chunk()
def send_story_block_list(inputs, storage):
    storyline = storage.get("storyline")
    storyline_details = storyline["æ•…äº‹çº¿è¯¦ç»†åˆ›ä½œ"]
    extra_instruction = input("[æ‚¨æ˜¯å¦è¿˜æœ‰å…¶ä»–åˆ›ä½œæŒ‡å¯¼è¯´æ˜ï¼Ÿå¦‚åˆ›ä½œé£æ ¼ã€æ³¨æ„äº‹é¡¹ç­‰]")
    story_block_list = []
    for item in storyline_details:
        item.update({ "è¡¥å……åˆ›ä½œæŒ‡å¯¼": extra_instruction })
        story_block_list.append(item)
    return story_block_list

## è¿‡ç¨‹äº§å‡ºè¾“å‡º
@main_workflow.chunk_class()
def print_process_output(inputs, storage):
    print(f"[{ inputs['default']['title'] }]:")
    if isinstance(inputs["default"]["result"], dict):
        print(
            json.dumps(inputs["default"]["result"], indent=4, ensure_ascii=False)
        )
    else:
        print(inputs["default"]["result"])
    return

## æœ€ç»ˆç»“æœæ•´ç†
@main_workflow.chunk()
def sort_out(inputs, storage):
    result = []
    for item in inputs["default"]:
        result.append(item["default"])
    return "\n\n".join(result)

# å®šä¹‰åˆ†å—åˆ›ä½œå·¥ä½œæµçš„å·¥ä½œå—
## è·å–åˆå§‹æ•°æ®
@block_workflow.chunk()
def init_data(inputs, storage):
    storage.set("story_block", inputs["default"])
    # ä»å…¬å…±å­˜å‚¨ä¸­å–å‡ºä¸Šä¸€æ®µåˆ›ä½œç»“æœ
    storage.set("last_block_content", block_workflow.public_storage.get("last_block_content"))
    return

## è¿›è¡Œæ­£æ–‡åˆ›ä½œ
@block_workflow.chunk()
def generate_block_content(inputs, storage):
    # è¦è€ƒè™‘çš„æ¡ä»¶è¾ƒå¤šï¼Œå¯ä»¥åœ¨è¯·æ±‚å¤–éƒ¨æ„é€ inputå’Œinstructçš„promptæ•°æ®
    ## å›´ç»•æ•…äº‹çº¿è¯¦ç»†åˆ›ä½œä¿¡æ¯çš„prompt
    ## {"æœ¬æ®µæ•…äº‹ä½œç”¨": ,"å…³é”®æƒ…èŠ‚": , "æ¶‰åŠå…³é”®äººç‰©": , "è¡¥å……åˆ›ä½œæŒ‡å¯¼": }
    input_dict = storage.get("story_block")
    instruction_list = [
        "å‚è€ƒ{æœ¬æ®µæ•…äº‹ä½œç”¨}åŠ{æ¶‰åŠå…³é”®äººç‰©}ï¼Œå°†{å…³é”®æƒ…èŠ‚}æ‰©å†™ä¸ºå®Œæ•´çš„æ•…äº‹",
        "æ¯æ®µæ•…äº‹éœ€è¦å°½é‡åŒ…æ‹¬è¡ŒåŠ¨æå†™ã€å¿ƒç†æ´»åŠ¨æå†™å’Œå¯¹ç™½ç­‰ç»†èŠ‚",
        "æ¯æ¬¡åˆ›ä½œåªæ˜¯å®Œæ•´æ–‡ç« ç»“æ„ä¸­çš„ä¸€éƒ¨åˆ†ï¼Œæ‰¿æ‹…{æœ¬æ®µæ•…äº‹ä½œç”¨}è¯´æ˜çš„ä½œç”¨ä»»åŠ¡ï¼Œåªéœ€è¦æŒ‰è¦æ±‚å®Œæˆ{å…³é”®æƒ…èŠ‚}çš„æè¿°å³å¯ï¼Œä¸éœ€è¦è€ƒè™‘æœ¬æ®µæ•…äº‹è‡ªèº«ç»“æ„çš„å®Œæ•´æ€§",
    ]
    
    ## å¦‚æœæœ‰å‰ä¸€æ®µå†…å®¹ï¼Œé€šè¿‡ä¼ å…¥å‰ä¸€æ®µå†…å®¹æœ«å°¾ç¡®ä¿åˆ›ä½œçš„è¿è´¯æ€§
    last_block_content = storage.get("last_block_content", None)
    if last_block_content:
        ## åœ¨è¿™é‡Œå–ä¸Šä¸€æ®µè½çš„æœ€å50ä¸ªå­—ï¼Œå¯æ ¹æ®éœ€è¦ä¿®æ”¹ä¿ç•™çš„é•¿åº¦
        keep_length = 50
        input_dict.update({ "ä¸Šä¸€æ®µè½çš„æœ«å°¾": last_block_content[(-1 * keep_length):] })
        instruction_list.append("åˆ›ä½œæ—¶éœ€è¦æ‰¿æ¥{ä¸Šä¸€æ®µè½çš„æœ«å°¾}ï¼Œç¡®ä¿è¡¨è¾¾çš„è¿è´¯æ€§")
    
    ## å¦‚æœæœ‰äººç±»è¯„åˆ¤åé¦ˆçš„ä¿®æ”¹æ„è§ï¼Œæ·»åŠ prompt
    last_generation = storage.get("block_content", None)
    revision_suggestion = storage.get("revision_suggestion", None)
    if last_generation and revision_suggestion:
        input_dict.update({
            "å·²æœ‰åˆ›ä½œç»“æœ": last_generation,
            "ä¿®æ”¹æ„è§": revision_suggestion,
        })
        instruction_list.append("ä½ ä¹‹å‰å·²ç»åˆ›ä½œäº†{å·²æœ‰åˆ›ä½œç»“æœ}ï¼Œä½†ä»ç„¶éœ€è¦ä¿®æ”¹ï¼Œè¯·å‚è€ƒ{ä¿®æ”¹æ„è§}è¿›è¡Œä¿®è®¢")
    
    # å¼€å§‹åˆ›ä½œ
    block_content = (
        writer
            .input(input_dict)
            .instruct(instruction_list)
            .start()
    )

    # ä¿å­˜åˆ›ä½œç»“æœ
    storage.set("block_content", block_content)
    return {
        "title": f"æœ¬è½®åˆ›ä½œç›®æ ‡ï¼š{ input_dict['æœ¬æ®µæ•…äº‹ä½œç”¨'] }",
        "result": block_content,
    }

## äººç±»åˆ¤æ–­æ˜¯å¦æ»¡æ„
@block_workflow.chunk()
def human_confirm(inputs, storage):
    confirm = ""
    while confirm.lower() not in ("y", "n"):
        confirm = input("[æ‚¨æ˜¯å¦æ»¡æ„æœ¬æ¬¡åˆ›ä½œç»“æœï¼Ÿ(y/n)]: ")
    return confirm.lower()

## æäº¤ä¿®æ”¹æ„è§
@block_workflow.chunk()
def input_revision_suggestion(inputs, storage):
    storage.set("revision_suggestion", input("[è¯·è¾“å…¥æ‚¨çš„ä¿®æ”¹æ„è§]: "))
    return

## è¾“å‡ºæ»¡æ„çš„åˆ›ä½œæˆæœ
@block_workflow.chunk()
def return_block_content(inputs, storage):
    block_content = storage.get("block_content")
    # è®°å¾—åœ¨å…¬å…±å­˜å‚¨ä¸­æ›´æ–°æœ¬æ¬¡åˆ›ä½œç»“æœ
    block_workflow.public_storage.set("last_block_content", block_content)
    return block_content

## è¿‡ç¨‹äº§å‡ºè¾“å‡º
@block_workflow.chunk_class()
def print_process_output(inputs, storage):
    print(f"[{ inputs['default']['title'] }]:")
    if isinstance(inputs["default"]["result"], dict):
        print(
            json.dumps(inputs["default"]["result"], indent=4, ensure_ascii=False)
        )
    else:
        print(inputs["default"]["result"])
    return

# å®šä¹‰åˆ†å—åˆ›ä½œå·¥ä½œæµçš„å·¥ä½œæµç¨‹
(
    block_workflow
        .connect_to("init_data")
        .connect_to("generate_block_content")
        .connect_to("@print_process_output")
        .connect_to("human_confirm")
        .if_condition(lambda return_value, storage: return_value == "y")
            .connect_to("return_block_content")
            .connect_to("end")
        .else_condition()
            .connect_to("input_revision_suggestion")
            .connect_to("generate_block_content")
)

(
    main_workflow
        .connect_to("input_story_idea")
        .connect_to("generate_background")
        .connect_to("@print_process_output")
        .connect_to("generate_storyline")
        .connect_to("@print_process_output")
        .connect_to("send_story_block_list")# -> list[item1, item2, item3, ...]
            .loop_with(block_workflow) # item1 -> block_workflow:inputs["default"]; item2 -> block_workflow: i
        #.connect_to("sort_out")
        .connect_to("end")
)

# æ‰“å°æµç¨‹å›¾ï¼Œæ£€æŸ¥æµç¨‹æ­£ç¡®æ€§
print(main_workflow.draw())
```

**Output:**
```
%%{ init: { 'flowchart': { 'curve': 'linear' }, 'theme': 'neutral' } }%%
%% Rendered By Agently %%
flowchart LR
classDef chunk_style fill:#fbfcdb,stroke:#666,stroke-width:1px,color:#333;
classDef loop_style fill:#f5f7fa,stroke:#666,stroke-width:1px,color:#333,stroke-dasharray: 5 5
    subgraph Loop_1
    direction LR
    c6449090-6e6c-46e6-9745-cf7db9373c85("start"):::chunk_style -.-> |"* -->-- default"| 3f42d002-28bb-49bd-b3d9-5c5445175f78("init_data"):::chunk_style
    3f42d002-28bb-49bd-b3d9-5c5445175f78("init_data"):::chunk_style -.-> |"* -->-- default"| 75540bad-febf-4851-9206-62eead524826("generate_block_content"):::chunk_style
    75540bad-febf-4851-9206-62eead524826("generate_block_content"):::chunk_style -.-> |"* -->-- default"| c1b724dc-556e-4782-accb-56ed4ed7f9e6("@print_process_output"):::chunk_style
    c1b724dc-556e-4782-accb-56ed4ed7f9e6("@print_process_output"):::chunk_style -.-> |"* -->-- default"| c3e718df-ad17-4634-b1ff-de46ec55beba("human_confirm"):::chunk_style
    c3e718df-ad17-4634-b1ff-de46ec55beba("human_confirm"):::chunk_style -.-> |"* -- â—‡ -- default"| 02b7ce51-51fa-48a7-a758-b35dc01061d7("return_block_content"):::chunk_style
    02b7ce51-51fa-48a7-a758-b35dc01061d7("return_block_content"):::chunk_style -.-> |"* -->-- default"| 536cb2c9-8f64-4f38-b93f-7ca4acad4afe("end"):::chunk_style
    c3e718df-ad17-4634-b1ff-de46ec55beba("human_confirm"):::chunk_style -.-> |"* -- â—‡ -- default"| f480189c-0b7d-4715-8b09-0398590581f4("input_revision_suggestion"):::chunk_style
    f480189c-0b7d-4715-8b09-0398590581f4("input_revision_suggestion"):::chunk_style -.-> |"* -->-- default"| 75540bad-febf-4851-9206-62eead524826("generate_block_content"):::chunk_style
    end
    45622db2-1a8d-4af9-8312-c909f06c7de4("start"):::chunk_style -.-> |"* -->-- default"| 3861bd24-79b4-4982-ba2a-23d5dc615ae7("input_story_idea"):::chunk_style
    3861bd24-79b4-4982-ba2a-23d5dc615ae7("input_story_idea"):::chunk_style -.-> |"* -->-- default"| af6687bf-aaf3-49f7-9b9e-a0448f7585e8("generate_background"):::chunk_style
    af6687bf-aaf3-49f7-9b9e-a0448f7585e8("generate_background"):::chunk_style -.-> |"* -->-- default"| 7edb6345-4177-4087-b826-8271c56b5bcd("@print_process_output"):::chunk_style
    7edb6345-4177-4087-b826-8271c56b5bcd("@print_process_output"):::chunk_style -.-> |"* -->-- default"| b72ac1a4-2c76-43dc-b7fb-231e65dc87d8("generate_storyline"):::chunk_style
    b72ac1a4-2c76-43dc-b7fb-231e65dc87d8("generate_storyline"):::chunk_style -.-> |"* -->-- default"| a7235cad-acf8-42e7-be0e-a3ec5fdb0c53("@print_process_output"):::chunk_style
    a7235cad-acf8-42e7-be0e-a3ec5fdb0c53("@print_process_output"):::chunk_style -.-> |"* -->-- default"| dc4b4f9a-ea0d-4a56-8c84-6d0a008eedb3("send_story_block_list"):::chunk_style
    dc4b4f9a-ea0d-4a56-8c84-6d0a008eedb3("send_story_block_list"):::chunk_style -.-> |"* -->-- default"| Loop_1:::loop_style
    Loop_1:::loop_style -.-> |"* -->-- default"| 9402a2c0-94ca-407a-87da-d69798c342a6("sort_out"):::chunk_style
    9402a2c0-94ca-407a-87da-d69798c342a6("sort_out"):::chunk_style -.-> |"* -->-- default"| 3690195b-905e-4938-b70a-7184725a4066("end"):::chunk_style
```

![story_workflow.jpg](attachment:537fdf70-4970-4f24-a86a-632f882496fa.jpg)

```python
# å¼€å§‹æ‰§è¡Œ
result = main_workflow.start()
print(result["default"])
```

**Output:**
```
[ğŸ’¡è¯·è¾“å…¥æ‚¨çš„æ•…äº‹çµæ„Ÿ]:  æ˜Ÿé™…äº‰éœ¸ä¸–ç•Œè§‚ä¸‹çš„äººç±»å°å…µçš„æˆé•¿æ•…äº‹
[ä¸–ç•Œè§‚èƒŒæ™¯æ•…äº‹]:
{
    "ä¸–ç•Œåç§°": "æ˜Ÿé™…äº‰éœ¸å®‡å®™",
    "ä¸»è¦å›½å®¶æˆ–åœ°åŒº": [
        {
            "åç§°": "æ³°ä¼¦è”é‚¦",
            "å…³é”®ä¿¡æ¯": "ä½äºå…‹æ™®é²æ˜ŸåŒºï¼Œç¯å¢ƒå¤šæ ·ï¼Œä»æ²™æ¼ åˆ°å†°åŸï¼Œç§‘æŠ€æ°´å¹³é«˜ï¼Œä¿¡ä»°å¤šæ ·ï¼Œä»¥äººç±»è‡³ä¸Šä¸»ä¹‰ä¸ºä¸»ã€‚"
        },
        {
            "åç§°": "å‡¯å°”-è«æ‹‰è”åˆä½“",
            "å…³é”®ä¿¡æ¯": "ç”±å¤šä¸ªå¤–æ˜Ÿç§æ—ç»„æˆï¼Œç¯å¢ƒä»¥æ£®æ—å’Œå±±è„‰ä¸ºä¸»ï¼Œç§‘æŠ€æ°´å¹³ä¸æ³°ä¼¦è”é‚¦ç›¸å½“ï¼Œä¿¡ä»°ä»¥è‡ªç„¶å’Œè°ä¸ºæ ¸å¿ƒã€‚"
        },
        {
            "åç§°": "å¼‚è™«å·¢ç¾¤",
            "å…³é”®ä¿¡æ¯": "éå¸ƒå¤šä¸ªæ˜Ÿç³»ï¼Œç¯å¢ƒé€‚åº”æ€§å¼ºï¼Œç§‘æŠ€ä»¥ç”Ÿç‰©è¿›åŒ–ä¸ºä¸»ï¼Œæ— æ˜ç¡®ä¿¡ä»°ï¼Œä»¥ç”Ÿå­˜å’Œæ‰©å¼ ä¸ºå”¯ä¸€ç›®æ ‡ã€‚"
        }
    ],
    "ä¸–ç•ŒèƒŒæ™¯æ•…äº‹": [
        "2480å¹´ï¼Œæ³°ä¼¦è”é‚¦åœ¨å…‹æ™®é²æ˜ŸåŒºå»ºç«‹æ®–æ°‘åœ°ï¼Œå¼€å§‹äº†äººç±»çš„æ–°ç¯‡ç« ã€‚",
        "2490å¹´ï¼Œå‡¯å°”-è«æ‹‰è”åˆä½“ä¸æ³°ä¼¦è”é‚¦å»ºç«‹å¤–äº¤å…³ç³»ï¼Œä¿ƒè¿›äº†æ˜Ÿé™…é—´çš„ç§‘æŠ€å’Œæ–‡åŒ–äº¤æµã€‚",
        "2500å¹´ï¼Œå¼‚è™«å·¢ç¾¤é¦–æ¬¡å‡ºç°åœ¨å…‹æ™®é²æ˜ŸåŒºï¼Œå¼•å‘äº†äººç±»å’Œè”åˆä½“çš„è”åˆæŠµæŠ—ã€‚",
        "2510å¹´ï¼Œæ³°ä¼¦è”é‚¦å†…éƒ¨å‘ç”Ÿåˆ†è£‚ï¼Œå½¢æˆäº†å¤šä¸ªæ´¾ç³»ï¼ŒåŠ å‰§äº†æ˜ŸåŒºçš„æ”¿æ²»åŠ¨è¡ã€‚",
        "2520å¹´ï¼Œäººç±»å°å…µåœ¨å¤šæ¬¡ä¸å¼‚è™«çš„æˆ˜æ–—ä¸­æˆé•¿ï¼Œé€æ¸æˆä¸ºæŠµæŠ—å¼‚è™«çš„ä¸­åšåŠ›é‡ã€‚",
        "2530å¹´ï¼Œæ³°ä¼¦è”é‚¦ä¸å‡¯å°”-è«æ‹‰è”åˆä½“å…±åŒç ”å‘æ–°å‹æ­¦å™¨ï¼Œæœ‰æ•ˆéåˆ¶äº†å¼‚è™«çš„æ‰©å¼ ã€‚",
        "2540å¹´ï¼Œæ˜Ÿé™…é—´çš„å’Œå¹³åè®®ç­¾ç½²ï¼Œä½†å„æ–¹ä»ä¿æŒè­¦æƒ•ï¼Œä»¥é˜²å¼‚è™«çš„å†æ¬¡å…¥ä¾µã€‚"
    ]
}
[å…³é”®æƒ…èŠ‚çº¿]:
{
    "æƒ…èŠ‚ç»“æ„ç±»å‹": "ä¸‰å¹•ç»“æ„",
    "æƒ…èŠ‚ç»“æ„ç‰¹ç‚¹": "ä¸‰å¹•ç»“æ„æ˜¯æˆå‰§å’Œç”µå½±ä¸­å¸¸è§çš„æ•…äº‹ç»“æ„ï¼ŒåŒ…æ‹¬ç¬¬ä¸€å¹•çš„è®¾å®šå’Œå¼•å…¥ï¼Œç¬¬äºŒå¹•çš„å†²çªå’Œå¯¹æŠ—ï¼Œä»¥åŠç¬¬ä¸‰å¹•çš„é«˜æ½®å’Œè§£å†³ã€‚è¿™ç§ç»“æ„æœ‰åŠ©äºæ¸…æ™°åœ°å±•ç°æ•…äº‹çš„å‘å±•å’Œè§’è‰²çš„æˆé•¿ã€‚",
    "æ•…äº‹çº¿è¯¦ç»†åˆ›ä½œ": [
        {
            "æœ¬æ®µæ•…äº‹ä½œç”¨": "å¼•å…¥å’Œè®¾å®š",
            "å…³é”®æƒ…èŠ‚": [
                "ä¸»è§’åœ¨æ³°ä¼¦è”é‚¦çš„å†›äº‹è®­ç»ƒä¸­è¡¨ç°å¹³å¹³ï¼Œä½†å› ä¸€æ¬¡å¶ç„¶äº‹ä»¶å±•ç°å‡ºæ½œåŠ›",
                "ä¸»è§’è¢«åˆ†é…åˆ°å‰çº¿éƒ¨é˜Ÿï¼Œé¦–æ¬¡æ¥è§¦å¼‚è™«å·¢ç¾¤",
                "ä¸»è§’åœ¨ç¬¬ä¸€æ¬¡æˆ˜æ–—ä¸­è¡¨ç°å‡ºè‰²ï¼Œè·å¾—ä¸Šçº§å…³æ³¨"
            ],
            "æ¶‰åŠå…³é”®äººç‰©": [
                "ä¸»è§’",
                "ä¸Šçº§æŒ‡æŒ¥å®˜"
            ]
        },
        {
            "æœ¬æ®µæ•…äº‹ä½œç”¨": "å†²çªå’Œå¯¹æŠ—",
            "å…³é”®æƒ…èŠ‚": [
                "ä¸»è§’åœ¨å¤šæ¬¡ä¸å¼‚è™«çš„æˆ˜æ–—ä¸­é€æ¸æˆé•¿ï¼Œæˆä¸ºå°é˜Ÿæ ¸å¿ƒ",
                "æ³°ä¼¦è”é‚¦å†…éƒ¨æ”¿æ²»åŠ¨è¡ï¼Œä¸»è§’é¢ä¸´å¿ è¯šä¸ä¸ªäººä¿¡å¿µçš„æŠ‰æ‹©",
                "ä¸»è§’ä¸å‡¯å°”-è«æ‹‰è”åˆä½“çš„æˆ˜å£«åˆä½œï¼Œå…±åŒå¯¹æŠ—å¼‚è™«",
                "ä¸»è§’åœ¨ä¸€æ¬¡å…³é”®æˆ˜å½¹ä¸­å¤±å»æˆ˜å‹ï¼Œå†³å¿ƒæ›´åŠ åšå®š"
            ],
            "æ¶‰åŠå…³é”®äººç‰©": [
                "ä¸»è§’",
                "æˆ˜å‹",
                "å‡¯å°”-è«æ‹‰è”åˆä½“æˆ˜å£«"
            ]
        },
        {
            "æœ¬æ®µæ•…äº‹ä½œç”¨": "é«˜æ½®å’Œè§£å†³",
            "å…³é”®æƒ…èŠ‚": [
                "ä¸»è§’å‚ä¸ç ”å‘æ–°å‹æ­¦å™¨ï¼Œå¯¹æŠ—å¼‚è™«çš„æ‰©å¼ ",
                "ä¸»è§’åœ¨æœ€ç»ˆæˆ˜å½¹ä¸­å‘æŒ¥å…³é”®ä½œç”¨ï¼ŒæˆåŠŸéåˆ¶å¼‚è™«",
                "æ˜Ÿé™…é—´çš„å’Œå¹³åè®®ç­¾ç½²ï¼Œä¸»è§’æˆä¸ºè‹±é›„",
                "ä¸»è§’åæ€æˆ˜äº‰ç»å†ï¼Œå†³å®šç»§ç»­ä¸ºå’Œå¹³è€Œæˆ˜"
            ],
            "æ¶‰åŠå…³é”®äººç‰©": [
                "ä¸»è§’",
                "æ³°ä¼¦è”é‚¦é«˜å±‚",
                "å‡¯å°”-è«æ‹‰è”åˆä½“é¢†è¢–"
            ]
        }
    ]
}
[æ‚¨æ˜¯å¦è¿˜æœ‰å…¶ä»–åˆ›ä½œæŒ‡å¯¼è¯´æ˜ï¼Ÿå¦‚åˆ›ä½œé£æ ¼ã€æ³¨æ„äº‹é¡¹ç­‰] ä¸»è§’çš„åå­—è®¾å®šæˆéº¦å…‹ï¼Œæˆ˜å‹çš„åå­—è®¾å®šæˆæ°èŠ¬ï¼Œæˆ‘æ¯”è¾ƒå–œæ¬¢Lovecraftçš„å…‹è‹é²ç³»ç¥è¯é£æ ¼ï¼Œå¯ä»¥åœ¨åˆ›ä½œçš„æ—¶å€™å°è¯•åŠ å…¥è¿™ç±»é£æ ¼
[æœ¬è½®åˆ›ä½œç›®æ ‡ï¼šå¼•å…¥å’Œè®¾å®š]:
åœ¨æ³°ä¼¦è”é‚¦çš„å†›äº‹è®­ç»ƒè¥ä¸­ï¼Œéº¦å…‹çš„åå­—å¹¶ä¸å“äº®ã€‚ä»–çš„è¡¨ç°å¹³å¹³ï¼Œå¦‚åŒå¤§å¤šæ•°æ–°å…µä¸€æ ·ï¼Œé»˜é»˜æ— é—»ã€‚ç„¶è€Œï¼Œå‘½è¿çš„é½¿è½®åœ¨æŸä¸ªä¸ç»æ„çš„ç¬é—´å¼€å§‹è½¬åŠ¨ã€‚ä¸€æ¬¡å¶ç„¶çš„æ¨¡æ‹Ÿæˆ˜æ–—ä¸­ï¼Œéº¦å…‹é¢å¯¹è™šæ‹Ÿçš„å¼‚è™«å·¢ç¾¤ï¼Œä»–çš„ååº”é€Ÿåº¦å’Œæˆ˜æœ¯åˆ¤æ–­è¿œè¶…é¢„æœŸï¼Œä»¿ä½›ä»–çš„è¡€æ¶²ä¸­æµæ·Œç€å¤è€çš„æˆ˜æ–—æ™ºæ…§ã€‚è¿™ä¸€å¹•è¢«ä¸Šçº§æŒ‡æŒ¥å®˜æ•é”åœ°æ•æ‰åˆ°ï¼Œä»–çš„çœ¼ä¸­é—ªè¿‡ä¸€ä¸æœŸå¾…ã€‚

â€œéº¦å…‹ï¼Œä½ çš„è¡¨ç°å¾ˆæœ‰æ½œåŠ›ã€‚â€ ä¸Šçº§æŒ‡æŒ¥å®˜çš„å£°éŸ³åœ¨è®­ç»ƒç»“æŸåå“èµ·ï¼Œä»–çš„ç›®å…‰å¦‚é¹°éš¼èˆ¬é”åˆ©ï¼Œâ€œä½ å°†è¢«åˆ†é…åˆ°å‰çº¿éƒ¨é˜Ÿï¼Œé‚£é‡Œæ‰æ˜¯çœŸæ­£è€ƒéªŒä½ çš„åœ°æ–¹ã€‚â€

éº¦å…‹çš„å¿ƒä¸­æ¶Œèµ·ä¸€è‚¡å¤æ‚çš„æƒ…ç»ªï¼Œæ—¢æœ‰å¯¹æœªçŸ¥çš„ææƒ§ï¼Œä¹Ÿæœ‰å¯¹æŒ‘æˆ˜çš„æ¸´æœ›ã€‚ä»–çŸ¥é“ï¼Œå‰çº¿çš„æˆ˜åœºä¸åŒäºè®­ç»ƒåœºï¼Œé‚£é‡Œçš„å¼‚è™«å·¢ç¾¤æ˜¯çœŸå®è€Œæ®‹é…·çš„ã€‚

ä¸ä¹…ï¼Œéº¦å…‹å’Œä»–çš„æˆ˜å‹æ°èŠ¬ä¸€èµ·è¢«æ´¾å¾€å‰çº¿ã€‚å½“ä»–ä»¬é¦–æ¬¡æ¥è§¦åˆ°çœŸå®çš„å¼‚è™«å·¢ç¾¤æ—¶ï¼Œé‚£ç§å‹è¿«æ„Ÿå’Œææ€–æ„Ÿå¦‚åŒå…‹è‹é²ç¥è¯ä¸­çš„æ·±æµ·å·¨å…½ï¼Œæ— å£°åœ°åå™¬ç€æ–°å…µä»¬çš„å‹‡æ°”ã€‚ç„¶è€Œï¼Œéº¦å…‹çš„å¿ƒä¸­å´æ¶Œç°å‡ºä¸€ç§å¥‡å¼‚çš„å¹³é™ï¼Œä»¿ä½›ä»–æ—©å·²é¢„è§äº†è¿™ä¸€åˆ»ã€‚

åœ¨ç¬¬ä¸€æ¬¡æˆ˜æ–—ä¸­ï¼Œéº¦å…‹çš„æŒ‡æŒ¥å†·é™è€Œæœæ–­ï¼Œä»–åˆ©ç”¨åœ°å½¢å’Œæˆ˜æœ¯ï¼ŒæˆåŠŸåœ°å¼•å¯¼æˆ˜å‹ä»¬å‡»é€€äº†å¼‚è™«çš„è¿›æ”»ã€‚ä»–çš„è¡¨ç°ä¸ä»…èµ¢å¾—äº†æˆ˜å‹ä»¬çš„å°Šæ•¬ï¼Œä¹Ÿå¼•èµ·äº†ä¸Šçº§æŒ‡æŒ¥å®˜çš„è¿›ä¸€æ­¥å…³æ³¨ã€‚

â€œéº¦å…‹ï¼Œä½ çš„æˆ˜æœ¯è¿ç”¨å¾—å¾ˆå¥½ã€‚â€ ä¸Šçº§æŒ‡æŒ¥å®˜åœ¨æˆ˜åçš„ç®€æŠ¥ä¸­èµè®¸é“ï¼Œâ€œç»§ç»­ä¿æŒï¼Œä½ çš„æ½œåŠ›è¿œä¸æ­¢äºæ­¤ã€‚â€

éº¦å…‹ç‚¹äº†ç‚¹å¤´ï¼Œä»–çš„å¿ƒä¸­å……æ»¡äº†å¯¹æœªæ¥çš„æœŸå¾…å’Œå¯¹æœªçŸ¥çš„æ•¬ç•ã€‚ä»–çŸ¥é“ï¼Œè¿™åœºæˆ˜äº‰åªæ˜¯å¼€å§‹ï¼Œè€Œä»–ï¼Œéº¦å…‹ï¼Œå°†åœ¨è¿™åœºä¸å¼‚è™«çš„è¾ƒé‡ä¸­ï¼Œé€æ¸æ­å¼€è‡ªå·±å‘½è¿çš„ç¥ç§˜é¢çº±ã€‚
[æ‚¨æ˜¯å¦æ»¡æ„æœ¬æ¬¡åˆ›ä½œç»“æœï¼Ÿ(y/n)]:  n
[è¯·è¾“å…¥æ‚¨çš„ä¿®æ”¹æ„è§]:  1. ä¸Šçº§æŒ‡æŒ¥å®˜åŠ ä¸€ä¸ªåå­—ï¼Œå«å‡¯æ©ï¼›2. é£æ ¼ä½¿ç”¨å…‹è‹é²ç¥è¯é£æ ¼ï¼Œä½†åœ¨æ–‡ä¸­ä¸è¦å‡ºç°â€œå…‹è‹é²â€è¿™æ ·çš„å­—æ ·ï¼›3. ç¬¬ä¸€æ¬¡æˆ˜æ–—çš„è¿‡ç¨‹æè¿°ä¸å¤Ÿæ¸…æ™°ï¼Œæ·»åŠ æ›´å¤šçš„æˆ˜æ–—ç»†èŠ‚ï¼Œå±•ç°æˆ˜æ–—çš„æ®‹é…·
[æœ¬è½®åˆ›ä½œç›®æ ‡ï¼šå¼•å…¥å’Œè®¾å®š]:
åœ¨æ³°ä¼¦è”é‚¦çš„å†›äº‹è®­ç»ƒè¥ä¸­ï¼Œéº¦å…‹çš„åå­—å¹¶ä¸å“äº®ã€‚ä»–çš„è¡¨ç°å¹³å¹³ï¼Œå¦‚åŒå¤§å¤šæ•°æ–°å…µä¸€æ ·ï¼Œé»˜é»˜æ— é—»ã€‚ç„¶è€Œï¼Œå‘½è¿çš„é½¿è½®åœ¨æŸä¸ªä¸ç»æ„çš„ç¬é—´å¼€å§‹è½¬åŠ¨ã€‚ä¸€æ¬¡å¶ç„¶çš„æ¨¡æ‹Ÿæˆ˜æ–—ä¸­ï¼Œéº¦å…‹é¢å¯¹è™šæ‹Ÿçš„å¼‚è™«å·¢ç¾¤ï¼Œä»–çš„ååº”é€Ÿåº¦å’Œæˆ˜æœ¯åˆ¤æ–­è¿œè¶…é¢„æœŸï¼Œä»¿ä½›ä»–çš„è¡€æ¶²ä¸­æµæ·Œç€å¤è€çš„æˆ˜æ–—æ™ºæ…§ã€‚è¿™ä¸€å¹•è¢«ä¸Šçº§æŒ‡æŒ¥å®˜å‡¯æ©æ•é”åœ°æ•æ‰åˆ°ï¼Œä»–çš„çœ¼ä¸­é—ªè¿‡ä¸€ä¸æœŸå¾…ã€‚

â€œéº¦å…‹ï¼Œä½ çš„è¡¨ç°å¾ˆæœ‰æ½œåŠ›ã€‚â€ å‡¯æ©çš„å£°éŸ³åœ¨è®­ç»ƒç»“æŸåå“èµ·ï¼Œä»–çš„ç›®å…‰å¦‚é¹°éš¼èˆ¬é”åˆ©ï¼Œâ€œä½ å°†è¢«åˆ†é…åˆ°å‰çº¿éƒ¨é˜Ÿï¼Œé‚£é‡Œæ‰æ˜¯çœŸæ­£è€ƒéªŒä½ çš„åœ°æ–¹ã€‚â€

éº¦å…‹çš„å¿ƒä¸­æ¶Œèµ·ä¸€è‚¡å¤æ‚çš„æƒ…ç»ªï¼Œæ—¢æœ‰å¯¹æœªçŸ¥çš„ææƒ§ï¼Œä¹Ÿæœ‰å¯¹æŒ‘æˆ˜çš„æ¸´æœ›ã€‚ä»–çŸ¥é“ï¼Œå‰çº¿çš„æˆ˜åœºä¸åŒäºè®­ç»ƒåœºï¼Œé‚£é‡Œçš„å¼‚è™«å·¢ç¾¤æ˜¯çœŸå®è€Œæ®‹é…·çš„ã€‚

ä¸ä¹…ï¼Œéº¦å…‹å’Œä»–çš„æˆ˜å‹æ°èŠ¬ä¸€èµ·è¢«æ´¾å¾€å‰çº¿ã€‚å½“ä»–ä»¬é¦–æ¬¡æ¥è§¦åˆ°çœŸå®çš„å¼‚è™«å·¢ç¾¤æ—¶ï¼Œé‚£ç§å‹è¿«æ„Ÿå’Œææ€–æ„Ÿå¦‚åŒæ·±æµ·ä¸­çš„ä¸å¯åçŠ¶ä¹‹ç‰©ï¼Œæ— å£°åœ°åå™¬ç€æ–°å…µä»¬çš„å‹‡æ°”ã€‚ç„¶è€Œï¼Œéº¦å…‹çš„å¿ƒä¸­å´æ¶Œç°å‡ºä¸€ç§å¥‡å¼‚çš„å¹³é™ï¼Œä»¿ä½›ä»–æ—©å·²é¢„è§äº†è¿™ä¸€åˆ»ã€‚

åœ¨ç¬¬ä¸€æ¬¡æˆ˜æ–—ä¸­ï¼Œéº¦å…‹çš„æŒ‡æŒ¥å†·é™è€Œæœæ–­ã€‚ä»–åˆ©ç”¨åœ°å½¢å’Œæˆ˜æœ¯ï¼Œå·§å¦™åœ°å¼•å¯¼æˆ˜å‹ä»¬é¿å¼€å¼‚è™«çš„æ­£é¢å†²å‡»ï¼Œè½¬è€Œæ”»å‡»å®ƒä»¬çš„ä¾§ç¿¼ã€‚æˆ˜æ–—å¼‚å¸¸æ¿€çƒˆï¼Œå¼‚è™«çš„å˜¶å¼å£°å’Œæªç‚®çš„è½°é¸£äº¤ç»‡åœ¨ä¸€èµ·ï¼Œç©ºæ°”ä¸­å¼¥æ¼«ç€ç¡çƒŸå’Œè¡€è…¥å‘³ã€‚éº¦å…‹çš„è€³è¾¹å›å“ç€å‡¯æ©çš„æ•™è¯²ï¼Œä»–çš„æ¯ä¸€ä¸ªå†³ç­–éƒ½æ˜¾å¾—å¼‚å¸¸å…³é”®ã€‚åœ¨ä¸€æ¬¡å…³é”®çš„åå‡»ä¸­ï¼Œéº¦å…‹äº²è‡ªå¸¦é¢†ä¸€å°é˜Ÿå£«å…µï¼Œåˆ©ç”¨çƒŸé›¾å¼¹æ©æŠ¤ï¼ŒæˆåŠŸåœ°çªç ´äº†å¼‚è™«çš„é˜²çº¿ï¼Œå‡»æºƒäº†å®ƒä»¬çš„æŒ‡æŒ¥ä¸­æ¢ã€‚

â€œéº¦å…‹ï¼Œä½ çš„æˆ˜æœ¯è¿ç”¨å¾—å¾ˆå¥½ã€‚â€ å‡¯æ©åœ¨æˆ˜åçš„ç®€æŠ¥ä¸­èµè®¸é“ï¼Œâ€œç»§ç»­ä¿æŒï¼Œä½ çš„æ½œåŠ›è¿œä¸æ­¢äºæ­¤ã€‚â€

éº¦å…‹ç‚¹äº†ç‚¹å¤´ï¼Œä»–çš„å¿ƒä¸­å……æ»¡äº†å¯¹æœªæ¥çš„æœŸå¾…å’Œå¯¹æœªçŸ¥çš„æ•¬ç•ã€‚ä»–çŸ¥é“ï¼Œè¿™åœºæˆ˜äº‰åªæ˜¯å¼€å§‹ï¼Œè€Œä»–ï¼Œéº¦å…‹ï¼Œå°†åœ¨è¿™åœºä¸å¼‚è™«çš„è¾ƒé‡ä¸­ï¼Œé€æ¸æ­å¼€è‡ªå·±å‘½è¿çš„ç¥ç§˜é¢çº±ã€‚
[æ‚¨æ˜¯å¦æ»¡æ„æœ¬æ¬¡åˆ›ä½œç»“æœï¼Ÿ(y/n)]:  y
[æœ¬è½®åˆ›ä½œç›®æ ‡ï¼šå†²çªå’Œå¯¹æŠ—]:
éº¦å…‹ç«™åœ¨æˆ˜åœºçš„åºŸå¢Ÿä¸­ï¼Œå››å‘¨æ˜¯å¼‚è™«æ®‹ç ´çš„å°¸ä½“å’Œç‡ƒçƒ§çš„æ®‹éª¸ã€‚ä»–çš„æˆ˜ç”²ä¸Šæ²¾æ»¡äº†è¡€è¿¹å’Œæ±¡æ³¥ï¼Œä½†ä»–çš„çœ¼ç¥å´å¼‚å¸¸åšå®šã€‚ç»è¿‡å¤šæ¬¡ä¸å¼‚è™«çš„æˆ˜æ–—ï¼Œéº¦å…‹å·²ç»ä»å°é˜Ÿä¸­çš„ä¸€åæ™®é€šå£«å…µæˆé•¿ä¸ºæ ¸å¿ƒæˆå‘˜ã€‚ä»–çš„æˆ˜æœ¯çœ¼å…‰å’Œæˆ˜æ–—æŠ€å·§åœ¨æ¯ä¸€æ¬¡äº¤é”‹ä¸­éƒ½å¾—åˆ°äº†æå‡ï¼Œé˜Ÿå‹ä»¬å¯¹ä»–çš„ä¿¡ä»»ä¹Ÿæ—¥ç›ŠåŠ æ·±ã€‚

â€œéº¦å…‹ï¼Œä½ è¿˜å¥½å—ï¼Ÿâ€æ°èŠ¬çš„å£°éŸ³ä»é€šè®¯å™¨ä¸­ä¼ æ¥ï¼Œä»–çš„è¯­æ°”ä¸­å¸¦ç€å…³åˆ‡ã€‚

â€œæˆ‘è¿˜å¥½ï¼Œæ°èŠ¬ã€‚åªæ˜¯...è¿™åœºæˆ˜æ–—æ¯”æˆ‘ä»¬é¢„æƒ³çš„è¦è‰°éš¾ã€‚â€éº¦å…‹å›åº”é“ï¼Œä»–çš„ç›®å…‰æ‰«è¿‡æˆ˜åœºï¼Œå¯»æ‰¾ç€ä»»ä½•å¯èƒ½çš„å¨èƒã€‚

æ³°ä¼¦è”é‚¦å†…éƒ¨çš„åŠ¨è¡è®©éº¦å…‹æ„Ÿåˆ°ä¸å®‰ã€‚æ”¿æ²»æ–—äº‰çš„é˜´å½±ç¬¼ç½©åœ¨æ¯ä¸ªäººçš„å¿ƒå¤´ï¼Œè€Œéº¦å…‹å¿…é¡»åœ¨å¿ è¯šäºè”é‚¦å’ŒåšæŒè‡ªå·±çš„ä¿¡å¿µä¹‹é—´åšå‡ºé€‰æ‹©ã€‚è¿™ç§å†…å¿ƒçš„æŒ£æ‰è®©ä»–å¤œä¸èƒ½å¯ï¼Œä½†ä»–çŸ¥é“ï¼Œæ— è®ºé€‰æ‹©å“ªæ¡è·¯ï¼Œä»–éƒ½å¿…é¡»åšå®šåœ°èµ°ä¸‹å»ã€‚

åœ¨ä¸€æ¬¡ä¸å‡¯å°”-è«æ‹‰è”åˆä½“çš„è”åˆè¡ŒåŠ¨ä¸­ï¼Œéº¦å…‹ä¸ä»–ä»¬çš„æˆ˜å£«å¹¶è‚©ä½œæˆ˜ã€‚è¿™äº›æˆ˜å£«çš„æˆ˜æ–—é£æ ¼ä¸æ³°ä¼¦è”é‚¦çš„å£«å…µæˆªç„¶ä¸åŒï¼Œä½†ä»–ä»¬å¯¹å¼‚è™«çš„ä»‡æ¨å´æ˜¯ç›¸åŒçš„ã€‚åœ¨ä¸€æ¬¡çŸ­æš‚çš„ä¼‘æ¯ä¸­ï¼Œéº¦å…‹ä¸ä¸€åå‡¯å°”-è«æ‹‰çš„æˆ˜å£«ååœ¨ä¸€èµ·ã€‚

â€œä½ ä»¬ä¸ºä»€ä¹ˆè¦ä¸æˆ‘ä»¬åˆä½œï¼Ÿâ€éº¦å…‹é—®é“ï¼Œä»–çš„å£°éŸ³ä¸­å¸¦ç€å¥½å¥‡ã€‚

â€œå› ä¸ºæˆ‘ä»¬æœ‰å…±åŒçš„æ•Œäººï¼Œéº¦å…‹ã€‚å¼‚è™«æ˜¯æˆ‘ä»¬æ‰€æœ‰äººçš„å¨èƒã€‚â€é‚£åæˆ˜å£«å›ç­”ï¼Œä»–çš„çœ¼ç¥åšå®šè€Œå†·é…·ã€‚

åœ¨ä¸€æ¬¡å…³é”®æˆ˜å½¹ä¸­ï¼Œéº¦å…‹å¤±å»äº†æ°èŠ¬ã€‚å½“ä»–åœ¨æˆ˜åœºä¸Šæ‰¾åˆ°æ°èŠ¬çš„é—ä½“æ—¶ï¼Œä»–çš„å¿ƒä¸­å……æ»¡äº†ç—›è‹¦å’Œæ„¤æ€’ã€‚ä»–ç´§ç´§æ¡ä½æ°èŠ¬çš„æ‰‹ï¼Œä½å£°è¯´é“ï¼šâ€œæˆ‘ä¼šä¸ºä½ æŠ¥ä»‡çš„ï¼Œæ°èŠ¬ã€‚æˆ‘ä¼šè®©è¿™äº›å¼‚è™«ä»˜å‡ºä»£ä»·ã€‚â€

ä»é‚£ä¸€åˆ»èµ·ï¼Œéº¦å…‹çš„å†³å¿ƒæ›´åŠ åšå®šã€‚ä»–çŸ¥é“ï¼Œè¿™åœºæˆ˜äº‰è¿œæœªç»“æŸï¼Œè€Œä»–ï¼Œéº¦å…‹ï¼Œå°†ç»§ç»­åœ¨è¿™åœºä¸å¼‚è™«çš„è¾ƒé‡ä¸­ï¼Œæ­å¼€è‡ªå·±å‘½è¿çš„ç¥ç§˜é¢çº±ã€‚ä»–çš„å¿ƒä¸­å……æ»¡äº†å¯¹æœªçŸ¥çš„æ•¬ç•ï¼Œä½†ä»–ä¹Ÿæ˜ç™½ï¼Œåªæœ‰é€šè¿‡ä¸æ–­çš„æˆ˜æ–—å’Œç‰ºç‰²ï¼Œä»–æ‰èƒ½æ‰¾åˆ°çœŸæ­£çš„ç­”æ¡ˆã€‚
[æ‚¨æ˜¯å¦æ»¡æ„æœ¬æ¬¡åˆ›ä½œç»“æœï¼Ÿ(y/n)]:  y
[æœ¬è½®åˆ›ä½œç›®æ ‡ï¼šé«˜æ½®å’Œè§£å†³]:
éº¦å…‹ç«™åœ¨æ³°ä¼¦è”é‚¦çš„ç ”å‘ä¸­å¿ƒï¼Œçœ¼å‰æ˜¯ä¸€æ’æ’é—ªçƒç€è“å…‰çš„ä»ªå™¨å’Œå¿™ç¢Œçš„ç§‘å­¦å®¶ä»¬ã€‚ä»–çš„å¿ƒä¸­å……æ»¡äº†å¯¹æœªçŸ¥çš„æ•¬ç•ï¼Œä½†ä»–ä¹Ÿæ˜ç™½ï¼Œåªæœ‰é€šè¿‡ä¸æ–­çš„æˆ˜æ–—å’Œç‰ºç‰²ï¼Œä»–æ‰èƒ½æ‰¾åˆ°çœŸæ­£çš„ç­”æ¡ˆã€‚æ–°å‹æ­¦å™¨çš„ç ”å‘å·²ç»è¿›å…¥æœ€åé˜¶æ®µï¼Œè¿™æ˜¯å¯¹æŠ—å¼‚è™«æ‰©å¼ çš„å…³é”®ã€‚

â€œéº¦å…‹ï¼Œä½ å‡†å¤‡å¥½äº†å—ï¼Ÿâ€æ°èŠ¬èµ°è¿‡æ¥ï¼Œæ‹äº†æ‹ä»–çš„è‚©è†€ã€‚

â€œå½“ç„¶ï¼Œæ°èŠ¬ã€‚æˆ‘ä»¬ä¸èƒ½è®©è¿™äº›å¼‚è™«ç»§ç»­æ‰©å¼ ä¸‹å»ã€‚â€éº¦å…‹åšå®šåœ°å›ç­”ã€‚

åœ¨æ¥ä¸‹æ¥çš„å‡ å‘¨é‡Œï¼Œéº¦å…‹å’Œæ°èŠ¬ä¸ç§‘å­¦å®¶ä»¬ä¸€èµ·ï¼Œæ—¥ä»¥ç»§å¤œåœ°å·¥ä½œï¼Œç»ˆäºå®Œæˆäº†æ–°å‹æ­¦å™¨çš„ç ”å‘ã€‚è¿™ç§æ­¦å™¨èƒ½å¤Ÿæœ‰æ•ˆåœ°æŠ‘åˆ¶å¼‚è™«çš„ç¹æ®–å’Œæ‰©å¼ ï¼Œæ˜¯æ³°ä¼¦è”é‚¦å¯¹æŠ—å¼‚è™«çš„æœ€åå¸Œæœ›ã€‚

æœ€ç»ˆæˆ˜å½¹çš„å‰å¤œï¼Œéº¦å…‹ç«™åœ¨æŒ‡æŒ¥èˆ°çš„ç”²æ¿ä¸Šï¼Œæœ›ç€æ˜Ÿç©ºã€‚ä»–çš„å¿ƒä¸­å……æ»¡äº†ç´§å¼ å’ŒæœŸå¾…ã€‚ä»–çŸ¥é“ï¼Œæ˜å¤©çš„æˆ˜æ–—å°†å†³å®šæ˜Ÿé™…é—´çš„æœªæ¥ã€‚

â€œéº¦å…‹ï¼Œä½ çœ‹èµ·æ¥å¾ˆç´§å¼ ã€‚â€æ³°ä¼¦è”é‚¦çš„é«˜å±‚èµ°è¿‡æ¥ï¼Œå…³åˆ‡åœ°é—®é“ã€‚

â€œæ˜¯çš„ï¼Œé•¿å®˜ã€‚è¿™æ˜¯æˆ‘ç¬¬ä¸€æ¬¡é¢å¯¹å¦‚æ­¤å¤§è§„æ¨¡çš„æˆ˜æ–—ã€‚â€éº¦å…‹å¦è¯šåœ°å›ç­”ã€‚

â€œè®°ä½ï¼Œéº¦å…‹ï¼Œä½ ä¸æ˜¯ä¸€ä¸ªäººåœ¨æˆ˜æ–—ã€‚æˆ‘ä»¬éƒ½åœ¨ä½ èº«è¾¹ã€‚â€é«˜å±‚é¼“åŠ±é“ã€‚

ç¬¬äºŒå¤©ï¼Œæˆ˜æ–—å¼€å§‹äº†ã€‚éº¦å…‹å’Œæ°èŠ¬å¸¦é¢†ç€ä»–ä»¬çš„éƒ¨é˜Ÿï¼Œå†²å‘å¼‚è™«çš„å·¢ç©´ã€‚æ–°å‹æ­¦å™¨å‘æŒ¥äº†å·¨å¤§çš„ä½œç”¨ï¼Œå¼‚è™«çš„æ‰©å¼ è¢«æˆåŠŸéåˆ¶ã€‚ç»è¿‡å‡ ä¸ªå°æ—¶çš„æ¿€æˆ˜ï¼Œæ³°ä¼¦è”é‚¦å–å¾—äº†èƒœåˆ©ã€‚

æˆ˜æ–—ç»“æŸåï¼Œéº¦å…‹ç«™åœ¨æˆ˜åœºä¸Šï¼Œæœ›ç€æ»¡ç›®ç–®ç—çš„æ™¯è±¡ï¼Œå¿ƒä¸­å……æ»¡äº†å¤æ‚çš„æƒ…æ„Ÿã€‚ä»–çŸ¥é“ï¼Œè¿™åœºèƒœåˆ©åªæ˜¯æš‚æ—¶çš„ï¼ŒçœŸæ­£çš„å’Œå¹³è¿˜éœ€è¦æ›´å¤šçš„åŠªåŠ›ã€‚

åœ¨æ˜Ÿé™…é—´çš„å’Œå¹³åè®®ç­¾ç½²ä»ªå¼ä¸Šï¼Œéº¦å…‹è¢«æˆäºˆè‹±é›„çš„ç§°å·ã€‚ä»–ç«™åœ¨å°ä¸Šï¼Œæœ›ç€å°ä¸‹çš„ä¼—äººï¼Œå¿ƒä¸­å……æ»¡äº†æ„Ÿæ…¨ã€‚

â€œéº¦å…‹ï¼Œä½ æˆä¸ºäº†æˆ‘ä»¬çš„è‹±é›„ã€‚â€å‡¯å°”-è«æ‹‰è”åˆä½“çš„é¢†è¢–èµ°ä¸Šå‰æ¥ï¼Œå¾®ç¬‘ç€è¯´é“ã€‚

â€œè°¢è°¢ï¼Œä½†æˆ‘åªæ˜¯åšäº†æˆ‘åº”è¯¥åšçš„äº‹æƒ…ã€‚â€éº¦å…‹è°¦è™šåœ°å›ç­”ã€‚

ä»ªå¼ç»“æŸåï¼Œéº¦å…‹ç‹¬è‡ªä¸€äººèµ°åœ¨æ˜Ÿé™…æ¸¯å£çš„ç”²æ¿ä¸Šï¼Œæœ›ç€è¿œå¤„çš„æ˜Ÿç©ºã€‚ä»–åæ€ç€è‡ªå·±çš„æˆ˜äº‰ç»å†ï¼Œå†³å®šç»§ç»­ä¸ºå’Œå¹³è€Œæˆ˜ã€‚ä»–çŸ¥é“ï¼ŒçœŸæ­£çš„ç­”æ¡ˆè¿˜åœ¨å‰æ–¹ï¼Œè€Œä»–å°†ç»§ç»­è¿½å¯»ã€‚
[æ‚¨æ˜¯å¦æ»¡æ„æœ¬æ¬¡åˆ›ä½œç»“æœï¼Ÿ(y/n)]:  y
åœ¨æ³°ä¼¦è”é‚¦çš„å†›äº‹è®­ç»ƒè¥ä¸­ï¼Œéº¦å…‹çš„åå­—å¹¶ä¸å“äº®ã€‚ä»–çš„è¡¨ç°å¹³å¹³ï¼Œå¦‚åŒå¤§å¤šæ•°æ–°å…µä¸€æ ·ï¼Œé»˜é»˜æ— é—»ã€‚ç„¶è€Œï¼Œå‘½è¿çš„é½¿è½®åœ¨æŸä¸ªä¸ç»æ„çš„ç¬é—´å¼€å§‹è½¬åŠ¨ã€‚ä¸€æ¬¡å¶ç„¶çš„æ¨¡æ‹Ÿæˆ˜æ–—ä¸­ï¼Œéº¦å…‹é¢å¯¹è™šæ‹Ÿçš„å¼‚è™«å·¢ç¾¤ï¼Œä»–çš„ååº”é€Ÿåº¦å’Œæˆ˜æœ¯åˆ¤æ–­è¿œè¶…é¢„æœŸï¼Œä»¿ä½›ä»–çš„è¡€æ¶²ä¸­æµæ·Œç€å¤è€çš„æˆ˜æ–—æ™ºæ…§ã€‚è¿™ä¸€å¹•è¢«ä¸Šçº§æŒ‡æŒ¥å®˜å‡¯æ©æ•é”åœ°æ•æ‰åˆ°ï¼Œä»–çš„çœ¼ä¸­é—ªè¿‡ä¸€ä¸æœŸå¾…ã€‚

â€œéº¦å…‹ï¼Œä½ çš„è¡¨ç°å¾ˆæœ‰æ½œåŠ›ã€‚â€ å‡¯æ©çš„å£°éŸ³åœ¨è®­ç»ƒç»“æŸåå“èµ·ï¼Œä»–çš„ç›®å…‰å¦‚é¹°éš¼èˆ¬é”åˆ©ï¼Œâ€œä½ å°†è¢«åˆ†é…åˆ°å‰çº¿éƒ¨é˜Ÿï¼Œé‚£é‡Œæ‰æ˜¯çœŸæ­£è€ƒéªŒä½ çš„åœ°æ–¹ã€‚â€

éº¦å…‹çš„å¿ƒä¸­æ¶Œèµ·ä¸€è‚¡å¤æ‚çš„æƒ…ç»ªï¼Œæ—¢æœ‰å¯¹æœªçŸ¥çš„ææƒ§ï¼Œä¹Ÿæœ‰å¯¹æŒ‘æˆ˜çš„æ¸´æœ›ã€‚ä»–çŸ¥é“ï¼Œå‰çº¿çš„æˆ˜åœºä¸åŒäºè®­ç»ƒåœºï¼Œé‚£é‡Œçš„å¼‚è™«å·¢ç¾¤æ˜¯çœŸå®è€Œæ®‹é…·çš„ã€‚

ä¸ä¹…ï¼Œéº¦å…‹å’Œä»–çš„æˆ˜å‹æ°èŠ¬ä¸€èµ·è¢«æ´¾å¾€å‰çº¿ã€‚å½“ä»–ä»¬é¦–æ¬¡æ¥è§¦åˆ°çœŸå®çš„å¼‚è™«å·¢ç¾¤æ—¶ï¼Œé‚£ç§å‹è¿«æ„Ÿå’Œææ€–æ„Ÿå¦‚åŒæ·±æµ·ä¸­çš„ä¸å¯åçŠ¶ä¹‹ç‰©ï¼Œæ— å£°åœ°åå™¬ç€æ–°å…µä»¬çš„å‹‡æ°”ã€‚ç„¶è€Œï¼Œéº¦å…‹çš„å¿ƒä¸­å´æ¶Œç°å‡ºä¸€ç§å¥‡å¼‚çš„å¹³é™ï¼Œä»¿ä½›ä»–æ—©å·²é¢„è§äº†è¿™ä¸€åˆ»ã€‚

åœ¨ç¬¬ä¸€æ¬¡æˆ˜æ–—ä¸­ï¼Œéº¦å…‹çš„æŒ‡æŒ¥å†·é™è€Œæœæ–­ã€‚ä»–åˆ©ç”¨åœ°å½¢å’Œæˆ˜æœ¯ï¼Œå·§å¦™åœ°å¼•å¯¼æˆ˜å‹ä»¬é¿å¼€å¼‚è™«çš„æ­£é¢å†²å‡»ï¼Œè½¬è€Œæ”»å‡»å®ƒä»¬çš„ä¾§ç¿¼ã€‚æˆ˜æ–—å¼‚å¸¸æ¿€çƒˆï¼Œå¼‚è™«çš„å˜¶å¼å£°å’Œæªç‚®çš„è½°é¸£äº¤ç»‡åœ¨ä¸€èµ·ï¼Œç©ºæ°”ä¸­å¼¥æ¼«ç€ç¡çƒŸå’Œè¡€è…¥å‘³ã€‚éº¦å…‹çš„è€³è¾¹å›å“ç€å‡¯æ©çš„æ•™è¯²ï¼Œä»–çš„æ¯ä¸€ä¸ªå†³ç­–éƒ½æ˜¾å¾—å¼‚å¸¸å…³é”®ã€‚åœ¨ä¸€æ¬¡å…³é”®çš„åå‡»ä¸­ï¼Œéº¦å…‹äº²è‡ªå¸¦é¢†ä¸€å°é˜Ÿå£«å…µï¼Œåˆ©ç”¨çƒŸé›¾å¼¹æ©æŠ¤ï¼ŒæˆåŠŸåœ°çªç ´äº†å¼‚è™«çš„é˜²çº¿ï¼Œå‡»æºƒäº†å®ƒä»¬çš„æŒ‡æŒ¥ä¸­æ¢ã€‚

â€œéº¦å…‹ï¼Œä½ çš„æˆ˜æœ¯è¿ç”¨å¾—å¾ˆå¥½ã€‚â€ å‡¯æ©åœ¨æˆ˜åçš„ç®€æŠ¥ä¸­èµè®¸é“ï¼Œâ€œç»§ç»­ä¿æŒï¼Œä½ çš„æ½œåŠ›è¿œä¸æ­¢äºæ­¤ã€‚â€

éº¦å…‹ç‚¹äº†ç‚¹å¤´ï¼Œä»–çš„å¿ƒä¸­å……æ»¡äº†å¯¹æœªæ¥çš„æœŸå¾…å’Œå¯¹æœªçŸ¥çš„æ•¬ç•ã€‚ä»–çŸ¥é“ï¼Œè¿™åœºæˆ˜äº‰åªæ˜¯å¼€å§‹ï¼Œè€Œä»–ï¼Œéº¦å…‹ï¼Œå°†åœ¨è¿™åœºä¸å¼‚è™«çš„è¾ƒé‡ä¸­ï¼Œé€æ¸æ­å¼€è‡ªå·±å‘½è¿çš„ç¥ç§˜é¢çº±ã€‚

éº¦å…‹ç«™åœ¨æˆ˜åœºçš„åºŸå¢Ÿä¸­ï¼Œå››å‘¨æ˜¯å¼‚è™«æ®‹ç ´çš„å°¸ä½“å’Œç‡ƒçƒ§çš„æ®‹éª¸ã€‚ä»–çš„æˆ˜ç”²ä¸Šæ²¾æ»¡äº†è¡€è¿¹å’Œæ±¡æ³¥ï¼Œä½†ä»–çš„çœ¼ç¥å´å¼‚å¸¸åšå®šã€‚ç»è¿‡å¤šæ¬¡ä¸å¼‚è™«çš„æˆ˜æ–—ï¼Œéº¦å…‹å·²ç»ä»å°é˜Ÿä¸­çš„ä¸€åæ™®é€šå£«å…µæˆé•¿ä¸ºæ ¸å¿ƒæˆå‘˜ã€‚ä»–çš„æˆ˜æœ¯çœ¼å…‰å’Œæˆ˜æ–—æŠ€å·§åœ¨æ¯ä¸€æ¬¡äº¤é”‹ä¸­éƒ½å¾—åˆ°äº†æå‡ï¼Œé˜Ÿå‹ä»¬å¯¹ä»–çš„ä¿¡ä»»ä¹Ÿæ—¥ç›ŠåŠ æ·±ã€‚

â€œéº¦å…‹ï¼Œä½ è¿˜å¥½å—ï¼Ÿâ€æ°èŠ¬çš„å£°éŸ³ä»é€šè®¯å™¨ä¸­ä¼ æ¥ï¼Œä»–çš„è¯­æ°”ä¸­å¸¦ç€å…³åˆ‡ã€‚

â€œæˆ‘è¿˜å¥½ï¼Œæ°èŠ¬ã€‚åªæ˜¯...è¿™åœºæˆ˜æ–—æ¯”æˆ‘ä»¬é¢„æƒ³çš„è¦è‰°éš¾ã€‚â€éº¦å…‹å›åº”é“ï¼Œä»–çš„ç›®å…‰æ‰«è¿‡æˆ˜åœºï¼Œå¯»æ‰¾ç€ä»»ä½•å¯èƒ½çš„å¨èƒã€‚

æ³°ä¼¦è”é‚¦å†…éƒ¨çš„åŠ¨è¡è®©éº¦å…‹æ„Ÿåˆ°ä¸å®‰ã€‚æ”¿æ²»æ–—äº‰çš„é˜´å½±ç¬¼ç½©åœ¨æ¯ä¸ªäººçš„å¿ƒå¤´ï¼Œè€Œéº¦å…‹å¿…é¡»åœ¨å¿ è¯šäºè”é‚¦å’ŒåšæŒè‡ªå·±çš„ä¿¡å¿µä¹‹é—´åšå‡ºé€‰æ‹©ã€‚è¿™ç§å†…å¿ƒçš„æŒ£æ‰è®©ä»–å¤œä¸èƒ½å¯ï¼Œä½†ä»–çŸ¥é“ï¼Œæ— è®ºé€‰æ‹©å“ªæ¡è·¯ï¼Œä»–éƒ½å¿…é¡»åšå®šåœ°èµ°ä¸‹å»ã€‚

åœ¨ä¸€æ¬¡ä¸å‡¯å°”-è«æ‹‰è”åˆä½“çš„è”åˆè¡ŒåŠ¨ä¸­ï¼Œéº¦å…‹ä¸ä»–ä»¬çš„æˆ˜å£«å¹¶è‚©ä½œæˆ˜ã€‚è¿™äº›æˆ˜å£«çš„æˆ˜æ–—é£æ ¼ä¸æ³°ä¼¦è”é‚¦çš„å£«å…µæˆªç„¶ä¸åŒï¼Œä½†ä»–ä»¬å¯¹å¼‚è™«çš„ä»‡æ¨å´æ˜¯ç›¸åŒçš„ã€‚åœ¨ä¸€æ¬¡çŸ­æš‚çš„ä¼‘æ¯ä¸­ï¼Œéº¦å…‹ä¸ä¸€åå‡¯å°”-è«æ‹‰çš„æˆ˜å£«ååœ¨ä¸€èµ·ã€‚

â€œä½ ä»¬ä¸ºä»€ä¹ˆè¦ä¸æˆ‘ä»¬åˆä½œï¼Ÿâ€éº¦å…‹é—®é“ï¼Œä»–çš„å£°éŸ³ä¸­å¸¦ç€å¥½å¥‡ã€‚

â€œå› ä¸ºæˆ‘ä»¬æœ‰å…±åŒçš„æ•Œäººï¼Œéº¦å…‹ã€‚å¼‚è™«æ˜¯æˆ‘ä»¬æ‰€æœ‰äººçš„å¨èƒã€‚â€é‚£åæˆ˜å£«å›ç­”ï¼Œä»–çš„çœ¼ç¥åšå®šè€Œå†·é…·ã€‚

åœ¨ä¸€æ¬¡å…³é”®æˆ˜å½¹ä¸­ï¼Œéº¦å…‹å¤±å»äº†æ°èŠ¬ã€‚å½“ä»–åœ¨æˆ˜åœºä¸Šæ‰¾åˆ°æ°èŠ¬çš„é—ä½“æ—¶ï¼Œä»–çš„å¿ƒä¸­å……æ»¡äº†ç—›è‹¦å’Œæ„¤æ€’ã€‚ä»–ç´§ç´§æ¡ä½æ°èŠ¬çš„æ‰‹ï¼Œä½å£°è¯´é“ï¼šâ€œæˆ‘ä¼šä¸ºä½ æŠ¥ä»‡çš„ï¼Œæ°èŠ¬ã€‚æˆ‘ä¼šè®©è¿™äº›å¼‚è™«ä»˜å‡ºä»£ä»·ã€‚â€

ä»é‚£ä¸€åˆ»èµ·ï¼Œéº¦å…‹çš„å†³å¿ƒæ›´åŠ åšå®šã€‚ä»–çŸ¥é“ï¼Œè¿™åœºæˆ˜äº‰è¿œæœªç»“æŸï¼Œè€Œä»–ï¼Œéº¦å…‹ï¼Œå°†ç»§ç»­åœ¨è¿™åœºä¸å¼‚è™«çš„è¾ƒé‡ä¸­ï¼Œæ­å¼€è‡ªå·±å‘½è¿çš„ç¥ç§˜é¢çº±ã€‚ä»–çš„å¿ƒä¸­å……æ»¡äº†å¯¹æœªçŸ¥çš„æ•¬ç•ï¼Œä½†ä»–ä¹Ÿæ˜ç™½ï¼Œåªæœ‰é€šè¿‡ä¸æ–­çš„æˆ˜æ–—å’Œç‰ºç‰²ï¼Œä»–æ‰èƒ½æ‰¾åˆ°çœŸæ­£çš„ç­”æ¡ˆã€‚

éº¦å…‹ç«™åœ¨æ³°ä¼¦è”é‚¦çš„ç ”å‘ä¸­å¿ƒï¼Œçœ¼å‰æ˜¯ä¸€æ’æ’é—ªçƒç€è“å…‰çš„ä»ªå™¨å’Œå¿™ç¢Œçš„ç§‘å­¦å®¶ä»¬ã€‚ä»–çš„å¿ƒä¸­å……æ»¡äº†å¯¹æœªçŸ¥çš„æ•¬ç•ï¼Œä½†ä»–ä¹Ÿæ˜ç™½ï¼Œåªæœ‰é€šè¿‡ä¸æ–­çš„æˆ˜æ–—å’Œç‰ºç‰²ï¼Œä»–æ‰èƒ½æ‰¾åˆ°çœŸæ­£çš„ç­”æ¡ˆã€‚æ–°å‹æ­¦å™¨çš„ç ”å‘å·²ç»è¿›å…¥æœ€åé˜¶æ®µï¼Œè¿™æ˜¯å¯¹æŠ—å¼‚è™«æ‰©å¼ çš„å…³é”®ã€‚

â€œéº¦å…‹ï¼Œä½ å‡†å¤‡å¥½äº†å—ï¼Ÿâ€æ°èŠ¬èµ°è¿‡æ¥ï¼Œæ‹äº†æ‹ä»–çš„è‚©è†€ã€‚

â€œå½“ç„¶ï¼Œæ°èŠ¬ã€‚æˆ‘ä»¬ä¸èƒ½è®©è¿™äº›å¼‚è™«ç»§ç»­æ‰©å¼ ä¸‹å»ã€‚â€éº¦å…‹åšå®šåœ°å›ç­”ã€‚

åœ¨æ¥ä¸‹æ¥çš„å‡ å‘¨é‡Œï¼Œéº¦å…‹å’Œæ°èŠ¬ä¸ç§‘å­¦å®¶ä»¬ä¸€èµ·ï¼Œæ—¥ä»¥ç»§å¤œåœ°å·¥ä½œï¼Œç»ˆäºå®Œæˆäº†æ–°å‹æ­¦å™¨çš„ç ”å‘ã€‚è¿™ç§æ­¦å™¨èƒ½å¤Ÿæœ‰æ•ˆåœ°æŠ‘åˆ¶å¼‚è™«çš„ç¹æ®–å’Œæ‰©å¼ ï¼Œæ˜¯æ³°ä¼¦è”é‚¦å¯¹æŠ—å¼‚è™«çš„æœ€åå¸Œæœ›ã€‚

æœ€ç»ˆæˆ˜å½¹çš„å‰å¤œï¼Œéº¦å…‹ç«™åœ¨æŒ‡æŒ¥èˆ°çš„ç”²æ¿ä¸Šï¼Œæœ›ç€æ˜Ÿç©ºã€‚ä»–çš„å¿ƒä¸­å……æ»¡äº†ç´§å¼ å’ŒæœŸå¾…ã€‚ä»–çŸ¥é“ï¼Œæ˜å¤©çš„æˆ˜æ–—å°†å†³å®šæ˜Ÿé™…é—´çš„æœªæ¥ã€‚

â€œéº¦å…‹ï¼Œä½ çœ‹èµ·æ¥å¾ˆç´§å¼ ã€‚â€æ³°ä¼¦è”é‚¦çš„é«˜å±‚èµ°è¿‡æ¥ï¼Œå…³åˆ‡åœ°é—®é“ã€‚

â€œæ˜¯çš„ï¼Œé•¿å®˜ã€‚è¿™æ˜¯æˆ‘ç¬¬ä¸€æ¬¡é¢å¯¹å¦‚æ­¤å¤§è§„æ¨¡çš„æˆ˜æ–—ã€‚â€éº¦å…‹å¦è¯šåœ°å›ç­”ã€‚

â€œè®°ä½ï¼Œéº¦å…‹ï¼Œä½ ä¸æ˜¯ä¸€ä¸ªäººåœ¨æˆ˜æ–—ã€‚æˆ‘ä»¬éƒ½åœ¨ä½ èº«è¾¹ã€‚â€é«˜å±‚é¼“åŠ±é“ã€‚

ç¬¬äºŒå¤©ï¼Œæˆ˜æ–—å¼€å§‹äº†ã€‚éº¦å…‹å’Œæ°èŠ¬å¸¦é¢†ç€ä»–ä»¬çš„éƒ¨é˜Ÿï¼Œå†²å‘å¼‚è™«çš„å·¢ç©´ã€‚æ–°å‹æ­¦å™¨å‘æŒ¥äº†å·¨å¤§çš„ä½œç”¨ï¼Œå¼‚è™«çš„æ‰©å¼ è¢«æˆåŠŸéåˆ¶ã€‚ç»è¿‡å‡ ä¸ªå°æ—¶çš„æ¿€æˆ˜ï¼Œæ³°ä¼¦è”é‚¦å–å¾—äº†èƒœåˆ©ã€‚

æˆ˜æ–—ç»“æŸåï¼Œéº¦å…‹ç«™åœ¨æˆ˜åœºä¸Šï¼Œæœ›ç€æ»¡ç›®ç–®ç—çš„æ™¯è±¡ï¼Œå¿ƒä¸­å……æ»¡äº†å¤æ‚çš„æƒ…æ„Ÿã€‚ä»–çŸ¥é“ï¼Œè¿™åœºèƒœåˆ©åªæ˜¯æš‚æ—¶çš„ï¼ŒçœŸæ­£çš„å’Œå¹³è¿˜éœ€è¦æ›´å¤šçš„åŠªåŠ›ã€‚

åœ¨æ˜Ÿé™…é—´çš„å’Œå¹³åè®®ç­¾ç½²ä»ªå¼ä¸Šï¼Œéº¦å…‹è¢«æˆäºˆè‹±é›„çš„ç§°å·ã€‚ä»–ç«™åœ¨å°ä¸Šï¼Œæœ›ç€å°ä¸‹çš„ä¼—äººï¼Œå¿ƒä¸­å……æ»¡äº†æ„Ÿæ…¨ã€‚

â€œéº¦å…‹ï¼Œä½ æˆä¸ºäº†æˆ‘ä»¬çš„è‹±é›„ã€‚â€å‡¯å°”-è«æ‹‰è”åˆä½“çš„é¢†è¢–èµ°ä¸Šå‰æ¥ï¼Œå¾®ç¬‘ç€è¯´é“ã€‚

â€œè°¢è°¢ï¼Œä½†æˆ‘åªæ˜¯åšäº†æˆ‘åº”è¯¥åšçš„äº‹æƒ…ã€‚â€éº¦å…‹è°¦è™šåœ°å›ç­”ã€‚

ä»ªå¼ç»“æŸåï¼Œéº¦å…‹ç‹¬è‡ªä¸€äººèµ°åœ¨æ˜Ÿé™…æ¸¯å£çš„ç”²æ¿ä¸Šï¼Œæœ›ç€è¿œå¤„çš„æ˜Ÿç©ºã€‚ä»–åæ€ç€è‡ªå·±çš„æˆ˜äº‰ç»å†ï¼Œå†³å®šç»§ç»­ä¸ºå’Œå¹³è€Œæˆ˜ã€‚ä»–çŸ¥é“ï¼ŒçœŸæ­£çš„ç­”æ¡ˆè¿˜åœ¨å‰æ–¹ï¼Œè€Œä»–å°†ç»§ç»­è¿½å¯»ã€‚
```

### 5.3 è¿›ä¸€æ­¥æ€è€ƒå’Œè®¨è®º

ä»¥ä¸‹è®¨è®ºç‚¹å…¨éƒ¨ä¸ºå¼€æ”¾æ€§è®¨è®ºï¼Œæ²¡æœ‰æ ‡å‡†çš„æ­£ç¡®ç­”æ¡ˆï¼Œä»…ä½œä¸ºå¯å‘æ€è€ƒå’Œå¼€æ‹“æ€è·¯çš„ä½œç”¨

- ä½¿ç”¨LangGraphæ˜¯å¦å¯ä»¥å¤ç°ä¸Šé¢çš„å·¥ä½œæµï¼Ÿ
- ä¸–ç•ŒèƒŒæ™¯å’Œæ•…äº‹çº¿æ˜¯å¦ä¹Ÿå¯ä»¥å¼•å…¥äººç±»è®¨è®ºåä½œçš„æœºåˆ¶ï¼Ÿè¯¥æ€ä¹ˆæ”¹å†™ï¼Ÿ
- æ˜¯å¦å¯ä»¥åƒç¿»è¯‘é¡¹ç›®ä¸€æ ·ï¼Œå¼•å…¥åæ€æœºåˆ¶ï¼Ÿå¦‚æœå¯ä»¥ï¼Œåæ€æœºåˆ¶åº”è¯¥å¦‚ä½•è®¾è®¡ï¼Ÿ
- è¿˜æœ‰æ²¡æœ‰æ›´å¥½çš„æ•…äº‹åˆ›ä½œå·¥ä½œæµè®¾è®¡ï¼Ÿ
- ä½ è¿˜æœ‰å“ªäº›å¥½çš„å·¥ä½œæµç‚¹å­ï¼Ÿå­¦å®Œæœ¬è¯¾ä¹‹åï¼Œè¿˜æœ‰å“ªäº›åˆ›ä½œéš¾ç‚¹ï¼Ÿ

## 6. å…¶ä»–ä¿¡æ¯

- Mermaidåœ¨çº¿æ¸²æŸ“ç½‘ç«™ï¼š[mermaid.live](https://mermaid.live/)
- æ‰‹ç»˜é£æ ¼æµç¨‹å›¾åœ¨çº¿ç¼–è¾‘ï¼š[excalidraw.com](https://excalidraw.com/)

## ğŸ”„ è¿™èŠ‚è¯¾å­¦å®Œä¹‹åï¼Œè®°å¾—æ¢å¤ç¯å¢ƒ

```python
# å› ä¸ºæœ¬è¯¾ä½¿ç”¨çš„langgraphå¯èƒ½éœ€è¦ä¾èµ–langchain 0.2.10ç‰ˆæœ¬ï¼Œä½†å…¶ä»–è¯¾ä»¶ä¾èµ–langchain 0.1.20ç‰ˆæœ¬
# è¯·å­¦ä¹ å®Œæœ¬è¯¾ä¹‹åå¯¹langchainè¿›è¡Œé™çº§ï¼Œä»¥å…åœ¨å…¶ä»–è¯¾ç¨‹å‡ºç°è¿è¡Œé”™è¯¯
!pip install langchain==0.1.20
!pip install langchain-openai==0.1.6
!pip install langchain-community==0.0.38
```